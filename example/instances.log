{"index": 0, "prediction": "Hallo, das ist Elena und ich werde unsere Arbeit präsentieren , indem wir uns in spanischen und angepreßten Modellen und Modellen vorstellen. (Stimme) Wir werden also darüber reden, was lexikalisches Borgen ist, die Aufgabe, die wir vorgeschlagen haben, die Datensätze, die wir veröffentlicht haben und einige Modelle, die wir erforscht haben. Aber was ist mit der Lexik und was ist mit der Mathematik? Leksikale Verwandlung ist in der Regel die Verwandlung von Worten aus einer Sprache in eine andere Sprache, in Spanisch verwenden Sie Wörter aus dem Englischen und Sie haben einige Beispiele wie Pods in English, All these English words are sometimes used in Spanish, Lexikale Verwandlung ist ein Sprachverwandlungsmodell. #um, die eigentlich einfach nur in einer Sprache verwendet werden, die von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen und von anderen Sprachen. Es gibt jedoch einige Unterschiede zwischen dem Text und dem Sch reibverhalten, die man auf dem Text verarbeiten kann. Das Schreibverhalten ist etwas, das durch die Definition von Linguistik und der Sprachverarbeitung nicht integriert ist. Es ist auch etwas, das durch das Sprachverhalten integriert ist. Das ist ja ein sehr gutes Beispiel dafür, dass die Bor rowings mit der Grammatik der Empfängersprache übereinstimmen und dass die Borrowings in der Empfängersprache integriert werden können. Warum ist das Leihen also ein interessantes Phänomen? Aus der Sicht der Linguistik ist das Leihen eine Manifestation, wie Sprachen sich verändern und wie sie interagieren. Und auch L eksikale Lern ern sind Beispiele für neue Lernformen, die in der spanischen Sprache eingeführt wurden. als neue Wörter . In Bezug auf NLP #ah Borrowings sind eine Ausgabe von Wörtern aus der Sprache und in der Tat automatisch auswählen, wie die Textverarbeitung für NLP-T ests wie Sprachverknüpfungen oder Maschinendurchsetzungen verwendet werden kann. Es hat ein wachsendes Interesse an der Wirkung von Englisch auf andere Sprachen, besonders Ich habe mir vorgenommen, dass ich mich mit dem Englischen auskennen kann, was manchmal als \"Anglicisations\" bezeichnet wird. Und du hast einige Beispiele für #ah-Work auf der automatischen Ausarbeitung von #ah-Bewerbungen in einigen dieser Sprachen. Die Aufgabe, die wir vorschlagen, ist es zu detektieren, nicht analysierte lexikalische Bogen in spanischen Nachrichten, was bedeutet, dass wir interessiert sind, in der Ausführung von #ah-Werben aus Die anderen Sprachen, die in spanischen Zeitungen verwendet wurden, waren nicht integriert oder in die Sprache integriert , also nicht in spanisch integriert. Hier haben Sie ein Beispiel für diese Sprache. Sie sehen die drei Spannungen, die eigentlich englisch sind, wie English Work, Animal Printing und Packing Work. Das ist die Art von Spannungen, die wir in der Erforschung und Erforschung interessieren. Es gab vorherige Worte. auf der Anglistik der Anglistik, die von der C.R.F. Model für die Anglistik der spanischen Nachrichten in der spanischen Version erstellt wurde . Dieser Model hat einen Punkt von sechsundsechzig, aber es gibt einige Einschränkungen in der Modellierung und in der Modellierung. Es ist auch so, dass es in der Zeit, in der wir uns in der Zeit befinden, in der wir uns in der Zeit befinden, in der wir uns in der Zeit befinden. die Präsentation der Modellierung der Modellierung kann eigentlich generell zu den vorherigen Bawings. #ah, so wir wollen es, einige dieser #ah, Limitation in der Taske zu verarbeiten. Also zu Beginn mit der wir eine neue Datensatz ung erzeugt haben. Die neue Datensatzung ist Anmerkung: mit den Textverarbeit ungen und dem Test wird erzeugt, dass es so schwierig ist, dass es möglich ist, dass es so wenig wie möglich in den Themen zwischen dem Training und dem Test zu finden ist, und dass die Tests aus den Quellen und den Quellen kommen. Wir sehen nicht in der Trainings-Serie, dass Sie nicht in der Zeit überlaufen können. Es ist auch sehr schwierig, Ihnen einige Zahlen zu geben, wenn Sie die Trainings-Serie mit sechs Boards haben. Ich habe tausend Tok en, die Teststelle enthält zwanzig Barings. Ich habe tausend Token. Die Test stelle enthält so viele aus dem Vokabular gewählte Wörter wie möglich. Tatsächlich waren 92 % der Borrowings in der Teststelle OOB, also waren sie nicht während des Trainings gesehen. #um der Korpus ist eigentlich eine Sammlung von Texten, die aus verschiedenen Sprach arten der spanischen Zeitungen stammen und #um ist von Hand verwendet, um einen englischen Text zu verwenden, der für die meisten Sprachveröffentlichungen in Spanien und dann für andere Sprachen verwendet wird. Wir verwenden Konformform ate und wir verwenden BIO-Encoder. So dass wir können, dass wir ein Single-Token-Browning, wie z.B. ein Multi-Token-Browning oder ein Machine Learning-Browning machen können. Diese Zahlen der Corpus können Sie sagen, dass es drei hundert undsiebzigtausend Tonnen sind und Sie haben die Nummer von dass wir als Englisch und die Sp rachsprachigen als andere Wörter und wie viele von ihnen wir haben. Und hier haben wir ein paar Beispiele von der Datensatz -Satzung, wie Sie sehen können, Wir haben in der ersten Example wir haben die Bauing. Das ist ein Multi-Wort-Borgen. Und wir haben es mit der BIO- Anmeldung verwendet, also die BIO-Anmeldung wird immer verwendet. Wo ist in Spanisch so nicht für wo für wo wir nicht barren? Und hier in diesem zweiten Beispiel haben wir Penching und Crash. die auch als \"Labour\" aus Englisch bezeichnet werden. So, als wir das Datensatz hatten, haben wir mehrere Modelle für die Aufgabe der Entdeckung und Entdeckung dieser lexikalischen Ent deckungen erforscht. Das erste, was wir versuchen, ist die Conditioning-Modell-Modell. Das ist das Modell , das in der vorherigen Arbeit verwendet wurde. Und wir benutzen die gleichen Hand werk-Features von der Arbeit, wie man sie von der Arbeit aus sieht. Diese Features sind die Features, die in der Welt der Apotheke sind. Es ist eine Quote, die Mark so etwas wie: sind die Art von Funktionen, die man in einer benannten Editurenerkennungs-Task erwarten würde. Das sind die Ergebnisse, die wir bekommen haben. Ich habe fünfzig fünf von F one Score erhalten, indem ich die mit der C.R.F. #ahm mit Handcrafted Feature, die unterschiedlich ist. Vergleichen Sie das mit dem berichteten F1 Score von 86 - das Ergebnis wurde mit dem gleichen CRF-Modell er mittelt, aber mit unterschiedlichen Daten, auch für die Sprachverarbeitung. dass die Daten, die wir erstellt haben, viel schwieriger sind als die Wir brauchen , um mehr spezielle Modelle für diese Aufgabe zu erforschen. Also wir... Wir haben das Transformator-Modell getestet, wir benutzen das Beto, das ein monolinguales Modell für Spanisch und auch für Sprach modelle ist. Wir benutzen beide Modelle, die wir durch die Transformations-Bild ung nutzen. Das ist so, dass wir sagen können, dass wir besser als Beto funktionieren. Die Entwicklung ist auf der Testseite und auf der Testseite und über alle Metriken. Das haben wir. Und ich habe die Idee, die zu vergleichen, die C.R.F. Model von Ten and Eighty Two. Das ist der C.R.F. von der Obtainer Fifty Five, der Obtainer Fifty Five von One Score, der Multilingual Bird Obtainer Eighty. die zwei, die eine große Differenz sind. So, dass wir diese Ergebnisse haben, fragen wir uns selbst eine andere Frage, die lautet: Was ist gut für uns? #uh Find ein Bios DMCRF-Modell, mit verschiedenen Typen von Embeddings. Es gibt verschiedene Arten von linguistischen Informationen. und so, dass die Ergebnisse von Transformationsmodellen erhalten werden. Also wir müssen es so machen, wir ran some #ah Preliminary experiments we we. #ah, die ranne die TMCR-Modell-Mode. Wir haben die Bibliothek und die Experimenten mit verschiedenen Arten von Bäumen, wie z.B. Bäumen, aber auch mit Fassbändern und so weiter. Was wir herausfanden, war, dass Transformator-basierte Embeddings besser funktionieren als nicht-kontextuelle Embeddings , dass die Kombination aus englischen und spanischen Embeddings aus Multi-Lingual-Bedings und B.P. Embeddings produziert wird. Besser als ein und ein und ein und ein und ein. Das ist besser, wie ich das hier denke. Best performing weighs so viel. Modelle werden von der MCRF Modell. #ah, wenn man ein Stück weiß, ist es so. Beton und Betonbeton und B.P. und der andere Beton und B.P. und auch B.P. und auch B.P. und B.P. Das ist das letzte, das ist der höchste Punkt auf der Teststelle, der höchste Punkt auf der Entwicklung wird von der Entwicklung durch die eine mit den B.P. Ich denke, dass wir mit dem besten Ergebnis mit einer Mütze von siebenundsechzig auf der Entwicklung und zwei auf der Testseite kommen. Das ist eine Verbesserung, die sich mit diesen Ergebnissen vergleichen lässt. Wir haben uns endlich gefragt, ob wir eine andere Frage stellen können, die lautet: Kann die translationsfähige Ausdehnung von der Sprachidentifizierung und der Sprachverwechslung so aussehen, dass wir das gleiche Modell haben, das wir haben, aber wir verwenden nicht die verwendeten Transformations-Behälter. und aber auch in den Bäudungen. Wir verwenden Code Switching und Betten. Was sind Code Switching und Betten? die in der Transform ation eingeb aut wurden, die für die Sprachidenti fizierung in der spanischen englischen Sprach abteilung der Sprachvermittlung verwendet wurden , die auf der Sprachvermittlung in der spanischen Sprachabteilung der Sprachvermittlung angesiedelt ist. Fett unsere Biol ast-TMCRF mit Switch -Bedding und Optional-Bedding und B .P.B.B.ing und so weiter. Das beste Ergebnis ist vierundzwanzig Punkt, der höchste Punkt, den wir alle versuchen, auf der Teststelle zu testen. Das beste Ergebnis ist, dass wir einen Punkt auf der Entwicklung erzielen, der siebenund zwanzig ist, und das beste Ergebnis ist, dass wir es durch die BLS-Ref #ah. mit unadaptierten Einbettungen. Also einige Schlussfolgerungen aus unserer Arbeit haben wir Wir haben ein neues Datensatz von Spanish News Wired produziert. Das ist mit dem nicht-verknüpften, nicht-verknüpften Barwins, der ist mehr als der Barwins und wir haben vier Arten von Modellen für die Erforschung von Barwins in der Erforschung von Analysen. Wir haben mit Wick Point für alle Modelle zusammengetragen. #um, wie ich hier auch Frequent negative Folgen beinhalten auch Abwehrmaßnahmen, die in englischer und spanischer Sprache vorhanden sind. #um auch interessant die B P P-B ewertungen zu verbessern ein Punkt und zu verbessern die #um zu verbessern, was #um ist interessant zu finden, dass wir es auf der Zukunft arbeiten können und das alles haben wir alles, danke fürs Hören.", "delays": [6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 8000.0, 8000.0, 8000.0, 9500.0, 11000.0, 11000.0, 11000.0, 11750.0, 11750.0, 11750.0, 11750.0, 11750.0, 11750.0, 11750.0, 11750.0, 13750.0, 18000.0, 18000.0, 18000.0, 21000.0, 21000.0, 21000.0, 21000.0, 22500.0, 22500.0, 22500.0, 22500.0, 22500.0, 22500.0, 22500.0, 22500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 25500.0, 28000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 31000.0, 35750.0, 38750.0, 38750.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 41500.0, 41500.0, 41500.0, 43000.0, 43000.0, 43000.0, 43000.0, 43000.0, 43000.0, 43000.0, 43000.0, 43000.0, 43000.0, 44500.0, 49000.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 51500.0, 54250.0, 55750.0, 55750.0, 57250.0, 57250.0, 57250.0, 57250.0, 57250.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 63000.0, 64500.0, 64500.0, 64500.0, 64500.0, 64500.0, 64500.0, 64500.0, 64500.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 73500.0, 78000.0, 78000.0, 78000.0, 78000.0, 78000.0, 88500.0, 88500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 89500.0, 92000.0, 92000.0, 92000.0, 93500.0, 95000.0, 95000.0, 98000.0, 98000.0, 98000.0, 98000.0, 98000.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 99500.0, 103750.0, 103750.0, 103750.0, 103750.0, 103750.0, 105250.0, 105250.0, 105250.0, 109500.0, 109500.0, 109500.0, 109500.0, 109500.0, 109500.0, 109500.0, 109500.0, 109500.0, 109500.0, 111000.0, 111000.0, 111000.0, 111000.0, 111000.0, 111000.0, 111000.0, 112500.0, 117000.0, 117000.0, 117000.0, 118500.0, 118500.0, 119500.0, 119500.0, 119500.0, 119500.0, 119500.0, 119500.0, 119500.0, 119500.0, 119500.0, 119500.0, 119500.0, 119500.0, 119500.0, 122250.0, 122250.0, 122250.0, 125250.0, 125250.0, 125250.0, 125250.0, 125250.0, 125250.0, 125250.0, 125250.0, 126750.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 135500.0, 135500.0, 135500.0, 136500.0, 136500.0, 136500.0, 136500.0, 136500.0, 136500.0, 136500.0, 136500.0, 140750.0, 140750.0, 140750.0, 140750.0, 140750.0, 142250.0, 142250.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 146750.0, 146750.0, 154000.0, 154000.0, 154000.0, 154000.0, 154000.0, 154000.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 156250.0, 160500.0, 160500.0, 160500.0, 160500.0, 161000.0, 161000.0, 161000.0, 161000.0, 161000.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 169750.0, 174000.0, 174000.0, 174000.0, 174000.0, 174000.0, 175500.0, 175500.0, 175500.0, 175500.0, 178500.0, 178500.0, 178500.0, 178500.0, 178500.0, 178500.0, 178500.0, 178500.0, 180000.0, 180000.0, 180000.0, 181500.0, 181500.0, 181500.0, 184500.0, 184500.0, 184500.0, 184500.0, 184500.0, 186000.0, 186000.0, 189000.0, 194000.0, 194000.0, 195500.0, 195500.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 201250.0, 201250.0, 201250.0, 201250.0, 201250.0, 201250.0, 204000.0, 204000.0, 204000.0, 204000.0, 208000.0, 209500.0, 209500.0, 209500.0, 212500.0, 212500.0, 212500.0, 212500.0, 212500.0, 212500.0, 212500.0, 212500.0, 212500.0, 212500.0, 214000.0, 214000.0, 214000.0, 215500.0, 215500.0, 217000.0, 217000.0, 217000.0, 218500.0, 218500.0, 218500.0, 218500.0, 218500.0, 218500.0, 218500.0, 218500.0, 218500.0, 218500.0, 218500.0, 218500.0, 220000.0, 221500.0, 221500.0, 221500.0, 222250.0, 222250.0, 222250.0, 222250.0, 228000.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 231000.0, 231000.0, 232500.0, 232500.0, 232500.0, 232500.0, 232500.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 235750.0, 238750.0, 238750.0, 238750.0, 238750.0, 238750.0, 239250.0, 239250.0, 239250.0, 239250.0, 239250.0, 239250.0, 239250.0, 243500.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 247000.0, 247000.0, 247000.0, 249750.0, 249750.0, 249750.0, 251250.0, 251250.0, 251250.0, 253750.0, 253750.0, 253750.0, 253750.0, 253750.0, 253750.0, 253750.0, 256500.0, 256500.0, 261000.0, 262500.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 267000.0, 267000.0, 267000.0, 267000.0, 267000.0, 268500.0, 269250.0, 269250.0, 269250.0, 269250.0, 269250.0, 269250.0, 269250.0, 269250.0, 269250.0, 269250.0, 269250.0, 269250.0, 269250.0, 272000.0, 272000.0, 272000.0, 273500.0, 273500.0, 276500.0, 276500.0, 278000.0, 282500.0, 282500.0, 282500.0, 282500.0, 282500.0, 282500.0, 282500.0, 282500.0, 282500.0, 282500.0, 282500.0, 282500.0, 283750.0, 283750.0, 283750.0, 283750.0, 283750.0, 283750.0, 283750.0, 283750.0, 283750.0, 283750.0, 283750.0, 283750.0, 286500.0, 286500.0, 286500.0, 286500.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 290500.0, 290500.0, 290500.0, 290500.0, 293250.0, 293250.0, 294750.0, 294750.0, 294750.0, 294750.0, 294750.0, 294750.0, 294750.0, 297500.0, 297500.0, 297500.0, 297500.0, 299000.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 300500.0, 305000.0, 306500.0, 306500.0, 306500.0, 306500.0, 306500.0, 306500.0, 306500.0, 306500.0, 306500.0, 308000.0, 308000.0, 308000.0, 309500.0, 309500.0, 309500.0, 309500.0, 311000.0, 311000.0, 311000.0, 311000.0, 312500.0, 314000.0, 315500.0, 315500.0, 315500.0, 317000.0, 317000.0, 318500.0, 318500.0, 318500.0, 318500.0, 318500.0, 318500.0, 318500.0, 318500.0, 318500.0, 320000.0, 320000.0, 320000.0, 320500.0, 320500.0, 320500.0, 320500.0, 323500.0, 323500.0, 323500.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 333000.0, 333000.0, 333000.0, 337500.0, 339000.0, 339000.0, 339000.0, 339000.0, 339000.0, 339000.0, 339000.0, 340500.0, 342000.0, 342000.0, 342000.0, 342000.0, 342000.0, 343500.0, 343500.0, 343500.0, 343500.0, 343500.0, 343500.0, 343500.0, 343500.0, 343500.0, 343500.0, 343500.0, 343500.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 348500.0, 348500.0, 348500.0, 348500.0, 348500.0, 348500.0, 348500.0, 350000.0, 350000.0, 350000.0, 351250.0, 351250.0, 351250.0, 351250.0, 351250.0, 351250.0, 351250.0, 351250.0, 355500.0, 355500.0, 355500.0, 357000.0, 357000.0, 357000.0, 357000.0, 357000.0, 357000.0, 358500.0, 358750.0, 358750.0, 358750.0, 358750.0, 358750.0, 361500.0, 361500.0, 361500.0, 362000.0, 362000.0, 362000.0, 362000.0, 362000.0, 362000.0, 362000.0, 365250.0, 365250.0, 365250.0, 365250.0, 368000.0, 368000.0, 368000.0, 371000.0, 371000.0, 371000.0, 371000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 374750.0, 374750.0, 374750.0, 374750.0, 374750.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 382750.0, 382750.0, 383250.0, 383250.0, 383250.0, 383250.0, 383250.0, 383250.0, 389000.0, 389000.0, 389000.0, 389000.0, 389000.0, 389000.0, 389000.0, 389000.0, 390500.0, 390500.0, 390500.0, 390500.0, 392000.0, 392000.0, 393500.0, 393500.0, 395000.0, 395000.0, 395000.0, 395000.0, 396500.0, 396500.0, 396500.0, 396500.0, 396500.0, 396500.0, 396500.0, 396500.0, 397250.0, 397250.0, 400000.0, 400000.0, 400000.0, 400000.0, 401500.0, 401500.0, 401500.0, 401500.0, 401500.0, 401500.0, 401500.0, 401500.0, 404500.0, 404500.0, 406000.0, 406000.0, 406000.0, 407500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 413500.0, 414000.0, 414000.0, 414000.0, 414000.0, 414000.0, 414000.0, 417500.0, 417500.0, 417500.0, 417500.0, 417500.0, 417500.0, 417500.0, 417500.0, 417500.0, 421500.0, 421500.0, 421500.0, 421500.0, 421500.0, 421500.0, 421500.0, 421500.0, 421500.0, 421500.0, 421500.0, 421500.0, 421500.0, 426000.0, 426000.0, 426000.0, 426000.0, 426000.0, 426000.0, 426000.0, 426000.0, 429500.0, 429500.0, 431000.0, 431000.0, 431000.0, 431750.0, 431750.0, 431750.0, 431750.0, 431750.0, 431750.0, 431750.0, 436000.0, 436000.0, 437000.0, 437000.0, 437000.0, 437000.0, 437000.0, 437000.0, 437000.0, 437000.0, 439750.0, 441250.0, 441250.0, 441250.0, 441250.0, 444000.0, 444000.0, 444000.0, 444000.0, 445500.0, 445500.0, 445500.0, 445500.0, 445500.0, 445500.0, 445500.0, 445500.0, 445500.0, 448500.0, 450000.0, 450000.0, 450000.0, 450000.0, 450000.0, 450000.0, 450000.0, 451500.0, 451500.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 459500.0, 459500.0, 460750.0, 460750.0, 460750.0, 460750.0, 460750.0, 460750.0, 460750.0, 460750.0, 460750.0, 460750.0, 463000.0, 463000.0, 468750.0, 468750.0, 470250.0, 471750.0, 471750.0, 471750.0, 473250.0, 474750.0, 474750.0, 474750.0, 474750.0, 474750.0, 474750.0, 474750.0, 474750.0, 474750.0, 474750.0, 474750.0, 476000.0, 477500.0, 477500.0, 477500.0, 480500.0, 480500.0, 480500.0, 480500.0, 480500.0, 480500.0, 480500.0, 480500.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 483000.0, 487250.0, 487250.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 489250.0, 489250.0, 489250.0, 489250.0, 489250.0, 489250.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 495750.0, 498500.0, 498500.0, 501500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 502500.0, 504500.0, 504500.0, 504500.0, 504500.0, 504500.0, 504500.0, 504500.0, 507500.0, 509000.0, 509000.0, 509000.0, 509000.0, 510500.0, 511500.0, 511500.0, 511500.0, 511500.0, 511500.0, 511500.0, 511500.0, 511500.0, 511500.0, 511500.0, 511500.0, 511500.0, 511500.0, 511500.0, 517500.0, 517500.0, 517500.0, 517500.0, 517500.0, 517500.0, 517500.0, 517500.0, 517500.0, 517500.0, 520750.0, 520750.0, 520750.0, 520750.0, 520750.0, 520750.0, 520750.0, 523750.0, 525750.0, 525750.0, 525750.0, 525750.0, 525750.0, 525750.0, 525750.0, 525750.0, 528500.0, 528500.0, 528500.0, 528500.0, 528500.0, 530000.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 533000.0, 533250.0, 533250.0, 533250.0, 533250.0, 537500.0, 537500.0, 537500.0, 537500.0, 537500.0, 537500.0, 537500.0, 539000.0, 539000.0, 539000.0, 539000.0, 540500.0, 540500.0, 540500.0, 542500.0, 542500.0, 542500.0, 542500.0, 542500.0, 542500.0, 542500.0, 542500.0, 545250.0, 545250.0, 545250.0, 546750.0, 546750.0, 546750.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 549500.0, 551000.0, 551000.0, 551000.0, 551000.0, 552500.0, 552500.0, 552500.0, 552500.0, 555500.0, 556500.0, 556500.0, 556500.0, 556500.0, 556500.0, 556500.0, 556500.0, 559250.0, 559250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 562250.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 568500.0, 568750.0, 568750.0, 568750.0, 568750.0, 568750.0, 571500.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 574750.0, 574750.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 577500.0, 579000.0, 579000.0, 579000.0, 580500.0, 580500.0, 582000.0, 582000.0, 582000.0, 582000.0, 582000.0, 582000.0, 582000.0, 582000.0, 582000.0, 582000.0, 583500.0, 585000.0, 585000.0, 585000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 589500.0, 589500.0, 589500.0, 591000.0, 591000.0, 591000.0, 591000.0, 591000.0, 591000.0, 591000.0, 594000.0, 595500.0, 595500.0, 595500.0, 597000.0, 597000.0, 597000.0, 597000.0, 597000.0, 597000.0, 597000.0, 598500.0, 598500.0, 600000.0, 600000.0, 600000.0, 601500.0, 601500.0, 601500.0, 601500.0, 601500.0, 603250.0, 603250.0, 603250.0, 603250.0, 603250.0, 603250.0, 603250.0, 603250.0, 603250.0, 603250.0, 603250.0, 603250.0, 606000.0, 606000.0, 607500.0, 609000.0, 610500.0, 610500.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 619500.0, 621000.0, 621000.0, 621000.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 623250.0, 625250.0, 625250.0, 625250.0, 625250.0, 625250.0, 625250.0, 628000.0, 629500.0, 630500.0, 630500.0, 630500.0, 630500.0, 630500.0, 630500.0, 630500.0, 630500.0, 630500.0, 630500.0, 634750.0, 636000.0, 636000.0, 636000.0, 637500.0, 637500.0, 639000.0, 639000.0, 639000.0, 639000.0, 639000.0, 639000.0, 640500.0, 640500.0, 640500.0, 640500.0, 640500.0, 640500.0, 642000.0, 642000.0, 643500.0, 643500.0, 643500.0, 645000.0, 645000.0, 645000.0, 645000.0, 645000.0, 646500.0, 646500.0, 646500.0, 646500.0, 648000.0, 648000.0, 648750.0, 648750.0, 651500.0, 651500.0, 651500.0, 652000.0, 652000.0, 658000.0, 661000.0, 661000.0, 661000.0, 662500.0, 662500.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 665500.0, 665500.0, 665500.0, 665500.0, 665500.0, 665500.0, 665500.0, 665500.0, 665500.0, 665500.0, 665500.0, 668500.0, 670000.0, 670000.0, 670000.0, 670000.0, 670000.0, 670000.0, 670000.0, 670000.0, 670000.0, 671500.0, 671500.0, 671500.0, 671500.0, 674500.0, 674500.0, 674500.0, 674500.0, 674500.0, 674500.0, 674500.0, 674500.0, 674500.0, 674500.0, 675750.0, 675750.0, 675750.0, 675750.0, 678000.0, 678000.0, 678000.0, 682250.0, 682250.0, 682250.0, 682250.0, 682250.0, 682250.0, 682750.0, 682750.0, 685500.0, 685500.0, 686500.0, 686500.0, 686500.0, 686500.0, 686500.0, 686500.0, 686500.0, 686500.0, 689250.0, 689250.0, 689250.0, 692000.0, 692000.0, 692000.0, 693500.0, 693500.0, 693500.0, 693500.0, 695000.0, 695000.0, 695000.0, 695000.0, 696500.0, 696500.0, 698000.0, 698000.0, 698000.0, 699500.0, 699500.0, 699500.0, 701000.0, 701000.0, 701000.0, 702250.0, 702250.0, 702250.0, 702250.0, 702250.0, 704750.0, 704750.0, 704750.0, 704750.0, 704750.0, 704750.0, 704750.0, 704750.0, 704750.0, 707500.0, 707500.0, 707500.0, 707500.0, 707500.0, 710250.0, 711750.0, 711750.0, 714000.0, 714000.0, 714000.0, 714000.0, 714000.0, 714000.0, 714000.0, 714000.0, 714000.0, 714000.0, 714000.0, 716750.0, 718250.0, 718250.0, 718250.0, 718250.0, 718250.0, 722750.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 725500.0, 725500.0, 725500.0, 725500.0, 725500.0, 725500.0, 727000.0, 727000.0, 727000.0, 727000.0, 727000.0, 727000.0, 727000.0, 728500.0, 728500.0, 728500.0, 730000.0, 730000.0, 730000.0, 730000.0, 731500.0, 731500.0, 732000.0, 732000.0, 732000.0, 732000.0, 732000.0, 732000.0, 732000.0], "elapsed": [9644.572257995605, 9644.572257995605, 9644.572257995605, 9644.572257995605, 9644.572257995605, 9644.572257995605, 9644.572257995605, 12527.322769165039, 12527.322769165039, 12527.322769165039, 15470.166444778442, 19264.36161994934, 19264.36161994934, 19264.36161994934, 21547.594785690308, 21547.594785690308, 21547.594785690308, 21547.594785690308, 21547.594785690308, 21547.594785690308, 21547.594785690308, 21547.594785690308, 25204.25534248352, 33238.3291721344, 33238.3291721344, 33238.3291721344, 39147.545337677, 39147.545337677, 39147.545337677, 39147.545337677, 41995.025396347046, 41995.025396347046, 41995.025396347046, 41995.025396347046, 41995.025396347046, 41995.025396347046, 41995.025396347046, 41995.025396347046, 48392.106771469116, 48392.106771469116, 48392.106771469116, 48392.106771469116, 48392.106771469116, 48392.106771469116, 48392.106771469116, 48392.106771469116, 48392.106771469116, 48392.106771469116, 48392.106771469116, 48392.106771469116, 48392.106771469116, 53012.64810562134, 58643.399477005005, 58643.399477005005, 58643.399477005005, 58643.399477005005, 58643.399477005005, 58643.399477005005, 58643.399477005005, 58643.399477005005, 58643.399477005005, 58643.399477005005, 58643.399477005005, 67815.35458564758, 74386.21854782104, 74386.21854782104, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 77725.42977333069, 80888.89193534851, 80888.89193534851, 80888.89193534851, 83933.185338974, 83933.185338974, 83933.185338974, 83933.185338974, 83933.185338974, 83933.185338974, 83933.185338974, 83933.185338974, 83933.185338974, 83933.185338974, 86887.31646537781, 97258.71348381042, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 104410.573720932, 109081.03680610657, 112152.29654312134, 112152.29654312134, 114867.92945861816, 114867.92945861816, 114867.92945861816, 114867.92945861816, 114867.92945861816, 125798.41542243958, 125798.41542243958, 125798.41542243958, 125798.41542243958, 125798.41542243958, 125798.41542243958, 125798.41542243958, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 137193.3205127716, 140154.10923957825, 140154.10923957825, 140154.10923957825, 140154.10923957825, 140154.10923957825, 140154.10923957825, 140154.10923957825, 140154.10923957825, 154614.39156532288, 154614.39156532288, 154614.39156532288, 154614.39156532288, 154614.39156532288, 157545.3577041626, 168213.11974525452, 168213.11974525452, 168213.11974525452, 168213.11974525452, 168213.11974525452, 199498.98552894592, 199498.98552894592, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 204101.32575035095, 208354.61235046387, 208354.61235046387, 208354.61235046387, 210932.12008476257, 213317.86966323853, 213317.86966323853, 220578.27043533325, 220578.27043533325, 220578.27043533325, 220578.27043533325, 220578.27043533325, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 224450.3734111786, 231768.15915107727, 231768.15915107727, 231768.15915107727, 231768.15915107727, 231768.15915107727, 234247.00784683228, 234247.00784683228, 234247.00784683228, 242575.18482208252, 242575.18482208252, 242575.18482208252, 242575.18482208252, 242575.18482208252, 242575.18482208252, 242575.18482208252, 242575.18482208252, 242575.18482208252, 242575.18482208252, 245439.48316574097, 245439.48316574097, 245439.48316574097, 245439.48316574097, 245439.48316574097, 245439.48316574097, 245439.48316574097, 248038.23614120483, 258087.56637573242, 258087.56637573242, 258087.56637573242, 262484.1148853302, 262484.1148853302, 265648.0247974396, 265648.0247974396, 265648.0247974396, 265648.0247974396, 265648.0247974396, 265648.0247974396, 265648.0247974396, 265648.0247974396, 265648.0247974396, 265648.0247974396, 265648.0247974396, 265648.0247974396, 265648.0247974396, 270345.9289073944, 270345.9289073944, 270345.9289073944, 276121.1669445038, 276121.1669445038, 276121.1669445038, 276121.1669445038, 276121.1669445038, 276121.1669445038, 276121.1669445038, 276121.1669445038, 278934.2827796936, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 297118.75343322754, 300948.11034202576, 300948.11034202576, 300948.11034202576, 303958.42146873474, 303958.42146873474, 303958.42146873474, 303958.42146873474, 303958.42146873474, 303958.42146873474, 303958.42146873474, 303958.42146873474, 310969.17939186096, 310969.17939186096, 310969.17939186096, 310969.17939186096, 310969.17939186096, 313721.53091430664, 313721.53091430664, 317803.9360046387, 317803.9360046387, 317803.9360046387, 317803.9360046387, 317803.9360046387, 317803.9360046387, 317803.9360046387, 322819.02050971985, 322819.02050971985, 340501.0666847229, 340501.0666847229, 340501.0666847229, 340501.0666847229, 340501.0666847229, 340501.0666847229, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 348830.88755607605, 356151.20005607605, 356151.20005607605, 356151.20005607605, 356151.20005607605, 357759.80591773987, 357759.80591773987, 357759.80591773987, 357759.80591773987, 357759.80591773987, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 379766.9327259064, 387809.050321579, 387809.050321579, 387809.050321579, 387809.050321579, 387809.050321579, 390688.4455680847, 390688.4455680847, 390688.4455680847, 390688.4455680847, 396395.01214027405, 396395.01214027405, 396395.01214027405, 396395.01214027405, 396395.01214027405, 396395.01214027405, 396395.01214027405, 396395.01214027405, 399126.50513648987, 399126.50513648987, 399126.50513648987, 401777.5866985321, 401777.5866985321, 401777.5866985321, 407620.3098297119, 407620.3098297119, 407620.3098297119, 407620.3098297119, 407620.3098297119, 410657.66644477844, 410657.66644477844, 416276.7059803009, 426051.7134666443, 426051.7134666443, 429506.8187713623, 429506.8187713623, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 442908.7414741516, 445572.5464820862, 445572.5464820862, 445572.5464820862, 445572.5464820862, 445572.5464820862, 445572.5464820862, 450043.452501297, 450043.452501297, 450043.452501297, 450043.452501297, 457066.9615268707, 460026.89123153687, 460026.89123153687, 460026.89123153687, 466870.8276748657, 466870.8276748657, 466870.8276748657, 466870.8276748657, 466870.8276748657, 466870.8276748657, 466870.8276748657, 466870.8276748657, 466870.8276748657, 466870.8276748657, 469768.0022716522, 469768.0022716522, 469768.0022716522, 473044.3494319916, 473044.3494319916, 476393.99218559265, 476393.99218559265, 476393.99218559265, 479851.59945487976, 479851.59945487976, 479851.59945487976, 479851.59945487976, 479851.59945487976, 479851.59945487976, 479851.59945487976, 479851.59945487976, 479851.59945487976, 479851.59945487976, 479851.59945487976, 479851.59945487976, 482829.56767082214, 486020.57695388794, 486020.57695388794, 486020.57695388794, 488267.2793865204, 488267.2793865204, 488267.2793865204, 488267.2793865204, 499036.69905662537, 502157.3667526245, 502157.3667526245, 502157.3667526245, 502157.3667526245, 502157.3667526245, 507944.1227912903, 507944.1227912903, 512555.60755729675, 512555.60755729675, 512555.60755729675, 512555.60755729675, 512555.60755729675, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 514893.9483165741, 519503.03173065186, 525495.1066970825, 525495.1066970825, 525495.1066970825, 525495.1066970825, 525495.1066970825, 527180.547952652, 527180.547952652, 527180.547952652, 527180.547952652, 527180.547952652, 527180.547952652, 527180.547952652, 534678.3666610718, 537471.9886779785, 537471.9886779785, 537471.9886779785, 537471.9886779785, 537471.9886779785, 537471.9886779785, 537471.9886779785, 537471.9886779785, 537471.9886779785, 537471.9886779785, 537471.9886779785, 537471.9886779785, 537471.9886779785, 541205.9679031372, 541205.9679031372, 541205.9679031372, 546032.6502323151, 546032.6502323151, 546032.6502323151, 548574.3386745453, 548574.3386745453, 548574.3386745453, 553515.4929161072, 553515.4929161072, 553515.4929161072, 553515.4929161072, 553515.4929161072, 553515.4929161072, 553515.4929161072, 558663.8331413269, 558663.8331413269, 568717.066526413, 572423.3961105347, 576447.5340843201, 576447.5340843201, 576447.5340843201, 576447.5340843201, 576447.5340843201, 576447.5340843201, 576447.5340843201, 576447.5340843201, 576447.5340843201, 576447.5340843201, 576447.5340843201, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 579984.4350814819, 583212.0888233185, 583212.0888233185, 583212.0888233185, 583212.0888233185, 583212.0888233185, 586465.3458595276, 589030.5473804474, 589030.5473804474, 589030.5473804474, 589030.5473804474, 589030.5473804474, 589030.5473804474, 589030.5473804474, 589030.5473804474, 589030.5473804474, 589030.5473804474, 589030.5473804474, 589030.5473804474, 589030.5473804474, 593906.0325622559, 593906.0325622559, 593906.0325622559, 596841.2659168243, 596841.2659168243, 603112.8764152527, 603112.8764152527, 606583.019733429, 618267.1067714691, 618267.1067714691, 618267.1067714691, 618267.1067714691, 618267.1067714691, 618267.1067714691, 618267.1067714691, 618267.1067714691, 618267.1067714691, 618267.1067714691, 618267.1067714691, 618267.1067714691, 621414.8509502411, 621414.8509502411, 621414.8509502411, 621414.8509502411, 621414.8509502411, 621414.8509502411, 621414.8509502411, 621414.8509502411, 621414.8509502411, 621414.8509502411, 621414.8509502411, 621414.8509502411, 626201.7457485199, 626201.7457485199, 626201.7457485199, 626201.7457485199, 628879.2717456818, 628879.2717456818, 628879.2717456818, 628879.2717456818, 628879.2717456818, 628879.2717456818, 633169.6829795837, 633169.6829795837, 633169.6829795837, 633169.6829795837, 638086.9505405426, 638086.9505405426, 641021.4960575104, 641021.4960575104, 641021.4960575104, 641021.4960575104, 641021.4960575104, 641021.4960575104, 641021.4960575104, 646799.164056778, 646799.164056778, 646799.164056778, 646799.164056778, 650316.5106773376, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 653743.4203624725, 661645.0955867767, 664923.7439632416, 664923.7439632416, 664923.7439632416, 664923.7439632416, 664923.7439632416, 664923.7439632416, 664923.7439632416, 664923.7439632416, 664923.7439632416, 667692.4600601196, 667692.4600601196, 667692.4600601196, 670693.2837963104, 670693.2837963104, 670693.2837963104, 670693.2837963104, 673563.9388561249, 673563.9388561249, 673563.9388561249, 673563.9388561249, 676532.8831672668, 679724.4403362274, 683152.9266834259, 683152.9266834259, 683152.9266834259, 686675.8472919464, 686675.8472919464, 690393.7706947327, 690393.7706947327, 690393.7706947327, 690393.7706947327, 690393.7706947327, 690393.7706947327, 690393.7706947327, 690393.7706947327, 690393.7706947327, 693556.5540790558, 693556.5540790558, 693556.5540790558, 695573.0159282684, 695573.0159282684, 695573.0159282684, 695573.0159282684, 700707.263469696, 700707.263469696, 700707.263469696, 702287.8940105438, 702287.8940105438, 702287.8940105438, 702287.8940105438, 702287.8940105438, 718960.1566791534, 718960.1566791534, 718960.1566791534, 731437.3910427094, 745399.5189666748, 745399.5189666748, 745399.5189666748, 745399.5189666748, 745399.5189666748, 745399.5189666748, 745399.5189666748, 749685.2753162384, 753843.9910411835, 753843.9910411835, 753843.9910411835, 753843.9910411835, 753843.9910411835, 758042.7346229553, 758042.7346229553, 758042.7346229553, 758042.7346229553, 758042.7346229553, 758042.7346229553, 758042.7346229553, 758042.7346229553, 758042.7346229553, 758042.7346229553, 758042.7346229553, 758042.7346229553, 760463.0632400513, 760463.0632400513, 760463.0632400513, 760463.0632400513, 760463.0632400513, 760463.0632400513, 760463.0632400513, 760463.0632400513, 760463.0632400513, 768454.8668861389, 768454.8668861389, 768454.8668861389, 768454.8668861389, 768454.8668861389, 768454.8668861389, 768454.8668861389, 771247.0235824585, 771247.0235824585, 771247.0235824585, 773698.1477737427, 773698.1477737427, 773698.1477737427, 773698.1477737427, 773698.1477737427, 773698.1477737427, 773698.1477737427, 773698.1477737427, 780846.6863632202, 780846.6863632202, 780846.6863632202, 783504.3787956238, 783504.3787956238, 783504.3787956238, 783504.3787956238, 783504.3787956238, 783504.3787956238, 786269.9043750763, 787677.4854660034, 787677.4854660034, 787677.4854660034, 787677.4854660034, 787677.4854660034, 792412.7824306488, 792412.7824306488, 792412.7824306488, 793945.6613063812, 793945.6613063812, 793945.6613063812, 793945.6613063812, 793945.6613063812, 793945.6613063812, 793945.6613063812, 800405.6887626648, 800405.6887626648, 800405.6887626648, 800405.6887626648, 805370.3949451447, 805370.3949451447, 805370.3949451447, 810749.6891021729, 810749.6891021729, 810749.6891021729, 810749.6891021729, 813208.9586257935, 813208.9586257935, 813208.9586257935, 813208.9586257935, 813208.9586257935, 813208.9586257935, 813208.9586257935, 813208.9586257935, 817907.961845398, 817907.961845398, 817907.961845398, 817907.961845398, 817907.961845398, 820225.9604930878, 820225.9604930878, 820225.9604930878, 820225.9604930878, 820225.9604930878, 820225.9604930878, 820225.9604930878, 820225.9604930878, 827195.2042579651, 827195.2042579651, 827195.2042579651, 827195.2042579651, 827195.2042579651, 827195.2042579651, 827195.2042579651, 827195.2042579651, 827195.2042579651, 827195.2042579651, 827195.2042579651, 831896.5435028076, 831896.5435028076, 833512.7420425415, 833512.7420425415, 833512.7420425415, 833512.7420425415, 833512.7420425415, 833512.7420425415, 843322.9093551636, 843322.9093551636, 843322.9093551636, 843322.9093551636, 843322.9093551636, 843322.9093551636, 843322.9093551636, 843322.9093551636, 845995.9173202515, 845995.9173202515, 845995.9173202515, 845995.9173202515, 848731.4119338989, 848731.4119338989, 851921.87333107, 851921.87333107, 855374.3336200714, 855374.3336200714, 855374.3336200714, 855374.3336200714, 858818.8076019287, 858818.8076019287, 858818.8076019287, 858818.8076019287, 858818.8076019287, 858818.8076019287, 858818.8076019287, 858818.8076019287, 861046.9882488251, 861046.9882488251, 865751.4054775238, 865751.4054775238, 865751.4054775238, 865751.4054775238, 868341.0785198212, 868341.0785198212, 868341.0785198212, 868341.0785198212, 868341.0785198212, 868341.0785198212, 868341.0785198212, 868341.0785198212, 873299.8774051666, 873299.8774051666, 876121.6862201691, 876121.6862201691, 876121.6862201691, 879316.0209655762, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 893491.5242195129, 895272.6266384125, 895272.6266384125, 895272.6266384125, 895272.6266384125, 895272.6266384125, 895272.6266384125, 901892.4012184143, 901892.4012184143, 901892.4012184143, 901892.4012184143, 901892.4012184143, 901892.4012184143, 901892.4012184143, 901892.4012184143, 901892.4012184143, 909803.3049106598, 909803.3049106598, 909803.3049106598, 909803.3049106598, 909803.3049106598, 909803.3049106598, 909803.3049106598, 909803.3049106598, 909803.3049106598, 909803.3049106598, 909803.3049106598, 909803.3049106598, 909803.3049106598, 917259.8092556, 917259.8092556, 917259.8092556, 917259.8092556, 917259.8092556, 917259.8092556, 917259.8092556, 917259.8092556, 923217.2408103943, 923217.2408103943, 925755.6812763214, 925755.6812763214, 925755.6812763214, 927540.4727458954, 927540.4727458954, 927540.4727458954, 927540.4727458954, 927540.4727458954, 927540.4727458954, 927540.4727458954, 934957.1087360382, 934957.1087360382, 937530.2817821503, 937530.2817821503, 937530.2817821503, 937530.2817821503, 937530.2817821503, 937530.2817821503, 937530.2817821503, 937530.2817821503, 942329.9596309662, 945000.1282691956, 945000.1282691956, 945000.1282691956, 945000.1282691956, 950795.4750061035, 950795.4750061035, 950795.4750061035, 950795.4750061035, 953994.8673248291, 953994.8673248291, 953994.8673248291, 953994.8673248291, 953994.8673248291, 953994.8673248291, 953994.8673248291, 953994.8673248291, 953994.8673248291, 959762.951374054, 962974.7874736786, 962974.7874736786, 962974.7874736786, 962974.7874736786, 962974.7874736786, 962974.7874736786, 962974.7874736786, 965759.0801715851, 965759.0801715851, 972653.3353328705, 972653.3353328705, 972653.3353328705, 972653.3353328705, 972653.3353328705, 972653.3353328705, 972653.3353328705, 972653.3353328705, 972653.3353328705, 972653.3353328705, 972653.3353328705, 972653.3353328705, 980068.3279037476, 980068.3279037476, 982640.2821540833, 982640.2821540833, 982640.2821540833, 982640.2821540833, 982640.2821540833, 982640.2821540833, 982640.2821540833, 982640.2821540833, 982640.2821540833, 982640.2821540833, 986994.4424629211, 986994.4424629211, 997508.8160037994, 997508.8160037994, 1001121.8574047089, 1005006.9754123688, 1005006.9754123688, 1005006.9754123688, 1008587.8708362579, 1012349.7152328491, 1012349.7152328491, 1012349.7152328491, 1012349.7152328491, 1012349.7152328491, 1012349.7152328491, 1012349.7152328491, 1012349.7152328491, 1012349.7152328491, 1012349.7152328491, 1012349.7152328491, 1015848.2739925385, 1019712.0921611786, 1019712.0921611786, 1019712.0921611786, 1028265.6588554382, 1028265.6588554382, 1028265.6588554382, 1028265.6588554382, 1028265.6588554382, 1028265.6588554382, 1028265.6588554382, 1028265.6588554382, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1035214.9753570557, 1043000.2138614655, 1043000.2138614655, 1046146.894454956, 1046146.894454956, 1046146.894454956, 1046146.894454956, 1046146.894454956, 1046146.894454956, 1046146.894454956, 1046146.894454956, 1046146.894454956, 1047741.8327331543, 1047741.8327331543, 1047741.8327331543, 1047741.8327331543, 1047741.8327331543, 1047741.8327331543, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1061422.3279953003, 1066033.4882736206, 1066033.4882736206, 1071756.4487457275, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1075200.5486488342, 1079284.4088077545, 1079284.4088077545, 1079284.4088077545, 1079284.4088077545, 1079284.4088077545, 1079284.4088077545, 1079284.4088077545, 1084239.840745926, 1086966.2156105042, 1086966.2156105042, 1086966.2156105042, 1086966.2156105042, 1089810.3892803192, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1092323.1620788574, 1104747.3356723785, 1104747.3356723785, 1104747.3356723785, 1104747.3356723785, 1104747.3356723785, 1104747.3356723785, 1104747.3356723785, 1104747.3356723785, 1104747.3356723785, 1104747.3356723785, 1110837.2859954834, 1110837.2859954834, 1110837.2859954834, 1110837.2859954834, 1110837.2859954834, 1110837.2859954834, 1110837.2859954834, 1115622.5099563599, 1120215.348482132, 1120215.348482132, 1120215.348482132, 1120215.348482132, 1120215.348482132, 1120215.348482132, 1120215.348482132, 1120215.348482132, 1125042.120218277, 1125042.120218277, 1125042.120218277, 1125042.120218277, 1125042.120218277, 1127798.0370521545, 1129229.0425300598, 1129229.0425300598, 1129229.0425300598, 1129229.0425300598, 1129229.0425300598, 1129229.0425300598, 1129229.0425300598, 1129229.0425300598, 1134228.066444397, 1135679.3384552002, 1135679.3384552002, 1135679.3384552002, 1135679.3384552002, 1143633.5942745209, 1143633.5942745209, 1143633.5942745209, 1143633.5942745209, 1143633.5942745209, 1143633.5942745209, 1143633.5942745209, 1146379.8191547394, 1146379.8191547394, 1146379.8191547394, 1146379.8191547394, 1149590.200662613, 1149590.200662613, 1149590.200662613, 1154496.1297512054, 1154496.1297512054, 1154496.1297512054, 1154496.1297512054, 1154496.1297512054, 1154496.1297512054, 1154496.1297512054, 1154496.1297512054, 1159325.876235962, 1159325.876235962, 1159325.876235962, 1162451.6739845276, 1162451.6739845276, 1162451.6739845276, 1165118.225812912, 1165118.225812912, 1165118.225812912, 1165118.225812912, 1165118.225812912, 1167747.0710277557, 1170596.4848995209, 1170596.4848995209, 1170596.4848995209, 1170596.4848995209, 1173550.2858161926, 1173550.2858161926, 1173550.2858161926, 1173550.2858161926, 1179836.6463184357, 1182805.6585788727, 1182805.6585788727, 1182805.6585788727, 1182805.6585788727, 1182805.6585788727, 1182805.6585788727, 1182805.6585788727, 1187588.2894992828, 1187588.2894992828, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1193311.6810321808, 1199887.6657485962, 1199887.6657485962, 1199887.6657485962, 1199887.6657485962, 1199887.6657485962, 1204418.2043075562, 1205598.937511444, 1205598.937511444, 1205598.937511444, 1205598.937511444, 1205598.937511444, 1210692.7161216736, 1212224.7388362885, 1212224.7388362885, 1212224.7388362885, 1212224.7388362885, 1212224.7388362885, 1212224.7388362885, 1212224.7388362885, 1212224.7388362885, 1217321.3222026825, 1217321.3222026825, 1220094.4106578827, 1220094.4106578827, 1220094.4106578827, 1220094.4106578827, 1220094.4106578827, 1220094.4106578827, 1220094.4106578827, 1222880.1472187042, 1226576.1590003967, 1226576.1590003967, 1226576.1590003967, 1230262.511253357, 1230262.511253357, 1233958.744764328, 1233958.744764328, 1233958.744764328, 1233958.744764328, 1233958.744764328, 1233958.744764328, 1233958.744764328, 1233958.744764328, 1233958.744764328, 1233958.744764328, 1236822.672367096, 1239960.0591659546, 1239960.0591659546, 1239960.0591659546, 1246792.48046875, 1246792.48046875, 1246792.48046875, 1246792.48046875, 1246792.48046875, 1246792.48046875, 1246792.48046875, 1246792.48046875, 1250038.5103225708, 1250038.5103225708, 1250038.5103225708, 1253238.941192627, 1253238.941192627, 1253238.941192627, 1253238.941192627, 1253238.941192627, 1253238.941192627, 1253238.941192627, 1259308.123588562, 1262120.8696365356, 1262120.8696365356, 1262120.8696365356, 1264956.012248993, 1264956.012248993, 1264956.012248993, 1264956.012248993, 1264956.012248993, 1264956.012248993, 1264956.012248993, 1267804.1307926178, 1267804.1307926178, 1270564.4881725311, 1270564.4881725311, 1270564.4881725311, 1273519.3274021149, 1273519.3274021149, 1273519.3274021149, 1273519.3274021149, 1273519.3274021149, 1278524.8339176178, 1278524.8339176178, 1278524.8339176178, 1278524.8339176178, 1278524.8339176178, 1278524.8339176178, 1278524.8339176178, 1278524.8339176178, 1278524.8339176178, 1278524.8339176178, 1278524.8339176178, 1278524.8339176178, 1283219.8417186737, 1283219.8417186737, 1286295.8171367645, 1289491.3277626038, 1293283.5228443146, 1293283.5228443146, 1297610.3184223175, 1297610.3184223175, 1297610.3184223175, 1297610.3184223175, 1297610.3184223175, 1297610.3184223175, 1297610.3184223175, 1297610.3184223175, 1297610.3184223175, 1297610.3184223175, 1320233.075618744, 1325282.6228141785, 1325282.6228141785, 1325282.6228141785, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1333996.2639808655, 1337778.408050537, 1337778.408050537, 1337778.408050537, 1337778.408050537, 1337778.408050537, 1337778.408050537, 1342654.2992591858, 1345804.271697998, 1348152.0800590515, 1348152.0800590515, 1348152.0800590515, 1348152.0800590515, 1348152.0800590515, 1348152.0800590515, 1348152.0800590515, 1348152.0800590515, 1348152.0800590515, 1348152.0800590515, 1355916.3992404938, 1358359.591960907, 1358359.591960907, 1358359.591960907, 1361429.898738861, 1361429.898738861, 1364634.3908309937, 1364634.3908309937, 1364634.3908309937, 1364634.3908309937, 1364634.3908309937, 1364634.3908309937, 1367528.9969444275, 1367528.9969444275, 1367528.9969444275, 1367528.9969444275, 1367528.9969444275, 1367528.9969444275, 1370399.7690677643, 1370399.7690677643, 1373705.2042484283, 1373705.2042484283, 1373705.2042484283, 1377256.9453716278, 1377256.9453716278, 1377256.9453716278, 1377256.9453716278, 1377256.9453716278, 1380598.0608463287, 1380598.0608463287, 1380598.0608463287, 1380598.0608463287, 1383802.244901657, 1383802.244901657, 1386001.6725063324, 1386001.6725063324, 1390744.383573532, 1390744.383573532, 1390744.383573532, 1392105.6447029114, 1392105.6447029114, 1414528.2549858093, 1422147.400379181, 1422147.400379181, 1422147.400379181, 1425855.7024002075, 1425855.7024002075, 1429796.9179153442, 1429796.9179153442, 1429796.9179153442, 1429796.9179153442, 1429796.9179153442, 1429796.9179153442, 1429796.9179153442, 1429796.9179153442, 1429796.9179153442, 1429796.9179153442, 1429796.9179153442, 1432978.5597324371, 1432978.5597324371, 1432978.5597324371, 1432978.5597324371, 1432978.5597324371, 1432978.5597324371, 1432978.5597324371, 1432978.5597324371, 1432978.5597324371, 1432978.5597324371, 1432978.5597324371, 1437977.2033691406, 1441095.4220294952, 1441095.4220294952, 1441095.4220294952, 1441095.4220294952, 1441095.4220294952, 1441095.4220294952, 1441095.4220294952, 1441095.4220294952, 1441095.4220294952, 1443801.436662674, 1443801.436662674, 1443801.436662674, 1443801.436662674, 1450193.656206131, 1450193.656206131, 1450193.656206131, 1450193.656206131, 1450193.656206131, 1450193.656206131, 1450193.656206131, 1450193.656206131, 1450193.656206131, 1450193.656206131, 1452697.1015930176, 1452697.1015930176, 1452697.1015930176, 1452697.1015930176, 1457013.6978626251, 1457013.6978626251, 1457013.6978626251, 1464788.0899906158, 1464788.0899906158, 1464788.0899906158, 1464788.0899906158, 1464788.0899906158, 1464788.0899906158, 1466001.381635666, 1466001.381635666, 1470739.6471500397, 1470739.6471500397, 1472881.6001415253, 1472881.6001415253, 1472881.6001415253, 1472881.6001415253, 1472881.6001415253, 1472881.6001415253, 1472881.6001415253, 1472881.6001415253, 1477884.8028182983, 1477884.8028182983, 1477884.8028182983, 1485665.96865654, 1485665.96865654, 1485665.96865654, 1488754.8866271973, 1488754.8866271973, 1488754.8866271973, 1488754.8866271973, 1491784.6076488495, 1491784.6076488495, 1491784.6076488495, 1491784.6076488495, 1494371.4962005615, 1494371.4962005615, 1497464.504480362, 1497464.504480362, 1497464.504480362, 1500461.4613056183, 1500461.4613056183, 1500461.4613056183, 1503564.3742084503, 1503564.3742084503, 1503564.3742084503, 1506288.9342308044, 1506288.9342308044, 1506288.9342308044, 1506288.9342308044, 1506288.9342308044, 1511079.703092575, 1511079.703092575, 1511079.703092575, 1511079.703092575, 1511079.703092575, 1511079.703092575, 1511079.703092575, 1511079.703092575, 1511079.703092575, 1515729.832649231, 1515729.832649231, 1515729.832649231, 1515729.832649231, 1515729.832649231, 1520614.2811775208, 1523507.0478916168, 1523507.0478916168, 1529070.6813335419, 1529070.6813335419, 1529070.6813335419, 1529070.6813335419, 1529070.6813335419, 1529070.6813335419, 1529070.6813335419, 1529070.6813335419, 1529070.6813335419, 1529070.6813335419, 1529070.6813335419, 1533587.9564285278, 1536254.9035549164, 1536254.9035549164, 1536254.9035549164, 1536254.9035549164, 1536254.9035549164, 1545182.1999549866, 1548223.0412960052, 1548223.0412960052, 1548223.0412960052, 1548223.0412960052, 1548223.0412960052, 1548223.0412960052, 1551452.721118927, 1551452.721118927, 1551452.721118927, 1551452.721118927, 1551452.721118927, 1551452.721118927, 1554619.7135448456, 1554619.7135448456, 1554619.7135448456, 1554619.7135448456, 1554619.7135448456, 1554619.7135448456, 1554619.7135448456, 1557503.7596225739, 1557503.7596225739, 1557503.7596225739, 1560485.7416152954, 1560485.7416152954, 1560485.7416152954, 1560485.7416152954, 1563683.3801269531, 1563683.3801269531, 1565865.772485733, 1565865.772485733, 1565865.772485733, 1565865.772485733, 1565865.772485733, 1565865.772485733, 1565865.772485733], "prediction_length": 1709, "reference": "Hallo, hier ist Elena und ich stelle nun unsere Arbeit vor: Die Erkennung nicht-assimilierter Entlehnungen im Spanischen: Ein annotierter Korpus und Ansätze zur Modellierung. Wir werden uns also damit beschäftigen, was die lexikalische Entlehnung ist, die von uns vorgeschlagene Aufgabe, den veröffentlichten Datensatz und einige untersuchte Modelle. Doch zunächst einmal: Was ist die lexikalische Entlehnung und warum ist sie als NLP-Aufgabe so wichtig? Die lexikalische Entlehnung ist im Grunde die Übernahme von Wörtern aus einer Sprache in eine andere Sprache. Zum Beispiel verwenden wir im Spanischen Wörter, die aus dem Englischen stammen. Und hier ein paar Beispiele: Wörter wie Podcast, App und Online-Crowdfunding sind englische Wörter, die wir manchmal im Spanischen verwenden. Die lexikalische Entlehnung ist eine Art der sprachlichen Entlehnung, die im Grunde genommen die Reproduktion von Mustern einer Sprache in einer anderen Sprache bedeutet. Manchmal wurde die Entlehnung mit dem Code-Switching verglichen und als ein Kontinuum beschrieben. Code-Switching wird von Zweisprachigen praktiziert, wenn sie zwei Sprachen gleichzeitig verwenden. Es gibt jedoch einige Unterschiede zwischen lexikalischer Entlehnung und Code-Switching. Wir werden uns auf die lexikalische Entlehnung konzentrieren. Zweisprachige Personen praktizieren das sogenannte Code-Switching. Per Definition sind die Code-Switches nicht Teil der verwendeten Sprachen, während die lexikalische Entlehnung auch von einsprachigen Personen verwendet wird. Die Entlehnungen werden der Grammatik der Empfängersprache angepasst. Entlehnungen können Schritt für Schritt in die Empfängersprache integriert werden. Warum ist Entlehnen so ein interessantes Phänomen? Aus Sicht der Linguistik ist die Entlehnung eine Manifestation dessen, wie sich Sprachen verändern und wie sie interagieren. Auch lexikalische Entlehnungen sind eine Quelle für neue Wörter. Hier finden Sie einige Beispiele für lexikalische Entlehnungen, die als neue Wörter in die spanische Sprache aufgenommen wurden. Beim NLP sind Entlehnungen eine häufige Quelle von Wörtern, die nicht im Wortschatz enthalten sind. Die automatische Erkennung lexikalischer Entlehnungen erwies sich als nützlich für NLP und nachgelagerte Aufgaben wie Parsing, Text-zu-Sprache-Synthesen oder die maschinelle Übersetzung. Der Einfluss des Englischen auf andere Sprachen erfährt immer stärkeres Interesse, insbesondere bei englischen lexikalischen Entlehnungen. Diese werden manchmal auch als Anglizismen bezeichnet. Hier sind einige Beispiele von Arbeiten zur automatischen Erkennung von Entlehnungen in einigen dieser Sprachen. Die Aufgabe, die wir vorschlagen, besteht also darin, nicht-assimilierte lexikalische Entlehnungen in spanischen Nachrichten zu erkennen. Wir sind daran interessiert, aus anderen Sprachen entlehnte Wörter zu extrahieren, die in spanischen Zeitungen verwendet werden, aber nicht in die Empfängersprache integriert oder assimiliert wurden. Sie wurden also noch nicht ins Spanische integriert. Hier ist ein Beispiel. Dies ist ein Satz auf Spanisch: Las prendas bestsellers se estampan con motivos florales, animal print o retales tipo patchwork. Wie Sie sehen können, sind hier drei Textpassagen, die eigentlich englische Wörter sind: Bestseller, Animal Print und Patchwork. Bei diesen Passagen wollen wir extrahieren und erkennen. Es gab früher schon Arbeiten über die Erkennung von Anglizismen. Diese beschäftigten sich mit einem CRF-Modell für die Erkennung von Anglizismen in spanischen Nachrichten. Dieses Modell erreichte einen F1-Score von 86. Es gab jedoch einige Einschränkungen sowohl beim Datensatz als auch beim Modellierungsansatz. Der Datensatz konzentrierte sich also ausschließlich auf eine Quelle von den Nachrichten und bestand nur aus Schlagzeilen. Außerdem gab es Überschneidungen bei den Entlehnungen, die im Trainingssatz und im Testsatz vorkommen. Dadurch konnte nicht beurteilt werden, ob der Modellierungsansatz tatsächlich auf zuvor unbekannte Entlehnungen verallgemeinert werden kann. Unser Ziel ist es also, einige dieser Einschränkungen in der Aufgabe zu überwinden. Zu Beginn haben wir also einen neuen Datensatz erstellt. Das Ziel war ein neuer Datensatz, der mit lexikalischen Entlehnungen annotiert wurde, und einen möglichst schwierigen Testsatz zu erstellen. Es gäbe also minimale Überschneidungen bei Wörtern und Themen zwischen dem Trainingssatz und dem Testsatz. Das Ergebnis ist, dass der Testsatz aus Quellen und Daten stammt, die wir nicht im Trainingssatz sehen. Hier können Sie sehen, dass es keine Überschneidungen in der Zeit gibt. Außerdem enthält der Testsatz auch sehr viele Entlehnungen. Um Ihnen ein paar Zahlen zu nennen: Wenn der Trainingssatz sechs Entlehnungen pro 1000 Token enthält, enthält der Testsatz 20 Entlehnungen pro 1000 Token. Der Testsatz enthielt so viele Vokabelwörter wie möglich. Tatsächlich sind 92 Prozent der Entlehnungen im Testsatz OOV. Sie waren also während des Trainings nicht bekannt. Der Korpus bestand im Wesentlichen aus einer Sammlung von Texten, die aus verschiedenen Quellen spanischer Zeitungen stammten. Er wurde manuell mit zwei Tags annotiert. Einer für englische lexikalische Entlehnungen, die den Großteil der lexikalischen Entlehnungen im Spanischen ausmachen, und dann das andere Label für Entlehnungen aus anderen Sprachen. Wir verwenden CONLL-Formate und die BIO-Kodierung, sodass wir einfache Token-Entlehnungen wie „App“ oder mehrteilige Token-Entlehnungen wie „maschinelles Lernen“ kodieren können. Das sind die Nummern des Korpus. Wie Sie sehen können, handelt es sich um etwa 370 000 Token. Hier sehen Sie die Reihe an Passagen, die als Englisch markiert wurden, und die Passagen, die als andere Entlehnungen markiert waren, und wie viele davon einzigartig waren. Hier sehen Sie einige Beispiele für den Datensatz. Wie Sie zum Beispiel hier sehen können, haben wir im ersten Beispiel die Entlehnung „batch cooking“, die eine mehrteilige Wort-Entlehnung ist. Wir haben dieses Wort mit der BIO-Kodierung annotiert. BIO wurde also für Wörter im Spanischen verwendet, also nicht für Wörter, die nicht entlehnt wurden. Hier in diesem zweiten Beispiel sehen Sie „benching“ und „crash“, die ebenfalls als Entlehnungen aus dem Englischen markiert sind. Nachdem wir also den Datensatz hatten, untersuchten wir verschiedene Modelle für die Aufgabe, bei der wir lexikalische Entlehnungen extrahieren und erkennen wollten. Zuerst haben wir das bedingte Zufallsfeld Modell getestet. Das war das Modell, das bei früheren Arbeiten verwendet worden war. Wir haben die gleichen manuell erstellten Funktionen wie bei dieser Arbeit verwendet. Wie Sie sehen können, sind dies die Funktionen. Dies sind binäre Funktionen, wie das Wort oder das Token in Großbuchstaben. Handelt es sich um einen Titel? Ist es ein Anführungszeichen? Solche Dinge sind die Art von Funktionen, die man bei einer Named Entity Recognition-Aufgabe erwarten würde. Das sind die Ergebnisse, die wir erhalten haben. Wir erhalten 55 F1-Scores, wenn wir das CRF-Modell mit manuell erstellten Funktionen verwenden. Das ist ein großer Unterschied im Vergleich zum bereits berichteten F1-Score von 86, der ein Ergebnis desselben CRF-Modells mit derselben Funktionen war, aber auf einen anderen Datensatz angewendet wurde, auch für die Erkennung von spanischen lexikalischen Entlehnungen. Das beweist also, dass der Datensatz, den wir erstellt haben, schwieriger ist und dass wir anspruchsvollere Modelle für diese Aufgaben entwickeln müssen. Wir haben also zwei Transformer-basierte Modelle getestet. Wir haben BETO verwendet, ein einsprachiges BERT-Modell, das auf Spanisch trainiert ist, und auch ein mehrsprachiges BERT-Modell. Beide Modelle verwenden wir über die Transformer-Bibliothek von HuggingFace. Das sind die Ergebnisse, die wir erhalten haben. Wie Sie sehen können, schneidet das mehrsprachige BERT sowohl im Entwicklungssatz als auch im Testsatz und bei allen Metriken besser ab als BETO. Das CRF-Modell hat 82 erreicht, nur damit wir einen Vergleich ziehen können. Das CRF-Modell erreichte einen F1-Score von 55, während das mehrsprachige BERT 82 erreichte, was ein großer Unterschied ist. Nachdem wir also diese Ergebnisse hatten, stellten wir uns eine weitere Frage, nämlich: Können wir ein BiLSTM-CRF-Modell finden, verschiedene Arten von Einbettungen darin einspeisen, Einbettungen, die verschiedene Arten von sprachlichen Informationen kodieren, und die Ergebnisse von Transformer-basierten Modellen übertreffen? Dafür haben wir einige präliminäre Experimente durchgeführt, und zwar mit dem BiLSTM-CRF-Modell unter Verwendung von Flare Library. Wir haben mit verschiedenen Arten von Einbettungen experimentiert, z. B. mit Transformer-basierten, aber auch mit Schnell-Text-Einbettungen und Zeichen-Einbettungen. Wir haben herausgefunden, dass Transformer-basierte Einbettungen besser abschneiden als nicht kontextualisierte Einbettungen, dass die Kombination aus englischer BERT- und spanischer BETO-Einbettung besser ist als mehrsprachige BERT-Einbettungen. Auch ergeben die BPE-Einbettungen ein besseres F1 und die Zeicheneinbettungen ein besseres Recall. Vor diesem Hintergrund waren dies die besten Ergebnisse, die wir erzielen konnten. Beide Modelle waren BiLSTM-CRF-Modelle unter Verwendung von Flare. Bei einem wurden BETO- und BERT-Einbettungen und BPE eingespeist, beim anderen BETO- und BERT-Einbettungen und BPE sowie Zeichen-Einbettungen. Letzteres war dasjenige, das den höchste F1-Score beim Testsatz erzielte, obwohl der höchste Score beim Entwicklungssatz durch das Modell ohne Zeichen-Einbettungen erreicht wurde. Vergessen Sie nicht, dass das beste Ergebnis, das wir mit mehrsprachigem BERT erzielt haben, einen F1-Wert von 76 im Entwicklungssatz und 82 im Testsatz erreichte. Dies ist also eine Verbesserung im Vergleich zu diesen Ergebnissen. Schließlich stellten wir uns noch eine weitere Frage: Kann die Erkennung von lexikalischen Entlehnungen als Transferlernen von Sprachidentifikation beim Code-Switching formuliert werden? Wir haben also dasselbe BiLSTM-CRF-Modell wie mit Flare verwendet, aber anstelle dieser nicht angepassten Transformer-basierten BETO- und BERT-Einbettungen haben wir Code-Switch-Einbettungen verwendet. Was sind Code-Switch-Einbettungen? Dies sind Einbettungen, die auf Transformer-basierte Einbettungen abgestimmt wurden. Diese wurden für die Sprachidentifikation im Spanisch-Englisch-Abschnitt des LinCE-Code-Switching-Datensatzes vortrainiert. LinCE ist ein Datensatz vom Code-Switching, der einen Abschnitt mit Code-Switching von Spanisch und Englisch enthält. Wir speisten also Code-Switch-Einbettungen in unser BiLSTM-CRF ein. Optional können Zeicheneinbettungen, BPE-Einbettungen und so weiter eingefügt werden. Das beste Ergebnis, das wir erzielt haben, war 84,22. Das ist das beste Ergebnis aller Modelle, die wir mit dem Testsatz ausprobiert haben. Obwohl der beste F1-Score, den wir beim Entwicklungssatz erzielt haben, 97 war, war dieser niedriger als das beste Ergebnis vom BiLSTM-CRF, das mit unangepassten Einbettungen eingespeist war. Hier sind einige Schlussfolgerungen aus unserer Arbeit. Wir haben einen neuen Datensatz mit spanischen Nachrichten erstellt, der mit nicht assimilierten lexikalischen Entlehnungen annotiert ist. Dieser Datensatz ist dichter an Entlehnungen und OOV-reicher als frühere Ressourcen. Wir haben vier Arten von Modellen für die Erkennung lexikalischer Entlehnungen erforscht. Also. Was die Fehleranalyse betrifft, war der Recall ein Schwachpunkt bei allen Modellen. Wie Sie hier sehen können, gehören zu den häufigen falsch-negativen Ergebnissen beispielsweise auch Entlehnungen in Großbuchstaben und Wörter, die es sowohl im Englischen als auch im Spanischen gibt. Interessant ist auch, dass BPE-Einbettungen den F1-Core zu verbessern scheinen. Und die Einbettung von Zeichen scheint den Recall zu verbessern. Das ist eine interessante Erkenntnis, die wir vielleicht in künftigen Arbeiten untersuchen können. Also. Das wäre alles, was ich zu sagen habe. Vielen Dank fürs Zuhören.", "source": ["2/acl_6060/dev/full_wavs/2022.acl-long.268.wav", "samplerate: 16000 Hz", "channels: 1", "duration: 1e+01:17.440 min", "format: WAV (Microsoft) [WAV]", "subtype: Signed 16 bit PCM [PCM_16]"], "source_length": 731757.0}
{"index": 1, "prediction": "Mein Name ist Antoine. Ich bin Doktorand an der Universität von Massachusetts Amherst. Ich präsentiere unsere Zeitung. Kenya Berth, Morphologie, wie? Kenya Rwanda Language Model. Das ist ein sehr gutes Beispiel. Heute werde ich über die Motivation für diese Forschung sprechen. Dann präsentiere ich Kenyabereits Modellarchitektur im Detail. Ich werde dann über unsere experimentellen Ergebnisse reden. Dann schließen wir mit einigen Schlüssen. Wir wissen alle, dass die jüngste Fortschritte bei der Verarbeitung natürlicher Sprachen durch die Verwendung von prätrainierten Sprachmodellen wie BERT ermöglicht wurden. Aber es gibt eine Reihe von Limitationen. aufgrund der komplexen Morphologie, die von den meisten morphologisch reichen Sprachen ausgedrückt wird? Die Ubiquitas byte. Die al gorithmischen Tokenisierungsalgorithmen, die verwendet werden, können nicht die exakten Unter wortlexikaleinheiten extrahieren, die für die Effektivität der Morpheme benötigt werden. Repräsentation Zum Beispiel haben wir hier drei kinya-rwanda-Wörter. Das hat mehr Morphine in ihm. aber die B P Algorithmen können sie nicht extrahieren. Das ist, weil es morphologische Regeln gibt. produziert verschiedene Oberflächenformen, die die genauen lexikalischen Informationen verbergen. und B P E, die sich auf der Oberfläche der Formeln befindet, hat keinen Zugang zu diesem lexikalischen Modell. Die zweite Herausforderung ist, dass auch wenn man Zugang zu einem morphologischen Analyzer hat, die BPE-Token mit Morphemen zu ersetzen, nicht ausreicht, um die morphologische Kompositionalität auszudrücken. Ein dritter Gap in der Forschung ist, dass Neue , prät rained Language-Modelle sind meistens auf High-Resource-Sprachen evaluiert. und wir müssen ihre Anwendbarkeit auf Rohstoffe bewerten. und diverse Languages as well. Deshalb präsentieren wir Kenya Bird. die eine einfache, aber wirksame Anpassung der B ERT-Architektur ist, die morphologisch reiche Sprachen effektiver handhaben soll. Wir evaluieren Kenya B ells in Kenia Rwanda, eine Low -Resource morphologisch-reiche Sprache, die von mehr als zwölf Millionen Menschen in East und Central Africa gesprochen wird. Das ist der Eingang zu dem Modell. ist auch eine Satz oder ein Dokument. Hier haben wir zum Beispiel John , du warst ja ein sehr treuer Mensch, das bedeutet, wir waren überrascht, John da zu finden. Wie Sie sehen können, enthalten die kenianischen Wörter mehrere Morph eme, die unterschiedliche Informationen enthalten. Deshalb. In unserem Modell geben wir diesen Satz oder ein Dokument einem morphologischen Analyzer vor. Die dann Morpheme generiert, die in jedem der Wörter enthalten sind. Die Morpheme sind normalerweise made of a stem and zero or more affixes. Die Aff ixe können Z ehnter, Aspekt, Subjekt oder Objekt in Verbs und mehr oft in Bezug zu den Band-Namen angeben. Klasse für Subjekte und Objekte. Der morphologische Analyzer produziert auch ein Part-of-Speech-Tag für jedes der Wörter. Nach diesem Schritt Wir machen Embeddings für die Spee the for the part of speech tags. Imbedings für die Affixes. Und das ist für den Stamm. Das sind die mehr fragilisierbaren. Das ist die Morphologie-Ebene. Imbedings Wir übertragen diese Embeddings dann durch einen Morphologie-Enkoder, der ein kleiner Transformator-Enkoder ist , der unabhängig voneinander auf jede Welt angewendet wird. Die Aus gaben sind die Vektoren, die mit der morphologischen Information an jeder Seite kontextualisiert sind. Jetzt führen wir Kompositionen durch. wo die morphologischen Embeddings, die einem Teil der Sprache und dem Stamm entsprechen, zusammenkorrelieren. Wir werden sie weiter mit einem anderen Stamm in der Satzstufe kombinieren. dann bilden wir einen Input zu dem Main-Satz- oder Dokumentencoder. Die End-Ausgabe sind kontextualisierte Embeddings, die für Downstream-NLP-Aufgaben verwendet werden können. für einen morphologischen Analysator. Wir verwenden endliche , zweistufige Morphologie-Prinzipien mit einer benutzerdefinierten Implementierung, die der kenia-rwandischen Sprache zugeschrieben ist. Wir modellieren die Morphologie aller kinya-rwandischen Wörter, einschließlich der Verbal, Nomen, Demonstrative und Possessive Pronomen, Numerals und andere. Wir benutzen unüberwachte part of Speech tagging Algorithm. Ein First-Told-Up-Faktor-Modell wird verwendet, um Morphologie-Wahrscheinlichkeiten zu berücksichtigen. #ah, eigentlich die Wahrscheinlichkeit, die ist von der morphologischen Analyzer. Wir werden auch berücksichtigen, Die Part of Speech tags pre misses, wie auch die syntactic agreements, die vorhanden sind. in den Input-Wörtern. Der Part of Speech Tagger verwendet eine bidirektionale Inferenz. die die häufigsten VTB- Algorithmen für das Dekodieren verbessert. Ein paar Bemerkungen hier für Positionalschlüsselung. Der Morphologie-Enkoder verwendet keine Positionalschlüsselung , da jeder der Morpheme einen eigenen Slot im morphologischen Modell hat, daher ist die Position alschlüsselung inhärent, wenn die Morpheme gegeben werden. Zweite Der Satzencoder verwendet die sogenannten untiefen relativen Positionalschlüsselungen, die kürzlich in der I con Conference veröffentlicht wurden. Diese Positionalschlüsselungen ent ziehen die positionalen Korrelationen von Token-zu-Token-Aufmerksamkeit-Computation. Ähnlich wie bei Bert verwenden wir ein maskiertes Sprachmodell für das Vor-Training-Ziel. Wir müssen sowohl den Stamm als auch die Affixe vorhersagen , die mit den Wörtern assoziiert sind. während des Pretraining Fünfzehn Prozent aller Wörter werden für die Vorhersage in Betracht gezogen. von denen 80 % maskiert sind, 10 % mit zufälligen Worten geschickt und 10 % unverändert bleiben. Für eine Affix-Vorhersage Wir haben ein Multi-Label-Klassifikationsproblem. für this, we either group together affixes into a fixed number of sets and predict the set as a class label. Die andere Option ist, die affixed Probabilitätsvektoren zu vorhersagen. Wir evaluieren both of these approaches in our experiments. Wir haben Kenya Beret auf etwa 2,5 Gigabyte von Kinyarwanda Text und compare it to three baseline models. Einer ist ein multilinguales Modell, das als Excel bezeichnet wird. M R. Das ist ein Trained on a large text corpora. Das ist aus mehreren Sprachen gemacht. Die anderen beiden Bas eline sind auf demselben Text aus Kenia und Rwanda vorbereitet, wobei entweder ein BitPay-Encoder-Algorithmus oder oder morph ologische Analysen verwenden, ohne die Transformator-Architektur zu verwenden. Alle Modelle sind konfiguriert. in der B ese Architektur, die zwischen hundert und hundert und zehn Millionen Parameter mit Kenya Rwanda mit Kenya Bite verwendet, die geringste Anzahl von Parameter. Alle Modelle , außer der mehrsprach ige, sind für 32000 Gradient-Updates vorbereitet. mit der Batch-Size von zwei tausend fünfhundert und sechzig Sequenzen. in jeder Batch. Wir bewerten die prätrainierten Modelle auf drei Set of tasks, one is the group benchmark, die für die Auswertung der Effektivität von Pre-trained Language Models verwendet wurde. Wir haben unsere Blue Benchmark erhalten. Daten , indem wir die ursprünglichen Benchmark-Daten in Kenia, Rwanda, using Google Translate, übersetzen. Die zweite Aufgabe ist Kenya Rwanda Named Identity Recognition Benchmark. Das ist ein hochwertiger Datensatz, der von trainierten Native Speakers annotiert wurde. Der dritte... ist die News Kategorierung task. wo wir Newsartikel von mehreren Websites ziehen und ihre Kategor isierungstags korrigieren, die von den Autoren unterschrieben wurden , und dann im Wesentlichen versuchen, das Gleiche zu vorhersagen. Das sind die gleichen Kategorien. Und jetzt gehen wir zu den Ergebnissen. für die Gluebenchmark Wir finden, dass Kenya Belt konsequent Baseline-Modelle übertrifft. Hier sehen wir die durchschnitt liche Leistung für ten fine tuning runs. Wir führen auch eine User-E valuation der Übersetzungen durch Google Translate durch. Es ist nicht so, dass die Nutzer etwa sechstausend Beispiele bewertet haben, indem sie Scores auf einer Skala von 1 bis 4 zugewiesen haben. die Qualität der Transaktionen. Das Ergebnis ist, dass viele Translationen laut sind. Aber alle Mod elle mussten mit dem selben Translation Noise coppiert werden, und die relative Performance zwischen den Modellen ist immer noch wichtig zu bemerken. für die Namensdentizitätserkennung. Wir finden auch, dass König Berth mit der Bestleistung , mit der Best leistung der Affinity Distribution Regulation Variant, sind diese Ergebnisse auch Durchschnittswerte von zehn Fin tuning runs. für die News-Kategorifizierung Wir finden gemischte Ergebnisse , vorherige War-Kontext-Klassifikationen für Kenia und Rwanda haben ergeben, dass die simple Keyword-Detektion ist mostly enough for solving this specific task, therefore there is Leise von using Pretraying Language Models. auf dieser besonderen Aufgabe der Kategoriisierung von Nachrichten. Wir haben auch eine Ablationstheorie durchgeführt, um zu sehen, ob es alternative Strukturen gibt, die die Leistung verbessern. für die Group Benchmark finden wir, dass wir verwenden Affix-Sets. Konsequenz volles Performance besser, wenn wir die Probabilität der Erstellung der Bestleistung der Besten Performance der Besten Recognition. Oder so. Durch das Aussehen der Lose Curves für die Feintuning finden wir, dass Knyabert eine bessere Konvergenz hat. in den meisten Fällen. So zu dem Schluss, dass diese Arbeit die Wirksamkeit der expliziten Verwendung morphologischer Informationen in prä- trainierten Sprachmodellen demonstriert hat. Ermöglicht die morphologische Erfassung von C. die morphologische Kompositionalität erfasst, was ein wichtiger Aspekt von morphologisch reichen Sprachen ist. Diese Ergebnisse sollten weitere Forschungsinitiativen fördern. In Morphologie haben wir Language Pre-Traded Language Models.", "delays": [2750.0, 2750.0, 2750.0, 2750.0, 5500.0, 5500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 6500.0, 8750.0, 8750.0, 8750.0, 8750.0, 11000.0, 11000.0, 11000.0, 11000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 13000.0, 16000.0, 17500.0, 17500.0, 17500.0, 17500.0, 17500.0, 19000.0, 19000.0, 19000.0, 19000.0, 20500.0, 20500.0, 20500.0, 21000.0, 21000.0, 21000.0, 21000.0, 23750.0, 23750.0, 23750.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 26500.0, 26500.0, 26500.0, 26500.0, 26500.0, 26500.0, 31250.0, 32750.0, 32750.0, 32750.0, 32750.0, 32750.0, 34250.0, 34250.0, 34250.0, 34250.0, 34250.0, 34250.0, 37250.0, 37250.0, 37250.0, 37250.0, 38750.0, 38750.0, 38750.0, 38750.0, 38750.0, 38750.0, 41500.0, 41750.0, 41750.0, 41750.0, 41750.0, 41750.0, 41750.0, 46000.0, 46000.0, 46000.0, 46000.0, 47500.0, 47500.0, 47500.0, 47500.0, 47750.0, 47750.0, 47750.0, 47750.0, 47750.0, 50000.0, 50000.0, 50000.0, 55750.0, 55750.0, 58750.0, 58750.0, 58750.0, 58750.0, 58750.0, 58750.0, 58750.0, 58750.0, 60000.0, 60000.0, 61000.0, 61000.0, 61000.0, 61000.0, 61000.0, 61000.0, 61000.0, 61000.0, 61000.0, 61000.0, 63000.0, 67000.0, 67000.0, 67000.0, 67000.0, 67000.0, 67000.0, 67000.0, 69250.0, 69250.0, 69250.0, 69250.0, 69250.0, 69250.0, 72750.0, 72750.0, 72750.0, 72750.0, 72750.0, 72750.0, 72750.0, 72750.0, 72750.0, 75500.0, 75500.0, 75500.0, 76000.0, 76000.0, 76000.0, 76000.0, 78750.0, 78750.0, 80000.0, 81500.0, 81500.0, 81750.0, 81750.0, 81750.0, 81750.0, 84500.0, 84500.0, 84500.0, 84500.0, 84500.0, 88250.0, 88250.0, 88250.0, 88250.0, 88250.0, 88250.0, 88250.0, 88250.0, 88250.0, 88250.0, 88250.0, 88250.0, 88250.0, 88250.0, 93000.0, 93000.0, 93000.0, 93000.0, 93000.0, 94500.0, 94500.0, 94500.0, 94500.0, 94500.0, 96000.0, 97500.0, 97500.0, 100500.0, 100500.0, 100500.0, 100500.0, 100500.0, 100500.0, 100500.0, 102000.0, 102250.0, 102250.0, 102250.0, 102250.0, 102250.0, 102250.0, 105000.0, 105000.0, 105500.0, 105500.0, 105500.0, 105500.0, 105500.0, 105500.0, 108000.0, 109500.0, 109500.0, 111000.0, 111000.0, 111000.0, 111000.0, 111000.0, 111000.0, 111000.0, 114750.0, 114750.0, 114750.0, 114750.0, 114750.0, 114750.0, 114750.0, 114750.0, 116750.0, 116750.0, 116750.0, 116750.0, 116750.0, 120250.0, 120250.0, 120250.0, 120250.0, 120250.0, 124500.0, 124500.0, 124500.0, 124500.0, 124500.0, 124500.0, 126000.0, 126000.0, 127500.0, 127500.0, 129000.0, 130000.0, 130000.0, 130000.0, 130000.0, 130000.0, 130000.0, 132750.0, 132750.0, 132750.0, 134250.0, 138750.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 141500.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 148500.0, 148500.0, 148500.0, 148500.0, 148500.0, 148500.0, 148500.0, 151000.0, 151000.0, 151000.0, 151000.0, 151000.0, 151000.0, 151000.0, 153750.0, 153750.0, 153750.0, 153750.0, 153750.0, 156500.0, 158000.0, 159500.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 159750.0, 164000.0, 164000.0, 164000.0, 164000.0, 165500.0, 165500.0, 165500.0, 165500.0, 165500.0, 165500.0, 167000.0, 167000.0, 167000.0, 167000.0, 167000.0, 169500.0, 174000.0, 174000.0, 174000.0, 175500.0, 175500.0, 175500.0, 175500.0, 175500.0, 175500.0, 175500.0, 176000.0, 176000.0, 176000.0, 176000.0, 181750.0, 181750.0, 181750.0, 181750.0, 181750.0, 181750.0, 181750.0, 181750.0, 181750.0, 181750.0, 181750.0, 184500.0, 184500.0, 186000.0, 187000.0, 187000.0, 187000.0, 187000.0, 187000.0, 187000.0, 187000.0, 187000.0, 187000.0, 187000.0, 190000.0, 190000.0, 191500.0, 191500.0, 194500.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 199250.0, 199250.0, 199250.0, 199250.0, 199250.0, 204000.0, 204000.0, 204000.0, 205500.0, 205500.0, 207000.0, 207000.0, 207000.0, 207000.0, 207000.0, 207000.0, 209250.0, 209250.0, 209250.0, 212000.0, 212000.0, 213500.0, 213500.0, 213500.0, 213500.0, 213500.0, 213500.0, 213500.0, 213500.0, 213500.0, 213500.0, 213500.0, 218250.0, 218250.0, 218250.0, 218250.0, 221500.0, 221500.0, 221500.0, 221500.0, 221500.0, 221500.0, 224000.0, 224250.0, 224250.0, 224250.0, 224250.0, 226500.0, 226500.0, 226500.0, 226500.0, 228750.0, 233000.0, 237500.0, 237500.0, 237500.0, 237500.0, 237500.0, 237500.0, 237500.0, 237500.0, 237500.0, 237500.0, 237500.0, 237500.0, 239000.0, 239000.0, 239000.0, 239000.0, 239000.0, 239000.0, 239000.0, 239000.0, 239000.0, 243750.0, 243750.0, 246750.0, 246750.0, 246750.0, 246750.0, 246750.0, 246750.0, 246750.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 250750.0, 251250.0, 251250.0, 251250.0, 251250.0, 255500.0, 255500.0, 255500.0, 257750.0, 257750.0, 257750.0, 257750.0, 257750.0, 257750.0, 257750.0, 257750.0, 257750.0, 257750.0, 257750.0, 262000.0, 263500.0, 263500.0, 263500.0, 264500.0, 264500.0, 264500.0, 264500.0, 264500.0, 264500.0, 264500.0, 264500.0, 268750.0, 269750.0, 269750.0, 269750.0, 269750.0, 269750.0, 269750.0, 269750.0, 269750.0, 269750.0, 274250.0, 275750.0, 277250.0, 277250.0, 277250.0, 277250.0, 277250.0, 277750.0, 277750.0, 277750.0, 277750.0, 281250.0, 281250.0, 281250.0, 281250.0, 284000.0, 285500.0, 285500.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 293000.0, 294500.0, 297500.0, 297500.0, 297500.0, 297500.0, 297500.0, 297500.0, 297500.0, 301750.0, 301750.0, 301750.0, 301750.0, 301750.0, 301750.0, 301750.0, 301750.0, 301750.0, 304000.0, 304000.0, 304000.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 311750.0, 311750.0, 311750.0, 311750.0, 311750.0, 311750.0, 311750.0, 311750.0, 314500.0, 316000.0, 316500.0, 316500.0, 316500.0, 316500.0, 316500.0, 316500.0, 316500.0, 316500.0, 319250.0, 319250.0, 319250.0, 319250.0, 322000.0, 322000.0, 322000.0, 322000.0, 323500.0, 323500.0, 324750.0, 324750.0, 324750.0, 324750.0, 324750.0, 324750.0, 324750.0, 324750.0, 324750.0, 327500.0, 327500.0, 327500.0, 332000.0, 332000.0, 332000.0, 332000.0, 333250.0, 333250.0, 333250.0, 333250.0, 333250.0, 337500.0, 337500.0, 339000.0, 339000.0, 339500.0, 339500.0, 339500.0, 339500.0, 339500.0, 344500.0, 344500.0, 344500.0, 344500.0, 344500.0, 344500.0, 351750.0, 351750.0, 351750.0, 351750.0, 351750.0, 353250.0, 353250.0, 353250.0, 353250.0, 353250.0, 354750.0, 354750.0, 357500.0, 357500.0, 357500.0, 357500.0, 359000.0, 359000.0, 359000.0, 359000.0, 359000.0, 359750.0, 359750.0, 359750.0, 359750.0, 359750.0, 359750.0, 359750.0, 361750.0, 366000.0, 366000.0, 367500.0, 367500.0, 370500.0, 370500.0, 370500.0, 370500.0, 370500.0, 372000.0, 375000.0, 375000.0, 375000.0, 376500.0, 376500.0, 376500.0, 376500.0, 376500.0, 376500.0, 378000.0, 379000.0, 379000.0, 379000.0, 379000.0, 379000.0, 379000.0, 385250.0, 385250.0, 385250.0, 385250.0, 385250.0, 385250.0, 386000.0, 386000.0, 386000.0, 386000.0, 386000.0, 386000.0, 388750.0, 390250.0, 390250.0, 391750.0, 391750.0, 391750.0, 391750.0, 391750.0, 391750.0, 391750.0, 392250.0, 392250.0, 392250.0, 392250.0, 392250.0, 392250.0, 392250.0, 394250.0, 394250.0, 394250.0, 398750.0, 398750.0, 398750.0, 398750.0, 398750.0, 398750.0, 398750.0, 398750.0, 398750.0, 398750.0, 398750.0, 401500.0, 401500.0, 401500.0, 401500.0, 403000.0, 403000.0, 403000.0, 403000.0, 404500.0, 404500.0, 404500.0, 404500.0, 405250.0, 405250.0, 405250.0, 405250.0, 405250.0, 408000.0, 408000.0, 408000.0, 410750.0, 410750.0, 410750.0, 410750.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 422750.0, 422750.0, 422750.0, 424000.0, 424000.0, 424500.0, 424500.0, 424500.0, 424500.0, 427250.0, 428750.0, 429000.0, 429000.0, 429000.0, 429000.0, 429000.0, 429000.0, 429000.0, 433750.0, 435250.0, 435250.0, 435250.0, 435250.0, 436750.0, 436750.0, 436750.0, 439750.0, 439750.0, 439750.0, 439750.0, 439750.0, 439750.0, 439750.0, 439750.0, 439750.0, 439750.0, 443250.0, 443250.0, 443250.0, 443250.0, 443250.0, 443250.0, 443250.0, 443250.0, 443250.0, 443250.0, 447500.0, 447500.0, 447500.0, 447500.0, 448750.0, 448750.0, 448750.0, 448750.0, 448750.0, 448750.0, 448750.0, 451000.0, 451000.0, 451000.0, 451000.0, 451000.0, 451000.0, 454000.0, 454000.0, 455500.0, 455500.0, 457000.0, 457000.0, 457000.0, 457000.0, 458500.0, 458500.0, 458500.0, 458500.0, 458500.0, 458500.0, 458500.0, 458500.0, 458500.0, 458500.0, 458500.0, 461250.0, 461250.0, 462750.0, 462750.0, 464000.0, 464000.0, 464000.0, 464750.0, 464750.0, 464750.0, 468000.0, 468000.0, 468000.0, 468000.0, 470750.0, 470750.0, 472000.0, 473500.0, 473500.0, 473500.0, 473500.0, 473500.0, 473500.0, 475000.0, 475000.0, 475000.0, 475000.0, 475000.0, 476500.0, 476500.0, 476500.0, 478000.0, 478000.0, 478000.0, 479250.0, 479250.0, 479250.0, 479250.0, 479250.0, 479250.0, 482000.0, 482000.0, 483500.0, 483500.0, 483500.0, 483500.0, 485000.0, 485000.0, 485000.0, 486250.0, 486250.0, 486250.0, 489000.0, 489000.0, 489000.0, 489000.0, 489000.0, 490250.0, 490250.0, 490250.0, 490250.0, 490250.0, 492500.0, 492500.0, 492500.0, 495250.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 500000.0, 501500.0, 503000.0, 503000.0, 503000.0, 503000.0, 503000.0, 503000.0, 503000.0, 503000.0, 503000.0, 503000.0, 504500.0, 504500.0, 504500.0, 504500.0, 504500.0, 504500.0, 504500.0, 504500.0, 507250.0, 507250.0, 507750.0, 507750.0, 507750.0, 507750.0, 512000.0, 513500.0, 513500.0, 513500.0, 513500.0, 513500.0, 513500.0, 513500.0, 514500.0, 514500.0, 514500.0, 514500.0, 514500.0, 514500.0, 518750.0, 518750.0, 518750.0, 518750.0, 519750.0, 519750.0, 519750.0, 519750.0, 519750.0, 519750.0, 522500.0, 522500.0, 524000.0, 525500.0, 525500.0, 525500.0, 525500.0, 525500.0, 525500.0, 525500.0, 525500.0, 525500.0, 527500.0, 527500.0, 530000.0, 530000.0, 530000.0, 530000.0, 530000.0, 534250.0, 534250.0, 534250.0, 534250.0, 534250.0, 535750.0, 537250.0, 537250.0, 537250.0, 537250.0, 538750.0, 538750.0, 538750.0, 538750.0, 540000.0, 540000.0, 540000.0, 540000.0, 541000.0, 541000.0, 541000.0, 541000.0, 541000.0, 541000.0, 541000.0, 541000.0, 541000.0, 541000.0, 543250.0, 543250.0, 543250.0, 543250.0, 543250.0, 548250.0, 548250.0, 548250.0, 548250.0, 548250.0, 548250.0, 548250.0, 550500.0, 550500.0, 550500.0, 553500.0, 553500.0, 553500.0, 553500.0, 555250.0, 555250.0, 555250.0, 555250.0, 558000.0, 558000.0, 558000.0, 558000.0, 558000.0, 559250.0, 559250.0, 559250.0, 559250.0, 559250.0, 559250.0, 559250.0, 562000.0, 565000.0, 565000.0, 565000.0, 565000.0, 565500.0, 565500.0, 565500.0, 565500.0, 565500.0, 565500.0, 565500.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 572500.0, 572500.0, 572500.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 574250.0, 577000.0, 577000.0, 577000.0, 577000.0, 580750.0, 580750.0, 580750.0, 580750.0, 580750.0, 580750.0, 580750.0, 580750.0, 587500.0, 587500.0, 587500.0, 589000.0, 589000.0, 589000.0, 589000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 595500.0, 595500.0, 595500.0, 597750.0, 597750.0, 597750.0, 597750.0, 597750.0, 597750.0, 602000.0, 602000.0, 602000.0, 605000.0, 605000.0, 605000.0, 606500.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 611750.0, 611750.0, 611750.0, 614500.0, 614500.0, 622000.0, 622000.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 623500.0, 626250.0, 626500.0, 626500.0, 626500.0, 626500.0, 626500.0, 630750.0, 630750.0, 630750.0, 630750.0, 630750.0, 630750.0, 630750.0, 630750.0, 634000.0, 634000.0, 635500.0, 635500.0, 637000.0, 637000.0, 638500.0, 638500.0, 638500.0, 638500.0, 638500.0, 639500.0, 639500.0, 639500.0, 639500.0, 639500.0, 639500.0, 639500.0, 642250.0, 642250.0, 643250.0, 643250.0, 643250.0, 643250.0, 643250.0, 643250.0, 643250.0, 643250.0, 646000.0, 650500.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 654000.0, 654000.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 662500.0, 662500.0, 662500.0, 662500.0, 665500.0, 665500.0, 667000.0, 667000.0, 668500.0, 668500.0, 668500.0, 668500.0, 668500.0, 668500.0, 670000.0, 670000.0, 671500.0, 671500.0, 673000.0, 673000.0, 674500.0, 674500.0, 674500.0, 674500.0, 679250.0, 679250.0, 679250.0, 679250.0, 679250.0, 679250.0, 685000.0, 686500.0, 686500.0, 686500.0, 686500.0, 686500.0, 686500.0, 686500.0, 686500.0, 688000.0, 688000.0, 688000.0, 688000.0, 689500.0, 690250.0, 690250.0, 690250.0, 690250.0, 690250.0, 693000.0, 693000.0, 693000.0, 693000.0, 694500.0, 694750.0, 694750.0, 694750.0], "elapsed": [4349.174976348877, 4349.174976348877, 4349.174976348877, 4349.174976348877, 9452.651500701904, 9452.651500701904, 11461.278438568115, 11461.278438568115, 11461.278438568115, 11461.278438568115, 11461.278438568115, 11461.278438568115, 11461.278438568115, 15321.175575256348, 15321.175575256348, 15321.175575256348, 15321.175575256348, 19636.35277748108, 19636.35277748108, 19636.35277748108, 19636.35277748108, 23620.157957077026, 23620.157957077026, 23620.157957077026, 23620.157957077026, 23620.157957077026, 23620.157957077026, 23620.157957077026, 23620.157957077026, 23620.157957077026, 23620.157957077026, 28278.43475341797, 30906.423568725586, 30906.423568725586, 30906.423568725586, 30906.423568725586, 30906.423568725586, 33607.18536376953, 33607.18536376953, 33607.18536376953, 33607.18536376953, 36376.023054122925, 36376.023054122925, 36376.023054122925, 38093.07885169983, 38093.07885169983, 38093.07885169983, 38093.07885169983, 42766.08753204346, 42766.08753204346, 42766.08753204346, 43906.46743774414, 43906.46743774414, 43906.46743774414, 43906.46743774414, 43906.46743774414, 48344.92373466492, 48344.92373466492, 48344.92373466492, 48344.92373466492, 48344.92373466492, 48344.92373466492, 54894.79327201843, 57797.19352722168, 57797.19352722168, 57797.19352722168, 57797.19352722168, 57797.19352722168, 60411.89694404602, 60411.89694404602, 60411.89694404602, 60411.89694404602, 60411.89694404602, 60411.89694404602, 65781.53228759766, 65781.53228759766, 65781.53228759766, 65781.53228759766, 68787.348985672, 68787.348985672, 68787.348985672, 68787.348985672, 68787.348985672, 68787.348985672, 73484.121799469, 74711.32564544678, 74711.32564544678, 74711.32564544678, 74711.32564544678, 74711.32564544678, 74711.32564544678, 82407.60207176208, 82407.60207176208, 82407.60207176208, 82407.60207176208, 85344.52414512634, 85344.52414512634, 85344.52414512634, 85344.52414512634, 86816.31469726562, 86816.31469726562, 86816.31469726562, 86816.31469726562, 86816.31469726562, 90966.59231185913, 90966.59231185913, 90966.59231185913, 101845.84140777588, 101845.84140777588, 109891.32118225098, 109891.32118225098, 109891.32118225098, 109891.32118225098, 109891.32118225098, 109891.32118225098, 109891.32118225098, 109891.32118225098, 112933.42590332031, 112933.42590332031, 115806.34689331055, 115806.34689331055, 115806.34689331055, 115806.34689331055, 115806.34689331055, 115806.34689331055, 115806.34689331055, 115806.34689331055, 115806.34689331055, 115806.34689331055, 119327.71110534668, 126350.19373893738, 126350.19373893738, 126350.19373893738, 126350.19373893738, 126350.19373893738, 126350.19373893738, 126350.19373893738, 130445.04523277283, 130445.04523277283, 130445.04523277283, 130445.04523277283, 130445.04523277283, 130445.04523277283, 137388.8921737671, 137388.8921737671, 137388.8921737671, 137388.8921737671, 137388.8921737671, 137388.8921737671, 137388.8921737671, 137388.8921737671, 137388.8921737671, 141997.69926071167, 141997.69926071167, 141997.69926071167, 143393.54491233826, 143393.54491233826, 143393.54491233826, 143393.54491233826, 147837.24236488342, 147837.24236488342, 150126.21760368347, 152822.44634628296, 152822.44634628296, 154145.5159187317, 154145.5159187317, 154145.5159187317, 154145.5159187317, 158997.73740768433, 158997.73740768433, 158997.73740768433, 158997.73740768433, 158997.73740768433, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 167343.0986404419, 175102.55002975464, 175102.55002975464, 175102.55002975464, 175102.55002975464, 175102.55002975464, 177935.83869934082, 177935.83869934082, 177935.83869934082, 177935.83869934082, 177935.83869934082, 180777.90880203247, 183651.9718170166, 183651.9718170166, 190045.51601409912, 190045.51601409912, 190045.51601409912, 190045.51601409912, 190045.51601409912, 190045.51601409912, 190045.51601409912, 193346.839427948, 195323.96411895752, 195323.96411895752, 195323.96411895752, 195323.96411895752, 195323.96411895752, 195323.96411895752, 200066.05577468872, 200066.05577468872, 201505.8627128601, 201505.8627128601, 201505.8627128601, 201505.8627128601, 201505.8627128601, 201505.8627128601, 206174.10826683044, 209056.7421913147, 209056.7421913147, 212235.94856262207, 212235.94856262207, 212235.94856262207, 212235.94856262207, 212235.94856262207, 212235.94856262207, 212235.94856262207, 218948.77529144287, 218948.77529144287, 218948.77529144287, 218948.77529144287, 218948.77529144287, 218948.77529144287, 218948.77529144287, 218948.77529144287, 222636.873960495, 222636.873960495, 222636.873960495, 222636.873960495, 222636.873960495, 228829.6718597412, 228829.6718597412, 228829.6718597412, 228829.6718597412, 228829.6718597412, 236733.72888565063, 236733.72888565063, 236733.72888565063, 236733.72888565063, 236733.72888565063, 236733.72888565063, 239304.25357818604, 239304.25357818604, 242024.38306808472, 242024.38306808472, 245185.17446517944, 247692.25573539734, 247692.25573539734, 247692.25573539734, 247692.25573539734, 247692.25573539734, 247692.25573539734, 252434.00382995605, 252434.00382995605, 252434.00382995605, 254891.66259765625, 264428.1404018402, 268177.1786212921, 268177.1786212921, 268177.1786212921, 268177.1786212921, 268177.1786212921, 271895.7619667053, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 274143.985748291, 282863.6403083801, 282863.6403083801, 282863.6403083801, 282863.6403083801, 282863.6403083801, 282863.6403083801, 282863.6403083801, 287194.5004463196, 287194.5004463196, 287194.5004463196, 287194.5004463196, 287194.5004463196, 287194.5004463196, 287194.5004463196, 291537.9033088684, 291537.9033088684, 291537.9033088684, 291537.9033088684, 291537.9033088684, 296188.54451179504, 298993.9384460449, 302271.1822986603, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 304145.74456214905, 311662.39953041077, 311662.39953041077, 311662.39953041077, 311662.39953041077, 314532.0339202881, 314532.0339202881, 314532.0339202881, 314532.0339202881, 314532.0339202881, 314532.0339202881, 317113.1203174591, 317113.1203174591, 317113.1203174591, 317113.1203174591, 317113.1203174591, 321109.40647125244, 328613.1942272186, 328613.1942272186, 328613.1942272186, 331493.3922290802, 331493.3922290802, 331493.3922290802, 331493.3922290802, 331493.3922290802, 331493.3922290802, 331493.3922290802, 333042.85287857056, 333042.85287857056, 333042.85287857056, 333042.85287857056, 343366.361618042, 343366.361618042, 343366.361618042, 343366.361618042, 343366.361618042, 343366.361618042, 343366.361618042, 343366.361618042, 343366.361618042, 343366.361618042, 343366.361618042, 347899.22428131104, 347899.22428131104, 350665.4188632965, 352845.2754020691, 352845.2754020691, 352845.2754020691, 352845.2754020691, 352845.2754020691, 352845.2754020691, 352845.2754020691, 352845.2754020691, 352845.2754020691, 352845.2754020691, 357893.92828941345, 357893.92828941345, 360613.9762401581, 360613.9762401581, 366879.74762916565, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 370454.4081687927, 376457.76534080505, 376457.76534080505, 376457.76534080505, 376457.76534080505, 376457.76534080505, 384023.06842803955, 384023.06842803955, 384023.06842803955, 386849.16472435, 386849.16472435, 389843.59526634216, 389843.59526634216, 389843.59526634216, 389843.59526634216, 389843.59526634216, 389843.59526634216, 393632.4589252472, 393632.4589252472, 393632.4589252472, 398146.5585231781, 398146.5585231781, 400995.82386016846, 400995.82386016846, 400995.82386016846, 400995.82386016846, 400995.82386016846, 400995.82386016846, 400995.82386016846, 400995.82386016846, 400995.82386016846, 400995.82386016846, 400995.82386016846, 407580.4662704468, 407580.4662704468, 407580.4662704468, 407580.4662704468, 413599.90406036377, 413599.90406036377, 413599.90406036377, 413599.90406036377, 413599.90406036377, 413599.90406036377, 418213.5577201843, 419387.07995414734, 419387.07995414734, 419387.07995414734, 419387.07995414734, 423607.44428634644, 423607.44428634644, 423607.44428634644, 423607.44428634644, 427333.22834968567, 434651.8111228943, 445082.08298683167, 445082.08298683167, 445082.08298683167, 445082.08298683167, 445082.08298683167, 445082.08298683167, 445082.08298683167, 445082.08298683167, 445082.08298683167, 445082.08298683167, 445082.08298683167, 445082.08298683167, 447994.1120147705, 447994.1120147705, 447994.1120147705, 447994.1120147705, 447994.1120147705, 447994.1120147705, 447994.1120147705, 447994.1120147705, 447994.1120147705, 455993.55483055115, 455993.55483055115, 462098.66857528687, 462098.66857528687, 462098.66857528687, 462098.66857528687, 462098.66857528687, 462098.66857528687, 462098.66857528687, 464746.45709991455, 464746.45709991455, 464746.45709991455, 464746.45709991455, 464746.45709991455, 464746.45709991455, 464746.45709991455, 469128.5388469696, 470526.3612270355, 470526.3612270355, 470526.3612270355, 470526.3612270355, 478566.8992996216, 478566.8992996216, 478566.8992996216, 484211.8151187897, 484211.8151187897, 484211.8151187897, 484211.8151187897, 484211.8151187897, 484211.8151187897, 484211.8151187897, 484211.8151187897, 484211.8151187897, 484211.8151187897, 484211.8151187897, 491283.3397388458, 493902.9116630554, 493902.9116630554, 493902.9116630554, 496273.8561630249, 496273.8561630249, 496273.8561630249, 496273.8561630249, 496273.8561630249, 496273.8561630249, 496273.8561630249, 496273.8561630249, 503556.5745830536, 505947.92199134827, 505947.92199134827, 505947.92199134827, 505947.92199134827, 505947.92199134827, 505947.92199134827, 505947.92199134827, 505947.92199134827, 505947.92199134827, 513370.8267211914, 516254.5704841614, 519602.4458408356, 519602.4458408356, 519602.4458408356, 519602.4458408356, 519602.4458408356, 521413.4888648987, 521413.4888648987, 521413.4888648987, 521413.4888648987, 527688.946723938, 527688.946723938, 527688.946723938, 527688.946723938, 532521.6467380524, 535336.264371872, 535336.264371872, 547949.3775367737, 547949.3775367737, 547949.3775367737, 547949.3775367737, 547949.3775367737, 547949.3775367737, 547949.3775367737, 547949.3775367737, 547949.3775367737, 547949.3775367737, 547949.3775367737, 547949.3775367737, 547949.3775367737, 552609.4279289246, 555550.6925582886, 561876.0073184967, 561876.0073184967, 561876.0073184967, 561876.0073184967, 561876.0073184967, 561876.0073184967, 561876.0073184967, 571181.9384098053, 571181.9384098053, 571181.9384098053, 571181.9384098053, 571181.9384098053, 571181.9384098053, 571181.9384098053, 571181.9384098053, 571181.9384098053, 575049.3614673615, 575049.3614673615, 575049.3614673615, 578970.415353775, 578970.415353775, 578970.415353775, 578970.415353775, 578970.415353775, 590610.3363037109, 590610.3363037109, 590610.3363037109, 590610.3363037109, 590610.3363037109, 590610.3363037109, 590610.3363037109, 590610.3363037109, 595486.7641925812, 598293.5421466827, 600124.0434646606, 600124.0434646606, 600124.0434646606, 600124.0434646606, 600124.0434646606, 600124.0434646606, 600124.0434646606, 600124.0434646606, 604459.0790271759, 604459.0790271759, 604459.0790271759, 604459.0790271759, 609289.345741272, 609289.345741272, 609289.345741272, 609289.345741272, 612057.6379299164, 612057.6379299164, 614720.0889587402, 614720.0889587402, 614720.0889587402, 614720.0889587402, 614720.0889587402, 614720.0889587402, 614720.0889587402, 614720.0889587402, 614720.0889587402, 619334.1681957245, 619334.1681957245, 619334.1681957245, 626893.9213752747, 626893.9213752747, 626893.9213752747, 626893.9213752747, 629336.8198871613, 629336.8198871613, 629336.8198871613, 629336.8198871613, 629336.8198871613, 636496.4895248413, 636496.4895248413, 639426.5599250793, 639426.5599250793, 641111.5815639496, 641111.5815639496, 641111.5815639496, 641111.5815639496, 641111.5815639496, 649436.6636276245, 649436.6636276245, 649436.6636276245, 649436.6636276245, 649436.6636276245, 649436.6636276245, 663137.796163559, 663137.796163559, 663137.796163559, 663137.796163559, 663137.796163559, 665948.459148407, 665948.459148407, 665948.459148407, 665948.459148407, 665948.459148407, 668771.744966507, 668771.744966507, 674689.0294551849, 674689.0294551849, 674689.0294551849, 674689.0294551849, 678199.4321346283, 678199.4321346283, 678199.4321346283, 678199.4321346283, 678199.4321346283, 680701.140165329, 680701.140165329, 680701.140165329, 680701.140165329, 680701.140165329, 680701.140165329, 680701.140165329, 684105.7605743408, 691743.3035373688, 691743.3035373688, 694584.655046463, 694584.655046463, 700830.61170578, 700830.61170578, 700830.61170578, 700830.61170578, 700830.61170578, 703832.6561450958, 710724.8439788818, 710724.8439788818, 710724.8439788818, 714321.7661380768, 714321.7661380768, 714321.7661380768, 714321.7661380768, 714321.7661380768, 714321.7661380768, 717619.4133758545, 720817.9624080658, 720817.9624080658, 720817.9624080658, 720817.9624080658, 720817.9624080658, 720817.9624080658, 731046.0057258606, 731046.0057258606, 731046.0057258606, 731046.0057258606, 731046.0057258606, 731046.0057258606, 733184.5512390137, 733184.5512390137, 733184.5512390137, 733184.5512390137, 733184.5512390137, 733184.5512390137, 737844.3193435669, 740608.9141368866, 740608.9141368866, 743713.0959033966, 743713.0959033966, 743713.0959033966, 743713.0959033966, 743713.0959033966, 743713.0959033966, 743713.0959033966, 745438.2135868073, 745438.2135868073, 745438.2135868073, 745438.2135868073, 745438.2135868073, 745438.2135868073, 745438.2135868073, 749052.2563457489, 749052.2563457489, 749052.2563457489, 758511.0728740692, 758511.0728740692, 758511.0728740692, 758511.0728740692, 758511.0728740692, 758511.0728740692, 758511.0728740692, 758511.0728740692, 758511.0728740692, 758511.0728740692, 758511.0728740692, 763121.6654777527, 763121.6654777527, 763121.6654777527, 763121.6654777527, 765971.2400436401, 765971.2400436401, 765971.2400436401, 765971.2400436401, 768807.944059372, 768807.944059372, 768807.944059372, 768807.944059372, 770560.5716705322, 770560.5716705322, 770560.5716705322, 770560.5716705322, 770560.5716705322, 775033.8246822357, 775033.8246822357, 775033.8246822357, 779957.0226669312, 779957.0226669312, 779957.0226669312, 779957.0226669312, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 798894.8090076447, 803597.113609314, 803597.113609314, 803597.113609314, 806154.899597168, 806154.899597168, 807900.593996048, 807900.593996048, 807900.593996048, 807900.593996048, 812371.6289997101, 815084.4252109528, 816384.5150470734, 816384.5150470734, 816384.5150470734, 816384.5150470734, 816384.5150470734, 816384.5150470734, 816384.5150470734, 822962.8989696503, 825768.7077522278, 825768.7077522278, 825768.7077522278, 825768.7077522278, 828605.9715747833, 828605.9715747833, 828605.9715747833, 834227.480173111, 834227.480173111, 834227.480173111, 834227.480173111, 834227.480173111, 834227.480173111, 834227.480173111, 834227.480173111, 834227.480173111, 834227.480173111, 840900.4995822906, 840900.4995822906, 840900.4995822906, 840900.4995822906, 840900.4995822906, 840900.4995822906, 840900.4995822906, 840900.4995822906, 840900.4995822906, 840900.4995822906, 847784.4388484955, 847784.4388484955, 847784.4388484955, 847784.4388484955, 850092.6675796509, 850092.6675796509, 850092.6675796509, 850092.6675796509, 850092.6675796509, 850092.6675796509, 850092.6675796509, 854146.318435669, 854146.318435669, 854146.318435669, 854146.318435669, 854146.318435669, 854146.318435669, 859151.6919136047, 859151.6919136047, 862185.3396892548, 862185.3396892548, 865331.0997486115, 865331.0997486115, 865331.0997486115, 865331.0997486115, 868671.4038848877, 868671.4038848877, 868671.4038848877, 868671.4038848877, 868671.4038848877, 868671.4038848877, 868671.4038848877, 868671.4038848877, 868671.4038848877, 868671.4038848877, 868671.4038848877, 873238.930940628, 873238.930940628, 876001.9104480743, 876001.9104480743, 878671.2214946747, 878671.2214946747, 878671.2214946747, 880482.7952384949, 880482.7952384949, 880482.7952384949, 885662.7395153046, 885662.7395153046, 885662.7395153046, 885662.7395153046, 890361.0999584198, 890361.0999584198, 892683.0904483795, 895687.9155635834, 895687.9155635834, 895687.9155635834, 895687.9155635834, 895687.9155635834, 895687.9155635834, 898444.9059963226, 898444.9059963226, 898444.9059963226, 898444.9059963226, 898444.9059963226, 901073.4632015228, 901073.4632015228, 901073.4632015228, 903834.1629505157, 903834.1629505157, 903834.1629505157, 906428.1742572784, 906428.1742572784, 906428.1742572784, 906428.1742572784, 906428.1742572784, 906428.1742572784, 911080.4500579834, 911080.4500579834, 913929.8837184906, 913929.8837184906, 913929.8837184906, 913929.8837184906, 916629.3966770172, 916629.3966770172, 916629.3966770172, 919175.7156848907, 919175.7156848907, 919175.7156848907, 924410.4008674622, 924410.4008674622, 924410.4008674622, 924410.4008674622, 924410.4008674622, 926824.7010707855, 926824.7010707855, 926824.7010707855, 926824.7010707855, 926824.7010707855, 930694.9276924133, 930694.9276924133, 930694.9276924133, 935403.2461643219, 937286.3247394562, 937286.3247394562, 937286.3247394562, 937286.3247394562, 937286.3247394562, 937286.3247394562, 944684.8595142365, 947787.2054576874, 950953.8488388062, 950953.8488388062, 950953.8488388062, 950953.8488388062, 950953.8488388062, 950953.8488388062, 950953.8488388062, 950953.8488388062, 950953.8488388062, 950953.8488388062, 953893.6035633087, 953893.6035633087, 953893.6035633087, 953893.6035633087, 953893.6035633087, 953893.6035633087, 953893.6035633087, 953893.6035633087, 958325.7706165314, 958325.7706165314, 959676.1372089386, 959676.1372089386, 959676.1372089386, 959676.1372089386, 967324.6736526489, 970474.2016792297, 970474.2016792297, 970474.2016792297, 970474.2016792297, 970474.2016792297, 970474.2016792297, 970474.2016792297, 972762.5246047974, 972762.5246047974, 972762.5246047974, 972762.5246047974, 972762.5246047974, 972762.5246047974, 980387.2358798981, 980387.2358798981, 980387.2358798981, 980387.2358798981, 982559.7145557404, 982559.7145557404, 982559.7145557404, 982559.7145557404, 982559.7145557404, 982559.7145557404, 987388.5879516602, 987388.5879516602, 990187.9155635834, 993195.1017379761, 993195.1017379761, 993195.1017379761, 993195.1017379761, 993195.1017379761, 993195.1017379761, 993195.1017379761, 993195.1017379761, 993195.1017379761, 996842.9849147797, 996842.9849147797, 1001263.2396221161, 1001263.2396221161, 1001263.2396221161, 1001263.2396221161, 1001263.2396221161, 1008497.8723526001, 1008497.8723526001, 1008497.8723526001, 1008497.8723526001, 1008497.8723526001, 1010936.9170665741, 1013786.7429256439, 1013786.7429256439, 1013786.7429256439, 1013786.7429256439, 1016898.5500335693, 1016898.5500335693, 1016898.5500335693, 1016898.5500335693, 1019582.3969841003, 1019582.3969841003, 1019582.3969841003, 1019582.3969841003, 1022130.3572654724, 1022130.3572654724, 1022130.3572654724, 1022130.3572654724, 1022130.3572654724, 1022130.3572654724, 1022130.3572654724, 1022130.3572654724, 1022130.3572654724, 1022130.3572654724, 1026218.772649765, 1026218.772649765, 1026218.772649765, 1026218.772649765, 1026218.772649765, 1034122.2579479218, 1034122.2579479218, 1034122.2579479218, 1034122.2579479218, 1034122.2579479218, 1034122.2579479218, 1034122.2579479218, 1038123.3639717102, 1038123.3639717102, 1038123.3639717102, 1043043.053150177, 1043043.053150177, 1043043.053150177, 1043043.053150177, 1047159.2082977295, 1047159.2082977295, 1047159.2082977295, 1047159.2082977295, 1051767.4160003662, 1051767.4160003662, 1051767.4160003662, 1051767.4160003662, 1051767.4160003662, 1054044.7313785553, 1054044.7313785553, 1054044.7313785553, 1054044.7313785553, 1054044.7313785553, 1054044.7313785553, 1054044.7313785553, 1058559.2424869537, 1064418.1039333344, 1064418.1039333344, 1064418.1039333344, 1064418.1039333344, 1066006.590127945, 1066006.590127945, 1066006.590127945, 1066006.590127945, 1066006.590127945, 1066006.590127945, 1066006.590127945, 1070675.7566928864, 1070675.7566928864, 1070675.7566928864, 1070675.7566928864, 1070675.7566928864, 1078726.9582748413, 1078726.9582748413, 1078726.9582748413, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1084264.5857334137, 1088700.5033493042, 1088700.5033493042, 1088700.5033493042, 1088700.5033493042, 1095313.592672348, 1095313.592672348, 1095313.592672348, 1095313.592672348, 1095313.592672348, 1095313.592672348, 1095313.592672348, 1095313.592672348, 1105505.392074585, 1105505.392074585, 1105505.392074585, 1108438.5454654694, 1108438.5454654694, 1108438.5454654694, 1108438.5454654694, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1115457.4580192566, 1121822.9746818542, 1121822.9746818542, 1121822.9746818542, 1125820.784330368, 1125820.784330368, 1125820.784330368, 1125820.784330368, 1125820.784330368, 1125820.784330368, 1133112.4355793, 1133112.4355793, 1133112.4355793, 1138982.1648597717, 1138982.1648597717, 1138982.1648597717, 1142014.9903297424, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1145534.3809127808, 1152387.2582912445, 1152387.2582912445, 1152387.2582912445, 1156907.7746868134, 1156907.7746868134, 1175224.3747711182, 1175224.3747711182, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1179510.957479477, 1184436.6221427917, 1185708.8367938995, 1185708.8367938995, 1185708.8367938995, 1185708.8367938995, 1185708.8367938995, 1192718.0559635162, 1192718.0559635162, 1192718.0559635162, 1192718.0559635162, 1192718.0559635162, 1192718.0559635162, 1192718.0559635162, 1192718.0559635162, 1197732.9885959625, 1197732.9885959625, 1200281.6216945648, 1200281.6216945648, 1203222.6943969727, 1203222.6943969727, 1206186.072587967, 1206186.072587967, 1206186.072587967, 1206186.072587967, 1206186.072587967, 1208388.4344100952, 1208388.4344100952, 1208388.4344100952, 1208388.4344100952, 1208388.4344100952, 1208388.4344100952, 1208388.4344100952, 1213182.3253631592, 1213182.3253631592, 1215469.7442054749, 1215469.7442054749, 1215469.7442054749, 1215469.7442054749, 1215469.7442054749, 1215469.7442054749, 1215469.7442054749, 1215469.7442054749, 1219989.5691871643, 1228867.0914173126, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1232285.694360733, 1235843.9121246338, 1235843.9121246338, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1250417.3736572266, 1254039.992570877, 1254039.992570877, 1254039.992570877, 1254039.992570877, 1258956.7303657532, 1258956.7303657532, 1261584.1517448425, 1261584.1517448425, 1264293.1673526764, 1264293.1673526764, 1264293.1673526764, 1264293.1673526764, 1264293.1673526764, 1264293.1673526764, 1267109.9917888641, 1267109.9917888641, 1270288.0113124847, 1270288.0113124847, 1273288.3336544037, 1273288.3336544037, 1276168.7104701996, 1276168.7104701996, 1276168.7104701996, 1276168.7104701996, 1284924.036026001, 1284924.036026001, 1284924.036026001, 1284924.036026001, 1284924.036026001, 1284924.036026001, 1295448.8878250122, 1298800.2352714539, 1298800.2352714539, 1298800.2352714539, 1298800.2352714539, 1298800.2352714539, 1298800.2352714539, 1298800.2352714539, 1298800.2352714539, 1301571.0561275482, 1301571.0561275482, 1301571.0561275482, 1301571.0561275482, 1304212.5523090363, 1306206.0897350311, 1306206.0897350311, 1306206.0897350311, 1306206.0897350311, 1306206.0897350311, 1310773.8628387451, 1310773.8628387451, 1310773.8628387451, 1310773.8628387451, 1313360.8658313751, 1314618.7057495117, 1314618.7057495117, 1314618.7057495117], "prediction_length": 1359, "reference": "Mein Name ist Antoine. Ich bin Doktorand an der University of Massachusetts Amherst. Ich stelle unser Paper KinyaBERT vor: ein Morphologie-bewusstes Kinyarwanda-Sprachmodell. Heute werde ich über den Grund für diese Forschung sprechen. Dann werde ich die KinyaBERT-Modell-Architektur im Detail vorstellen. Ich werde dann über unsere experimentellen Ergebnisse sprechen und zum Schluss einige Schlussfolgerungen darstellen. Wir alle wissen, dass die jüngsten Fortschritte bei der NLP durch die Verwendung von vortrainierten Sprachmodellen wie BERT ermöglicht wurden. Allerdings gibt es immer noch eine Reihe von Einschränkungen. Aufgrund der komplexen Morphologie, die von den meisten morphologisch reichen Sprachen ausgedrückt wird, kann der allgegenwärtige byte pair encoding-Tokenisierungsalgorithmus, den ich verwendet habe, nicht die genauen lexikalischen Unterwort-Einheiten extrahieren, d. h. die Morpheme, die für eine effektive Repräsentation benötigt werden. Hier haben wir zum Beispiel drei Kinyarwanda-Wörter, die mehrere Morpheme enthalten, aber die BPE-Algorithmen können sie nicht extrahieren. Das liegt daran, dass einige morphologische Regeln verschiedene Oberflächenformen erzeugen, die die genauen lexikalischen Informationen verbergen. BPE stützt sich aber nur auf die Oberflächenformen und hat so keinen Zugang zu diesem lexikalischen Modell. Die zweite Herausforderung besteht darin, dass, selbst wenn man Zugang zu einem morphologischen Analysator von Oracle hätte, würde es nicht ausreichen, das BPE-Token durch Morpheme zu ersetzen, um die morphologische Kompositionalität auszudrücken. Eine dritte Lücke in der Forschung besteht darin, dass neue vortrainierte Sprachmodelle meist bei ressourcenintensiven Sprachen evaluiert werden. Wir müssen ihre Anwendbarkeit auch bei geringen Ressourcen und in verschiedenen Sprachen bewerten. Daher präsentieren wir KinyaBERT. Das ist eine einfache, aber effektive Anpassung der BERT-Architektur, die für den effektiveren Umgang mit morphologisch reichen Sprachen gedacht ist. Wir evaluieren KinyaBERT mit Kinyarwanda, einer ressourcenarmen und morphologisch reichen Sprache, die von mehr als zwölf Millionen Menschen in Ost- und Zentralafrika gesprochen wird. Die Eingabe für das Modell ist entweder ein Satz oder ein Dokument. Zum Beispiel haben wir hier den Satz: „John twarahamubonye biradutangaza“. Das bedeutet: „Wir waren überrascht, John dort anzutreffen.“ Wie Sie sehen können, enthaltenWörter im Kinyarwanda mehrere Morpheme, die unterschiedliche Informationen enthalten. Daher übergeben wir in unserem Modell diesen Satz oder ein Dokument an einen morphologischen Analysator. Dieser erzeugt dann Morpheme, die in allen Wörtern enthalten sind. Die Morpheme setzen sich in der Regel aus dem Stamm und null oder mehr Affixen zusammen. Die Affixe können Zeitform, Aspekt, Subjekt oder Objekt in den Verben anzeigen und beziehen sich häufiger auf die Substantivklasse der Bantu für Subjekte und Objekte. Der morphologische Analysator erzeugt auch einen Teil eines Sprach-Tags für jedes der Wörter. Nach diesem Schritt erstellen wir Einbettungen für den Teil der Sprach-Tags. Einbettungen für die Affixe. Einbettungen für den Stamm. Dies sind die Einbettungen auf Morphologie-Ebene. Anschließend durchlaufen diese Einbettungen einen Morphologie-Encoder, der ein kleiner Transformer-Encoder ist, der auf jedes Wort unabhängig angewendet wird. Ausgegeben werden die Vektoren, die mit den morphologischen Informationen bei jedem Wort kontextualisiert werden. Nun führen wir eine Komposition durch, bei der die morphologischen Einbettungen, die der Sprache und dem Wortstamm entsprechen, miteinander verkettet werden. Wir verketten sie mit einer weiteren Einbettung des Stammes auf der Ebene des Satzes. Dann erstellen wir eine Eingabe für den Hauptsatz oder den Dokument-Encoder. Die Endausgabe sind kontextualisierte Einbettungen, die für nachgelagerte NLP-Aufgaben verwendet werden können. Für einen morphologischen Analysator verwenden wir Morphologie-Prinzipien mit endlichen Automaten auf zwei Ebenen und mit einer maßgeschneiderten Implementierung, die auf die Sprache Kinyarwanda zugeschnitten ist. Wir modellieren die Morphologie aller Wörter auf Kinyarwanda, einschließlich der Verben, Substantive, Demonstrativ- und Possessivpronomen, Numerale und andere. Wir verwenden einen nicht überwachten Teil eines Sprach-Tagging-Algorithmus. Ein faktorisiertes Modell erster Ordnung wird verwendet, um die Morphologie-Wahrscheinlichkeit zu berücksichtigen, d. h. die Wahrscheinlichkeit, die vom morphologischen Analysator zugewiesen wird. Wir berücksichtigen auch den Vorrang der Sprach-Tags sowie die syntaktischen Vereinbarungen, die in den eingegebenen Wörtern vorhanden sind. Der Teil des Sprach-Taggers verwendet eine bidirektionale Inferenz, die den häufiger verwendeten Viterbi-Algorithmus für die Dekodierung verbessert. Hier noch ein paar Anmerkungen zur Positionskodierung. Erstens verwendet der Morphologie-Encoder keine Positionskodierung. Das liegt daran, dass jedes der Morpheme einen bekannten Platz im morphologischen Modell einnimmt. Daher ist die positionelle Information inhärent, wenn die Morpheme gegeben sind. Zweitens verwendet der Satz-Encoder die so genannten ungebundenen, relativ positionellen Einbettungen, die kürzlich auf der ICLR-Konferenz veröffentlicht wurden. Diese positionellen Einbettungen entkoppeln im Wesentlichen positionelle Korrelationen von Token hin zu einer Token-Aufmerksamkeitsberechnung. Ähnlich wie BERT verwenden wir ein maskiertes Sprachmodell als Vortrainingsziel. Im Wesentlichen müssen wir sowohl den Stamm als auch die Affixe, aus denen die Wörter bestehen, vorhersagen. Während des Vortrainings werden fünfzehn Prozent aller Wörter für die Vorhersage berücksichtigt, von denen achtzig Prozent maskiert, zehn Prozent mit zufälligen Wörtern ausgetauscht und zehn Prozent unverändert gelassen werden. Für die Vorhersage der Affixe stehen wir vor einem Multi-Label-Klassifikationsproblem. Daher fassen wir entweder die Affixe zu einer festen Reihe von Gruppen zusammen und sagen die Gruppe als Klassenlabel voraus. Die andere Möglichkeit ist die Vorhersage der Affixe durch einen Wahrscheinlichkeitsvektor. Wir bewerten beide Ansätze in unseren Experimenten. Wir trainieren KinyaBERT mit etwa zweieinhalb Gigabyte an Text in Kinyarwanda vor und vergleichen es mit drei Modellen der Baseline. Eines davon ist ein mehrsprachiges Modell namens XLM-R, das mit großen Textkorpora trainiert wird, die aus mehreren Sprachen bestehen. Die beiden anderen Baselines werden mit demselben Text auf Kinyarwanda vortrainiert, wobei entweder der byte pair encoding-Algorithmus oder die morphologische Analyse ohne die zweistufige Transformer-Encoder-Architektur verwendet wird. Alle Modelle sind in der Basisarchitektur konfiguriert, die etwa hundert bis hundertzehn Millionen Parameter umfasst, wobei Kinyarwanda mit KinyaBERT die geringste Anzahl von Parametern verwendet. Alle außer dem mehrsprachigen Modell werden für zweiunddreißigtausend Gradient-Updates vortrainiert, mit einer Batchgröße von zweitausendfünfhundertsechzig Sequenzen in jedem Batch. Wir bewerten die vortrainierten Modelle anhand von drei Gruppen von Aufgaben. Eine davon ist die GLUE-Benchmark, die häufig zur Bewertung der Effektivität von vortrainierten Sprachmodellen verwendet wird. Wir erhalten unsere GLUE-Benchmark-Daten, indem wir die originalen Benchmark-Daten mit Google Translate ins Kinyarwanda übersetzen. Die zweite Aufgabe ist die named entity recognition-Benchmark von Kinyarwanda, ein qualitativ hochwertiger Datensatz, der von trainierten Muttersprachlern annotiert wurde. Bei der dritten Aufgabe handelt es sich um eine Kategorisierung von Nachrichten. Hier rufen wir Nachrichtenartikel von verschiedenen Websites ab und sammeln ihre Kategorisierungstags, die von den Autoren zugewiesen wurden. Im Wesentlichen versuchen wir, die gleichen Kategorien vorherzusagen. Sehen wir uns jetzt die Ergebnisse an. Bei der GLUE-Benchmark haben wir festgestellt, dass KinyaBERT durchweg besser abschneidet als die Baseline-Modelle. Hier zeigen wir die durchschnittliche Leistung von zehn Durchläufen zur Feinabstimmung. Wir führen auch eine Benutzerevaluation der Übersetzungen durch, die von Google Translate erstellt werden. Im Wesentlichen bewerteten die Benutzer etwa sechstausend Beispiele und vergaben Noten auf einer Skala von eins bis vier, um die Qualität der Übersetzungen zu bewerten. Das Ergebnis war, dass viele Übersetzungen qualitativ schlecht waren. Aber alle Modelle mussten mit der gleichen schlechten Qualität der Übersetzung umgehen, und die relative Leistung zwischen den Modellen kann immer noch bedeutend festgestellt werden. Bei der Aufgabe Named Entity Recognition stellten wir außerdem fest, dass KinyaBERT die beste Leistung erbringt, wobei die Variante mit der Verteilungsregression der Affixe am besten abschneidet. Diese Ergebnisse sind auch Mittelwerte von zehn Durchläufen zur Feinabstimmung. Bei der Aufgabe zur Kategorisierung der Nachrichten bekamen wir gemischte Ergebnisse. Frühere Arbeiten zur Textklassifizierung für Kinyarwanda hatten herausgefunden, dass eine einfache Schlüsselworterkennung meistens ausreicht, um diese spezifische Aufgabe zu lösen. Daher ist die Verwendung von vortrainierten Sprachmodellen weniger erfolgsversprechend. Jetzt zu dieser besonderen Aufgabe der Kategorisierung von Nachrichten. Wir haben auch eine Ablationsstudie durchgeführt, um zu sehen, ob es alternative Strukturen gibt, die die Leistung verbessern. Bei der GLUE-Benchmark haben wir festgestellt, dass die Verwendung von Affix-Sätzen durchweg besser abschneidet, während das Ziel der Affix-Wahrscheinlichkeitsregression die beste Leistung bei der Named Entity Recognition erbringt. Auch wenn man die niedrigen Werte bei der Feinabstimmung betrachtet, stellt man fest, dass KinyaBERT in den meisten Fällen eine bessere Konvergenz aufweist. Abschließend lässt sich sagen, dass diese Arbeit die Effektivität der expliziten Verwendung von morphologischen Informationen in vortrainierten Sprachmodellen bewiesen hat. Die vorgeschlagene zweistufige Transformer-Encoder-Architektur ermöglicht die Erfassung von morphologischer Komplexität und morphologischer Kompositionalität, die ein wichtiger Aspekt von morphologisch reichen Sprachen ist. Diese Ergebnisse sollten zu weiteren Forschungen über morphologie-bewusste, vortrainierte Sprachmodelle motivieren.", "source": ["2/acl_6060/dev/full_wavs/2022.acl-long.367.wav", "samplerate: 16000 Hz", "channels: 1", "duration: 1e+01:35.020 min", "format: WAV (Microsoft) [WAV]", "subtype: Signed 16 bit PCM [PCM_16]"], "source_length": 694388.0}
{"index": 2, "prediction": "Hallo, mein Name ist Miho Petrushka und es ist mir eine Freude, Ihnen das Papier mit dem Titel Sparsifying Transformers Models with Trainable Representation Pooling vorzustellen. Ich hab's nicht so gut geschafft. Lass mich mit den Problemen beginnen, unsere Arbeitsziele. Unsere Methode funktioniert gut für Fälle, in denen lange Eingänge berücksichtigt werden. Es ist für das Task Quarter gedacht, es ist ein Input von über 2000 Token und die Ziele sind kürzer. Dann haben sie Inputs geliefert. Das hat einige spezifische Anwendungen in NLP. Zum Beispiel kann man sich vorstellen, dass es aufgrund eines langen Dokuments eine Notwendigkeit gibt, das zu zusammenfassen und zu klassifizieren. Antworten Sie auf die Frage, Extrak-Informationen. Ich habe ein paar Schlüsselphrasen. Lass mich an den Vanilla-Transformer erinnern, der eine Frage der Aufmerksamkeit und Komplexität hat, die vom Quadrat des Eingangsläufers abhängt. In der Vanilla-Transformer Mit voller Aufmerksamkeit auf die Konnektivität, die Beziehungen von jedem Token To every other token have to be calculated. Die Komplexität der Aufmerksamkeit hängt von der Anzahl der Layer ab. Sequenzlänge an Eine weitere Sequenz. und die Dimensionalität von Repräsentationen. In ähnlicher Weise scharft der Dekatur Aufmerksamkeit auf dieses Bild auf der rechten Seite. Der einzige Unterschied hier ist, dass die Target Tokens die Input Tokens betreffen. In diesem Fall. Das ist auch in dieser Formel zu sehen. Die blaue Punktzahl stellt Beziehungen dar, die berechnet werden müssen. Im Falle der vollen Aufmerksamkeit müssen wir alle Beziehungen innerhalb der Eingangssequenz berechnen. Jetzt sehen wir, was passiert, wenn wir einen Block-Wise-Enkoder haben, der durch die Begrenzung der Token-Konnektivität funktioniert. So dass sie nur andere Token in der Nähe sehen können. Der Text wird in Stücken gelesen, was die Anzahl der Berechnungen auf der Encoder-Seite drastisch reduzieren kann. aber es verbessert nicht die Decoders. Cross Attention , da jeder Input-Token sowieso an den Decoder übergeben wird. Diese Methode wird oft als Fusion Indikator bezeichnet. Die Verbesserung hier kann als Veränderung interpretiert werden. Einer der Abhängigkeiten von n zu einer anderen Konstante m. die Blockgröße repräsentiert. Unsere wichtigste Beobachtung ist, dass die meisten Tokens irrelevant sind. für eine Vielzahl von Aufgaben und kann fast vollständig vernachlässigt werden. Das ist auf der Schieberliste veranschaulicht. wo nur Teile der Eingänge relevant sind. zu the desired output. zum Beispiel Man kann einen Artikel einmal lesen. die wichtigsten Teile mit einem High lighter zu markieren und dann eine Zusammenfassung basierend auf diesen Teilen aus der mittleren Stufe zu erstellen. Die Kosten für die Auszeichnung und Entscheidung, ob die aktuellen Token für die Herstellung der Zusammenfassung unerlässlich sind, sind also billig und hängen nur von der Repräsentation der Token ab. Das Pulling der hervorgehobenen Tokens ist möglich. Danke an unseren Top K Operator. Und die Kosten sind unerheblich. Die Kosten für die Zusammenfassung aus einem kurzfristigen Input. Es ist auch viel niedriger als im Van ille-Modell, wenn der gesamte Eingang berücksichtigt wird. Aber hier ist die Frage: wie man wichtige Tokens auswählt und wieder verbreitet. Gradienten zu dieser Selektion. Das ist das Problem, das wir lösen, den trainierbaren Selektionsmechanismus vorzuschlagen. Einer, der es ermöglicht, dass Gradienten während des Trainings zurückverbreitet werden, so dass das Netzwerk lernen kann, die wichtigsten Token zu wählen. Genauer gesagt: Geben Sie mir einige Embeddings und Schnürsenker aus einer einfachen linearen Schicht gewonnen Die Aufgabe ist es, die höchsten Punkte zurückzugeben. Zuerst ist die Sequenz permutirt. und Paars werden so vorbereitet, dass der höhere Scoring-Vektor mit dem niedrigeren Scoring genommen wird. Als nächstes werden die Gewichte mit Boosted Softmax über die Scores berechnet. Nach jeder Turnierrunde Neue Vektoren und die Scores sind als eine lineare Kombination aus diesen Parts zusammengesetzt. Und da haben wir das gewählt. Kurz gesagt, wir kombinieren sie linear. durch Performing Softmax Over The Das ist natürlich... Und während wir kombinieren, Zwei Tokens, ein bisschen Noise. die man produzieren kann. produziert, aber es erlaubt auch, die Gradienten zu propagieren, um alle Eingaben zu embonieren. Kurz gesagt, ein trainierbares Topk. Wir haben einen Antrag gemacht. Es basiert auf der Durchführung eines Turniers wie Soft Selection. Und aus einer anderen Perspektive. Die Repräsentationspoling folgt der Encoder-Schicht. Zuerst wird jede Repräsentation bewertet und dann nur die mit den höchsten Punkten. zu den nächsten Layer. Die Kodierung kann wie in der Standard-Transformer-Architektur auf der vollständigen Eingabe durchgeführt werden. Es ist jedoch möglich, Texte in Blöcken von Pixel zu verarbeiten. fixed length and globally select the best representation. Hier ist ein Beispiel für das Repräsentations-Polling , das nach dem Encoder eingeführt wurde. Das beeinflusst direkt die Kosten für die enge Aufmerksamkeit, Nicht auf der Input-Link-End. Aber die Konstante \"K\". Ich repräsentiere das Pool Play. Das ist konstant informiert, wie viele Repräsentanten ausgewählt wurden. und dann übergeben an den Dekoder. Produzieren eine Zusammenfassung aus einem kürzeren Text ist &nbsp; bedeutend billiger als vorherige Lösung. Da die Sequenzlänge durch einen großen Faktor verkürzt werden kann, Zum Beispiel haben wir erfolgreich K verwendet. von 16 oder sogar 60 Mal. oder sogar 64 mal kleiner als der Wert von n in unserem Experiment. Bitte nicht. dass die positive Wirkung von Blockwise-Enkodierung und Selbstbetrachtung ist sustained. Ich habe immer gedacht, dass die Rechnungskosten der Aufmerksamkeit vom Quadrat der Eingangslänge abhängen. Das ist ein Kind. Die früheren Eingänge während des Kodierungsprozesses können die Kosten deutlich senken. Für das pyramidische Modell schränken wir die Größe der Repräsentation auf der Ausgabe von jeder gewählten Schicht, was zu einer exponentiellen Reduktion die Kosten für die Berechnung, während die Kodierung voranschreitet. Wie Sie sehen können, die Gesamtrechnung skosten eines vollständigen Encoders sind weniger als doppelt so hoch wie die Kosten für die Vollgroß erste Schicht. Wenn das Pulling früher eingeführt wurde, Die Summe aller lila Quadrate ist also begrenzt auf eine Konstante. nicht abhängig von der Anzahl der Layer L. Was auf die Konstanz zu sagen die durch die Platzierung der Pulling-Layer innerhalb des Netzwerks beeinflusst werden können. Unsere Verbesserungen wurden auf achttausend Token langen Eingängen verglichen. Und die Figur zeigt, dass beim Pulling die beste Skalierbarkeit für die Netzwerkstiefe erreicht wird. hier kann man noten Das ist billiger , als einen zwei-Schicht-Vanille-Transformer mit so langem Eingang zu trainieren. Nicht zu erwähnen, wie leicht Vanilla Transformers Geh aus dem Gedächtnis für so einen langen Input. Der **. Qualitative Vergleichung unserer Die andere Baseline ist die Perform on the long document summary task, die die Gesamtheit eines Artikels aus Archive oder Papmat erzeugt. Wie man sehen kann. Blockwise, das ist unsere Baseline. performs on the level of the recent state of the art models. Während die Pyramidion die Leistung dieser wettbewerbsfähigen Baseline beibehält oder verbessert, Gleichzeitig. Unser Modell ist 80. Per zent schneller zu trainieren und über 450 Prozent schneller bei der In ferenz im Vergleich zur Blockweite-Basislinie. Beide Modelle haben eine viel niedrigere Parameterzahl und wurden von Anfang an an den gewählten Aufgaben ausgebildet. Vorherige Ansätze um zu erreichen. Eine ähnliche Leistung musste mehr Parameter verwenden. Und die Leverage- Pretrained-Foundation, die Fundamentals. und zusätzliche Sprachen für das Training. Ziel: Ähnliche Leistung zu erzielen. Oh, ja. Wir laden Sie ein, unser vollständiges Papier zu lesen und unseren GitHub-Code zu verwenden. Danke, dass du es gesehen hast.", "delays": [3000.0, 4500.0, 4500.0, 4500.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 13500.0, 18250.0, 18250.0, 18250.0, 18250.0, 18250.0, 18250.0, 21000.0, 21000.0, 21000.0, 21250.0, 21250.0, 21250.0, 21250.0, 21250.0, 24000.0, 24000.0, 25500.0, 25500.0, 25500.0, 26000.0, 26000.0, 26000.0, 26000.0, 26000.0, 26000.0, 26000.0, 31750.0, 31750.0, 31750.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 32500.0, 34500.0, 34500.0, 34500.0, 34500.0, 34500.0, 38750.0, 38750.0, 38750.0, 38750.0, 38750.0, 38750.0, 38750.0, 41500.0, 41500.0, 43000.0, 43000.0, 43000.0, 43000.0, 43000.0, 44500.0, 44750.0, 44750.0, 44750.0, 44750.0, 44750.0, 44750.0, 44750.0, 44750.0, 44750.0, 44750.0, 44750.0, 44750.0, 44750.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 50000.0, 50000.0, 50000.0, 50000.0, 50000.0, 54500.0, 54500.0, 54500.0, 56000.0, 56000.0, 56000.0, 56000.0, 59000.0, 59000.0, 59000.0, 59000.0, 59000.0, 59000.0, 59000.0, 59000.0, 59000.0, 59000.0, 59000.0, 59000.0, 59000.0, 62250.0, 62250.0, 62250.0, 66500.0, 67250.0, 67250.0, 67250.0, 67250.0, 67250.0, 67250.0, 67250.0, 67250.0, 67250.0, 67250.0, 70250.0, 70250.0, 70250.0, 70250.0, 70250.0, 70250.0, 70250.0, 70250.0, 74500.0, 74500.0, 74500.0, 76000.0, 76000.0, 76000.0, 76000.0, 76750.0, 76750.0, 76750.0, 76750.0, 79000.0, 79000.0, 82000.0, 82000.0, 82000.0, 84750.0, 84750.0, 84750.0, 84750.0, 84750.0, 89750.0, 89750.0, 89750.0, 89750.0, 89750.0, 89750.0, 89750.0, 89750.0, 89750.0, 89750.0, 89750.0, 89750.0, 89750.0, 89750.0, 93000.0, 93000.0, 93000.0, 93000.0, 97000.0, 97000.0, 97000.0, 97000.0, 97000.0, 97000.0, 97000.0, 97000.0, 97000.0, 99000.0, 99000.0, 99000.0, 101500.0, 101500.0, 101500.0, 101500.0, 101500.0, 101500.0, 101500.0, 101500.0, 106250.0, 106250.0, 106750.0, 106750.0, 106750.0, 106750.0, 106750.0, 106750.0, 106750.0, 106750.0, 111000.0, 111000.0, 111000.0, 111000.0, 111000.0, 111000.0, 111000.0, 112500.0, 113250.0, 113250.0, 113250.0, 113250.0, 113250.0, 117500.0, 117500.0, 117500.0, 117500.0, 119000.0, 119000.0, 119000.0, 120500.0, 120500.0, 120500.0, 120500.0, 121500.0, 121500.0, 121500.0, 121500.0, 121500.0, 121500.0, 124000.0, 124000.0, 124000.0, 124000.0, 124500.0, 124500.0, 124500.0, 124500.0, 124500.0, 124500.0, 124500.0, 129250.0, 129250.0, 129250.0, 129250.0, 129250.0, 129250.0, 130750.0, 130750.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 134500.0, 134500.0, 134500.0, 134500.0, 134500.0, 134500.0, 138750.0, 138750.0, 139500.0, 139500.0, 139500.0, 139500.0, 139500.0, 139500.0, 139500.0, 139500.0, 139500.0, 139500.0, 143750.0, 143750.0, 143750.0, 143750.0, 144500.0, 144500.0, 144500.0, 144500.0, 147250.0, 147250.0, 147250.0, 147250.0, 147750.0, 147750.0, 147750.0, 147750.0, 150500.0, 150500.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 154000.0, 154000.0, 154000.0, 161000.0, 162250.0, 162250.0, 162250.0, 162250.0, 162250.0, 162250.0, 162250.0, 162250.0, 162250.0, 166500.0, 166500.0, 166500.0, 166500.0, 166500.0, 167750.0, 167750.0, 167750.0, 167750.0, 167750.0, 167750.0, 170500.0, 170500.0, 170750.0, 170750.0, 170750.0, 170750.0, 174750.0, 174750.0, 174750.0, 174750.0, 174750.0, 174750.0, 174750.0, 176750.0, 176750.0, 176750.0, 176750.0, 181250.0, 181250.0, 184250.0, 184250.0, 184250.0, 184250.0, 184250.0, 184250.0, 188500.0, 188500.0, 188500.0, 188500.0, 188500.0, 188500.0, 190000.0, 190000.0, 190000.0, 190000.0, 190000.0, 191500.0, 191500.0, 192250.0, 192250.0, 192250.0, 192250.0, 192250.0, 192250.0, 192250.0, 192250.0, 192250.0, 192250.0, 195000.0, 195000.0, 196500.0, 198000.0, 198000.0, 198000.0, 198000.0, 198000.0, 198000.0, 198000.0, 198000.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 202250.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 209750.0, 209750.0, 209750.0, 209750.0, 209750.0, 209750.0, 211750.0, 211750.0, 211750.0, 211750.0, 211750.0, 214500.0, 214500.0, 216000.0, 216000.0, 216750.0, 216750.0, 216750.0, 216750.0, 216750.0, 219500.0, 219500.0, 219500.0, 219500.0, 219500.0, 221000.0, 221000.0, 221000.0, 222000.0, 222000.0, 222000.0, 222000.0, 222000.0, 222000.0, 222000.0, 224250.0, 224250.0, 224250.0, 224250.0, 224250.0, 227500.0, 227500.0, 227500.0, 227500.0, 227500.0, 227500.0, 227500.0, 227500.0, 229500.0, 229500.0, 229500.0, 229500.0, 232000.0, 232000.0, 233500.0, 235000.0, 235000.0, 235000.0, 235000.0, 235250.0, 235250.0, 235250.0, 235250.0, 238250.0, 238250.0, 241250.0, 241250.0, 241250.0, 242750.0, 242750.0, 242750.0, 242750.0, 242750.0, 242750.0, 243750.0, 243750.0, 243750.0, 243750.0, 243750.0, 243750.0, 243750.0, 243750.0, 243750.0, 243750.0, 243750.0, 246500.0, 246500.0, 249250.0, 249250.0, 249250.0, 249250.0, 249250.0, 249250.0, 249250.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 254750.0, 254750.0, 254750.0, 254750.0, 255250.0, 255250.0, 255250.0, 255250.0, 258250.0, 258250.0, 258250.0, 258250.0, 258250.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 269500.0, 269750.0, 269750.0, 269750.0, 269750.0, 269750.0, 269750.0, 273000.0, 273000.0, 273000.0, 275250.0, 275250.0, 279500.0, 279500.0, 280250.0, 280250.0, 280250.0, 280250.0, 280250.0, 280250.0, 280250.0, 280250.0, 280250.0, 280250.0, 282250.0, 282250.0, 282250.0, 282250.0, 282250.0, 282250.0, 287000.0, 287000.0, 287000.0, 287000.0, 287000.0, 287000.0, 291250.0, 291500.0, 291500.0, 291500.0, 291500.0, 293500.0, 293500.0, 293500.0, 296000.0, 296000.0, 296000.0, 296000.0, 298250.0, 298250.0, 298250.0, 298250.0, 298250.0, 300250.0, 300250.0, 300250.0, 300250.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 306000.0, 309500.0, 309500.0, 309500.0, 309500.0, 309500.0, 311500.0, 311500.0, 311500.0, 311500.0, 311500.0, 314500.0, 314500.0, 314500.0, 315750.0, 315750.0, 315750.0, 315750.0, 315750.0, 315750.0, 315750.0, 318500.0, 319250.0, 319250.0, 319250.0, 319250.0, 323250.0, 323250.0, 323250.0, 323250.0, 323250.0, 327750.0, 329250.0, 329250.0, 329250.0, 329750.0, 329750.0, 329750.0, 329750.0, 329750.0, 329750.0, 329750.0, 329750.0, 329750.0, 331750.0, 331750.0, 331750.0, 331750.0, 337500.0, 338000.0, 338000.0, 338000.0, 338000.0, 338000.0, 338000.0, 338000.0, 338000.0, 338000.0, 338000.0, 338000.0, 338000.0, 340750.0, 340750.0, 340750.0, 340750.0, 342000.0, 342000.0, 342000.0, 342000.0, 342000.0, 342000.0, 342000.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 350000.0, 350000.0, 350000.0, 351500.0, 351500.0, 353000.0, 353000.0, 353750.0, 353750.0, 353750.0, 353750.0, 353750.0, 353750.0, 353750.0, 356500.0, 358000.0, 358000.0, 358000.0, 358750.0, 358750.0, 358750.0, 358750.0, 358750.0, 360750.0, 360750.0, 360750.0, 360750.0, 364000.0, 364000.0, 364000.0, 364000.0, 366500.0, 366500.0, 366500.0, 366500.0, 366500.0, 369000.0, 369000.0, 369000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 374000.0, 374000.0, 374000.0, 374000.0, 374000.0, 374000.0, 376750.0, 379750.0, 379750.0, 379750.0, 379750.0, 379750.0, 379750.0, 379750.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 384750.0, 384750.0, 384750.0, 384750.0, 384750.0, 384750.0, 384750.0, 384750.0, 384750.0, 384750.0, 387750.0, 387750.0, 387750.0, 387750.0, 387750.0, 387750.0, 387750.0, 389750.0, 389750.0, 389750.0, 389750.0, 389750.0, 389750.0, 392750.0, 392750.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 398250.0, 398250.0, 402500.0, 402500.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 406000.0, 406000.0, 408750.0, 410250.0, 411750.0, 411750.0, 411750.0, 411750.0, 412250.0, 412250.0, 412250.0, 412250.0, 412250.0, 412250.0, 412250.0, 412250.0, 414250.0, 414250.0, 414250.0, 414250.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 422750.0, 424000.0, 424750.0, 424750.0, 424750.0, 424750.0, 424750.0, 424750.0, 424750.0, 424750.0, 427500.0, 427500.0, 429000.0, 430250.0, 430250.0, 430250.0, 430250.0, 430250.0, 430250.0, 430250.0, 430250.0, 430250.0, 433500.0, 433500.0, 433500.0, 433500.0, 433500.0, 433500.0, 433500.0, 433500.0, 433500.0, 436000.0, 436000.0, 436000.0, 436000.0, 437500.0, 437500.0, 439000.0, 440500.0, 440500.0, 440500.0, 440500.0, 441250.0, 441250.0, 441250.0, 441250.0, 441250.0, 441250.0, 441250.0, 441250.0, 441250.0, 441250.0, 443250.0, 443250.0, 443250.0, 446500.0, 446500.0, 446500.0, 446500.0, 446500.0, 446500.0, 450750.0, 450750.0, 450750.0, 450750.0, 450750.0, 450750.0, 450750.0, 451000.0, 451000.0, 451000.0, 451000.0, 454250.0, 454250.0, 454250.0, 454250.0, 454250.0, 454250.0, 454250.0, 454250.0, 456750.0, 456750.0, 456750.0, 456750.0, 456750.0, 456750.0, 459500.0, 461000.0, 461000.0, 461000.0, 461000.0, 461000.0, 461000.0, 461000.0, 461000.0, 461000.0, 461000.0, 461000.0, 465250.0, 465250.0, 466750.0, 466750.0, 466750.0, 466750.0, 466750.0, 466750.0, 466750.0, 469500.0, 469500.0, 471000.0, 471000.0, 471000.0, 472500.0, 472500.0, 472500.0, 472500.0, 472500.0, 473750.0, 473750.0, 473750.0, 473750.0, 473750.0, 475750.0, 475750.0, 475750.0, 475750.0, 478500.0, 478500.0, 483000.0, 484500.0, 484500.0, 484500.0, 484500.0, 484500.0, 484500.0, 484500.0, 484500.0, 484500.0, 484500.0, 487250.0, 487250.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 494250.0, 494250.0, 497000.0, 497000.0, 497000.0, 501250.0, 501250.0, 501250.0, 501250.0, 501250.0, 504000.0, 504000.0, 504000.0, 505500.0, 505500.0, 505500.0, 505500.0, 505500.0, 508500.0, 509500.0, 509500.0, 509500.0, 509500.0, 509500.0, 509500.0, 509500.0, 509500.0, 512500.0, 512500.0, 512500.0, 512500.0, 515500.0, 515500.0, 515500.0, 515500.0, 515500.0, 520500.0, 520500.0, 520500.0, 520500.0, 520500.0, 520500.0, 520500.0, 520500.0, 520500.0, 520500.0, 520500.0, 520500.0, 524750.0, 524750.0, 524750.0, 526250.0, 526250.0, 526750.0, 526750.0, 526750.0, 526750.0, 526750.0, 526750.0, 529250.0, 531250.0, 531250.0, 531250.0, 531250.0, 538500.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540250.0, 540250.0, 540250.0, 540250.0, 540250.0, 544750.0, 544750.0, 544750.0, 546250.0, 546250.0, 546250.0, 546250.0, 547750.0, 547750.0, 547750.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 550750.0, 550750.0, 553000.0, 553000.0, 553000.0, 557000.0, 557000.0, 557000.0, 557000.0, 557000.0, 557000.0, 557000.0, 559750.0, 559750.0, 559750.0, 561000.0, 561000.0, 561000.0, 563500.0, 563500.0, 563500.0, 563500.0, 563500.0, 563500.0, 567000.0, 567000.0, 567000.0, 567000.0, 567000.0, 569250.0, 569250.0, 572000.0, 572000.0, 573500.0, 573500.0, 574500.0, 574500.0, 574500.0, 574500.0, 574500.0, 574500.0, 574500.0, 574500.0, 574500.0, 574500.0, 577237.3125, 577237.3125, 577237.3125, 577237.3125, 577237.3125, 577237.3125], "elapsed": [5074.136018753052, 7844.094753265381, 7844.094753265381, 7844.094753265381, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 17844.44260597229, 27931.371212005615, 27931.371212005615, 27931.371212005615, 27931.371212005615, 27931.371212005615, 27931.371212005615, 27931.371212005615, 27931.371212005615, 36769.06991004944, 36769.06991004944, 36769.06991004944, 36769.06991004944, 36769.06991004944, 36769.06991004944, 41696.92587852478, 41696.92587852478, 41696.92587852478, 42971.23074531555, 42971.23074531555, 42971.23074531555, 42971.23074531555, 42971.23074531555, 47496.5398311615, 47496.5398311615, 50345.75533866882, 50345.75533866882, 50345.75533866882, 51999.1991519928, 51999.1991519928, 51999.1991519928, 51999.1991519928, 51999.1991519928, 51999.1991519928, 51999.1991519928, 63183.94637107849, 63183.94637107849, 63183.94637107849, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 65648.07772636414, 69609.38429832458, 69609.38429832458, 69609.38429832458, 69609.38429832458, 69609.38429832458, 76682.72161483765, 76682.72161483765, 76682.72161483765, 76682.72161483765, 76682.72161483765, 76682.72161483765, 76682.72161483765, 81467.74554252625, 81467.74554252625, 84409.73830223083, 84409.73830223083, 84409.73830223083, 84409.73830223083, 84409.73830223083, 87561.61451339722, 89382.741689682, 89382.741689682, 89382.741689682, 89382.741689682, 89382.741689682, 89382.741689682, 89382.741689682, 89382.741689682, 89382.741689682, 89382.741689682, 89382.741689682, 89382.741689682, 89382.741689682, 96144.00482177734, 96144.00482177734, 96144.00482177734, 96144.00482177734, 96144.00482177734, 96144.00482177734, 100059.9672794342, 100059.9672794342, 100059.9672794342, 100059.9672794342, 100059.9672794342, 107966.27712249756, 107966.27712249756, 107966.27712249756, 111077.7976512909, 111077.7976512909, 111077.7976512909, 111077.7976512909, 117057.43837356567, 117057.43837356567, 117057.43837356567, 117057.43837356567, 117057.43837356567, 117057.43837356567, 117057.43837356567, 117057.43837356567, 117057.43837356567, 117057.43837356567, 117057.43837356567, 117057.43837356567, 117057.43837356567, 122946.53248786926, 122946.53248786926, 122946.53248786926, 130237.77842521667, 132287.98818588257, 132287.98818588257, 132287.98818588257, 132287.98818588257, 132287.98818588257, 132287.98818588257, 132287.98818588257, 132287.98818588257, 132287.98818588257, 132287.98818588257, 138125.6115436554, 138125.6115436554, 138125.6115436554, 138125.6115436554, 138125.6115436554, 138125.6115436554, 138125.6115436554, 138125.6115436554, 145667.6971912384, 145667.6971912384, 145667.6971912384, 148322.60751724243, 148322.60751724243, 148322.60751724243, 148322.60751724243, 150024.0864753723, 150024.0864753723, 150024.0864753723, 150024.0864753723, 153885.60795783997, 153885.60795783997, 159550.3122806549, 159550.3122806549, 159550.3122806549, 164260.1673603058, 164260.1673603058, 164260.1673603058, 164260.1673603058, 164260.1673603058, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 174183.17675590515, 179846.98605537415, 179846.98605537415, 179846.98605537415, 179846.98605537415, 187086.95220947266, 187086.95220947266, 187086.95220947266, 187086.95220947266, 187086.95220947266, 187086.95220947266, 187086.95220947266, 187086.95220947266, 187086.95220947266, 190603.80673408508, 190603.80673408508, 190603.80673408508, 194997.38764762878, 194997.38764762878, 194997.38764762878, 194997.38764762878, 194997.38764762878, 194997.38764762878, 194997.38764762878, 194997.38764762878, 203081.86388015747, 203081.86388015747, 204748.75593185425, 204748.75593185425, 204748.75593185425, 204748.75593185425, 204748.75593185425, 204748.75593185425, 204748.75593185425, 204748.75593185425, 212122.4503517151, 212122.4503517151, 212122.4503517151, 212122.4503517151, 212122.4503517151, 212122.4503517151, 212122.4503517151, 214692.0087337494, 216586.95578575134, 216586.95578575134, 216586.95578575134, 216586.95578575134, 216586.95578575134, 223827.10528373718, 223827.10528373718, 223827.10528373718, 223827.10528373718, 226931.8401813507, 226931.8401813507, 226931.8401813507, 230363.2881641388, 230363.2881641388, 230363.2881641388, 230363.2881641388, 232772.71151542664, 232772.71151542664, 232772.71151542664, 232772.71151542664, 232772.71151542664, 232772.71151542664, 237345.97373008728, 237345.97373008728, 237345.97373008728, 237345.97373008728, 238831.14671707153, 238831.14671707153, 238831.14671707153, 238831.14671707153, 238831.14671707153, 238831.14671707153, 238831.14671707153, 246841.7091369629, 246841.7091369629, 246841.7091369629, 246841.7091369629, 246841.7091369629, 246841.7091369629, 249582.9746723175, 249582.9746723175, 252320.72710990906, 252320.72710990906, 252320.72710990906, 252320.72710990906, 252320.72710990906, 252320.72710990906, 252320.72710990906, 252320.72710990906, 252320.72710990906, 256732.75065422058, 256732.75065422058, 256732.75065422058, 256732.75065422058, 256732.75065422058, 256732.75065422058, 264592.01765060425, 264592.01765060425, 266816.4768218994, 266816.4768218994, 266816.4768218994, 266816.4768218994, 266816.4768218994, 266816.4768218994, 266816.4768218994, 266816.4768218994, 266816.4768218994, 266816.4768218994, 273840.3248786926, 273840.3248786926, 273840.3248786926, 273840.3248786926, 275533.15353393555, 275533.15353393555, 275533.15353393555, 275533.15353393555, 280187.79969215393, 280187.79969215393, 280187.79969215393, 280187.79969215393, 281634.45830345154, 281634.45830345154, 281634.45830345154, 281634.45830345154, 286383.2383155823, 286383.2383155823, 289056.01167678833, 289056.01167678833, 289056.01167678833, 289056.01167678833, 289056.01167678833, 289056.01167678833, 289056.01167678833, 289056.01167678833, 292967.1857357025, 292967.1857357025, 292967.1857357025, 302037.0304584503, 304688.2281303406, 304688.2281303406, 304688.2281303406, 304688.2281303406, 304688.2281303406, 304688.2281303406, 304688.2281303406, 304688.2281303406, 304688.2281303406, 311793.77365112305, 311793.77365112305, 311793.77365112305, 311793.77365112305, 311793.77365112305, 314165.5192375183, 314165.5192375183, 314165.5192375183, 314165.5192375183, 314165.5192375183, 314165.5192375183, 318958.82964134216, 318958.82964134216, 320354.1624546051, 320354.1624546051, 320354.1624546051, 320354.1624546051, 327145.5180644989, 327145.5180644989, 327145.5180644989, 327145.5180644989, 327145.5180644989, 327145.5180644989, 327145.5180644989, 330832.1523666382, 330832.1523666382, 330832.1523666382, 330832.1523666382, 336875.2861022949, 336875.2861022949, 342497.07865715027, 342497.07865715027, 342497.07865715027, 342497.07865715027, 342497.07865715027, 342497.07865715027, 349854.2449474335, 349854.2449474335, 349854.2449474335, 349854.2449474335, 349854.2449474335, 349854.2449474335, 352592.0524597168, 352592.0524597168, 352592.0524597168, 352592.0524597168, 352592.0524597168, 355399.04952049255, 355399.04952049255, 357540.02690315247, 357540.02690315247, 357540.02690315247, 357540.02690315247, 357540.02690315247, 357540.02690315247, 357540.02690315247, 357540.02690315247, 357540.02690315247, 357540.02690315247, 361997.9622364044, 361997.9622364044, 364706.44545555115, 367539.26396369934, 367539.26396369934, 367539.26396369934, 367539.26396369934, 367539.26396369934, 367539.26396369934, 367539.26396369934, 367539.26396369934, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 377051.72181129456, 383868.16143989563, 383868.16143989563, 383868.16143989563, 383868.16143989563, 383868.16143989563, 383868.16143989563, 383868.16143989563, 391017.8828239441, 391017.8828239441, 391017.8828239441, 391017.8828239441, 391017.8828239441, 391017.8828239441, 394703.8369178772, 394703.8369178772, 394703.8369178772, 394703.8369178772, 394703.8369178772, 399050.8460998535, 399050.8460998535, 401543.1866645813, 401543.1866645813, 403366.2111759186, 403366.2111759186, 403366.2111759186, 403366.2111759186, 403366.2111759186, 408226.4680862427, 408226.4680862427, 408226.4680862427, 408226.4680862427, 408226.4680862427, 410940.15979766846, 410940.15979766846, 410940.15979766846, 413198.7452507019, 413198.7452507019, 413198.7452507019, 413198.7452507019, 413198.7452507019, 413198.7452507019, 413198.7452507019, 417189.23592567444, 417189.23592567444, 417189.23592567444, 417189.23592567444, 417189.23592567444, 423758.7032318115, 423758.7032318115, 423758.7032318115, 423758.7032318115, 423758.7032318115, 423758.7032318115, 423758.7032318115, 423758.7032318115, 427620.9728717804, 427620.9728717804, 427620.9728717804, 427620.9728717804, 431880.3939819336, 431880.3939819336, 434317.9488182068, 437409.841299057, 437409.841299057, 437409.841299057, 437409.841299057, 438953.2573223114, 438953.2573223114, 438953.2573223114, 438953.2573223114, 443909.70945358276, 443909.70945358276, 449681.0898780823, 449681.0898780823, 449681.0898780823, 452803.915977478, 452803.915977478, 452803.915977478, 452803.915977478, 452803.915977478, 452803.915977478, 455167.2730445862, 455167.2730445862, 455167.2730445862, 455167.2730445862, 455167.2730445862, 455167.2730445862, 455167.2730445862, 455167.2730445862, 455167.2730445862, 455167.2730445862, 455167.2730445862, 459556.43701553345, 459556.43701553345, 464378.7672519684, 464378.7672519684, 464378.7672519684, 464378.7672519684, 464378.7672519684, 464378.7672519684, 464378.7672519684, 469074.21016693115, 469074.21016693115, 469074.21016693115, 469074.21016693115, 469074.21016693115, 469074.21016693115, 473852.48470306396, 473852.48470306396, 473852.48470306396, 473852.48470306396, 475334.5012664795, 475334.5012664795, 475334.5012664795, 475334.5012664795, 481339.2925262451, 481339.2925262451, 481339.2925262451, 481339.2925262451, 481339.2925262451, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 492639.37997817993, 499867.11406707764, 499867.11406707764, 499867.11406707764, 499867.11406707764, 499867.11406707764, 502559.0467453003, 503924.9863624573, 503924.9863624573, 503924.9863624573, 503924.9863624573, 503924.9863624573, 503924.9863624573, 510110.86440086365, 510110.86440086365, 510110.86440086365, 513839.80774879456, 513839.80774879456, 520993.70408058167, 520993.70408058167, 523086.7006778717, 523086.7006778717, 523086.7006778717, 523086.7006778717, 523086.7006778717, 523086.7006778717, 523086.7006778717, 523086.7006778717, 523086.7006778717, 523086.7006778717, 526816.0598278046, 526816.0598278046, 526816.0598278046, 526816.0598278046, 526816.0598278046, 526816.0598278046, 533435.2123737335, 533435.2123737335, 533435.2123737335, 533435.2123737335, 533435.2123737335, 533435.2123737335, 540265.7191753387, 541345.0260162354, 541345.0260162354, 541345.0260162354, 541345.0260162354, 544847.0764160156, 544847.0764160156, 544847.0764160156, 549048.4540462494, 549048.4540462494, 549048.4540462494, 549048.4540462494, 553168.5576438904, 553168.5576438904, 553168.5576438904, 553168.5576438904, 553168.5576438904, 556943.2444572449, 556943.2444572449, 556943.2444572449, 556943.2444572449, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 567527.0707607269, 574006.3278675079, 574006.3278675079, 574006.3278675079, 574006.3278675079, 574006.3278675079, 577693.0696964264, 577693.0696964264, 577693.0696964264, 577693.0696964264, 577693.0696964264, 582603.4979820251, 582603.4979820251, 582603.4979820251, 584971.2119102478, 584971.2119102478, 584971.2119102478, 584971.2119102478, 584971.2119102478, 584971.2119102478, 584971.2119102478, 589540.4233932495, 591196.5341567993, 591196.5341567993, 591196.5341567993, 591196.5341567993, 598247.5855350494, 598247.5855350494, 598247.5855350494, 598247.5855350494, 598247.5855350494, 606312.9658699036, 609414.2782688141, 609414.2782688141, 609414.2782688141, 611133.83436203, 611133.83436203, 611133.83436203, 611133.83436203, 611133.83436203, 611133.83436203, 611133.83436203, 611133.83436203, 611133.83436203, 614812.6192092896, 614812.6192092896, 614812.6192092896, 614812.6192092896, 625718.2869911194, 627885.9694004059, 627885.9694004059, 627885.9694004059, 627885.9694004059, 627885.9694004059, 627885.9694004059, 627885.9694004059, 627885.9694004059, 627885.9694004059, 627885.9694004059, 627885.9694004059, 627885.9694004059, 632746.5946674347, 632746.5946674347, 632746.5946674347, 632746.5946674347, 635148.4842300415, 635148.4842300415, 635148.4842300415, 635148.4842300415, 635148.4842300415, 635148.4842300415, 635148.4842300415, 643718.7433242798, 643718.7433242798, 643718.7433242798, 643718.7433242798, 643718.7433242798, 643718.7433242798, 643718.7433242798, 643718.7433242798, 649636.3956928253, 649636.3956928253, 649636.3956928253, 652268.800497055, 652268.800497055, 655089.1816616058, 655089.1816616058, 656981.7850589752, 656981.7850589752, 656981.7850589752, 656981.7850589752, 656981.7850589752, 656981.7850589752, 656981.7850589752, 661622.8218078613, 664246.1793422699, 664246.1793422699, 664246.1793422699, 665936.0926151276, 665936.0926151276, 665936.0926151276, 665936.0926151276, 665936.0926151276, 669924.1499900818, 669924.1499900818, 669924.1499900818, 669924.1499900818, 675781.4817428589, 675781.4817428589, 675781.4817428589, 675781.4817428589, 680029.7665596008, 680029.7665596008, 680029.7665596008, 680029.7665596008, 680029.7665596008, 684051.4740943909, 684051.4740943909, 684051.4740943909, 690304.3518066406, 690304.3518066406, 690304.3518066406, 690304.3518066406, 690304.3518066406, 690304.3518066406, 694254.0311813354, 694254.0311813354, 694254.0311813354, 694254.0311813354, 694254.0311813354, 694254.0311813354, 698855.1452159882, 704487.7436161041, 704487.7436161041, 704487.7436161041, 704487.7436161041, 704487.7436161041, 704487.7436161041, 704487.7436161041, 705902.6744365692, 705902.6744365692, 705902.6744365692, 705902.6744365692, 705902.6744365692, 705902.6744365692, 715334.2881202698, 715334.2881202698, 715334.2881202698, 715334.2881202698, 715334.2881202698, 715334.2881202698, 715334.2881202698, 715334.2881202698, 715334.2881202698, 715334.2881202698, 720020.7934379578, 720020.7934379578, 720020.7934379578, 720020.7934379578, 720020.7934379578, 720020.7934379578, 720020.7934379578, 723662.3311042786, 723662.3311042786, 723662.3311042786, 723662.3311042786, 723662.3311042786, 723662.3311042786, 728300.3582954407, 728300.3582954407, 735121.8965053558, 735121.8965053558, 735121.8965053558, 735121.8965053558, 735121.8965053558, 735121.8965053558, 735121.8965053558, 735121.8965053558, 735121.8965053558, 735121.8965053558, 735121.8965053558, 738934.0875148773, 738934.0875148773, 746112.092256546, 746112.092256546, 748896.8498706818, 748896.8498706818, 748896.8498706818, 748896.8498706818, 748896.8498706818, 748896.8498706818, 752450.1166343689, 752450.1166343689, 757049.7748851776, 759675.1556396484, 762600.2948284149, 762600.2948284149, 762600.2948284149, 762600.2948284149, 764464.5810127258, 764464.5810127258, 764464.5810127258, 764464.5810127258, 764464.5810127258, 764464.5810127258, 764464.5810127258, 764464.5810127258, 768102.9198169708, 768102.9198169708, 768102.9198169708, 768102.9198169708, 778468.4367179871, 778468.4367179871, 778468.4367179871, 778468.4367179871, 778468.4367179871, 778468.4367179871, 778468.4367179871, 778468.4367179871, 778468.4367179871, 778468.4367179871, 778468.4367179871, 783118.488073349, 785617.1140670776, 787651.7646312714, 787651.7646312714, 787651.7646312714, 787651.7646312714, 787651.7646312714, 787651.7646312714, 787651.7646312714, 787651.7646312714, 792473.6845493317, 792473.6845493317, 795276.1518955231, 797939.3377304077, 797939.3377304077, 797939.3377304077, 797939.3377304077, 797939.3377304077, 797939.3377304077, 797939.3377304077, 797939.3377304077, 797939.3377304077, 805023.931980133, 805023.931980133, 805023.931980133, 805023.931980133, 805023.931980133, 805023.931980133, 805023.931980133, 805023.931980133, 805023.931980133, 809315.107345581, 809315.107345581, 809315.107345581, 809315.107345581, 811709.3291282654, 811709.3291282654, 814226.1590957642, 817297.8985309601, 817297.8985309601, 817297.8985309601, 817297.8985309601, 819263.055562973, 819263.055562973, 819263.055562973, 819263.055562973, 819263.055562973, 819263.055562973, 819263.055562973, 819263.055562973, 819263.055562973, 819263.055562973, 823029.9146175385, 823029.9146175385, 823029.9146175385, 829244.5549964905, 829244.5549964905, 829244.5549964905, 829244.5549964905, 829244.5549964905, 829244.5549964905, 837001.993894577, 837001.993894577, 837001.993894577, 837001.993894577, 837001.993894577, 837001.993894577, 837001.993894577, 838169.8763370514, 838169.8763370514, 838169.8763370514, 838169.8763370514, 844292.9668426514, 844292.9668426514, 844292.9668426514, 844292.9668426514, 844292.9668426514, 844292.9668426514, 844292.9668426514, 844292.9668426514, 848453.5090923309, 848453.5090923309, 848453.5090923309, 848453.5090923309, 848453.5090923309, 848453.5090923309, 853320.4464912415, 856341.0720825195, 856341.0720825195, 856341.0720825195, 856341.0720825195, 856341.0720825195, 856341.0720825195, 856341.0720825195, 856341.0720825195, 856341.0720825195, 856341.0720825195, 856341.0720825195, 863521.5439796448, 863521.5439796448, 866269.0236568451, 866269.0236568451, 866269.0236568451, 866269.0236568451, 866269.0236568451, 866269.0236568451, 866269.0236568451, 871053.717136383, 871053.717136383, 873805.2885532379, 873805.2885532379, 873805.2885532379, 876507.3683261871, 876507.3683261871, 876507.3683261871, 876507.3683261871, 876507.3683261871, 878916.3949489594, 878916.3949489594, 878916.3949489594, 878916.3949489594, 878916.3949489594, 882425.6582260132, 882425.6582260132, 882425.6582260132, 882425.6582260132, 887127.6230812073, 887127.6230812073, 895803.1892776489, 899134.357213974, 899134.357213974, 899134.357213974, 899134.357213974, 899134.357213974, 899134.357213974, 899134.357213974, 899134.357213974, 899134.357213974, 899134.357213974, 903700.6638050079, 903700.6638050079, 906234.160900116, 906234.160900116, 906234.160900116, 906234.160900116, 906234.160900116, 912814.5487308502, 912814.5487308502, 912814.5487308502, 912814.5487308502, 912814.5487308502, 912814.5487308502, 912814.5487308502, 912814.5487308502, 912814.5487308502, 916582.3543071747, 916582.3543071747, 920960.5801105499, 920960.5801105499, 920960.5801105499, 928327.4154663086, 928327.4154663086, 928327.4154663086, 928327.4154663086, 928327.4154663086, 933786.694765091, 933786.694765091, 933786.694765091, 936799.947977066, 936799.947977066, 936799.947977066, 936799.947977066, 936799.947977066, 942287.7616882324, 944801.3527393341, 944801.3527393341, 944801.3527393341, 944801.3527393341, 944801.3527393341, 944801.3527393341, 944801.3527393341, 944801.3527393341, 950133.2061290741, 950133.2061290741, 950133.2061290741, 950133.2061290741, 955949.6192932129, 955949.6192932129, 955949.6192932129, 955949.6192932129, 955949.6192932129, 965654.1337966919, 965654.1337966919, 965654.1337966919, 965654.1337966919, 965654.1337966919, 965654.1337966919, 965654.1337966919, 965654.1337966919, 965654.1337966919, 965654.1337966919, 965654.1337966919, 965654.1337966919, 972880.8422088623, 972880.8422088623, 972880.8422088623, 975837.9151821136, 975837.9151821136, 977702.3010253906, 977702.3010253906, 977702.3010253906, 977702.3010253906, 977702.3010253906, 977702.3010253906, 982312.2627735138, 985820.7743167877, 985820.7743167877, 985820.7743167877, 985820.7743167877, 998924.8886108398, 1002391.8981552124, 1002391.8981552124, 1002391.8981552124, 1002391.8981552124, 1002391.8981552124, 1002391.8981552124, 1002391.8981552124, 1002391.8981552124, 1002391.8981552124, 1002391.8981552124, 1002391.8981552124, 1002391.8981552124, 1003965.0287628174, 1003965.0287628174, 1003965.0287628174, 1003965.0287628174, 1003965.0287628174, 1011505.5658817291, 1011505.5658817291, 1011505.5658817291, 1014518.2511806488, 1014518.2511806488, 1014518.2511806488, 1014518.2511806488, 1017464.2260074615, 1017464.2260074615, 1017464.2260074615, 1018993.4194087982, 1018993.4194087982, 1018993.4194087982, 1018993.4194087982, 1018993.4194087982, 1018993.4194087982, 1018993.4194087982, 1023419.8644161224, 1023419.8644161224, 1027187.255859375, 1027187.255859375, 1027187.255859375, 1034185.0218772888, 1034185.0218772888, 1034185.0218772888, 1034185.0218772888, 1034185.0218772888, 1034185.0218772888, 1034185.0218772888, 1039140.9599781036, 1039140.9599781036, 1039140.9599781036, 1041591.4008617401, 1041591.4008617401, 1041591.4008617401, 1045756.7811012268, 1045756.7811012268, 1045756.7811012268, 1045756.7811012268, 1045756.7811012268, 1045756.7811012268, 1052106.6284179688, 1052106.6284179688, 1052106.6284179688, 1052106.6284179688, 1052106.6284179688, 1056050.4233837128, 1056050.4233837128, 1060704.951763153, 1060704.951763153, 1063548.1674671173, 1063548.1674671173, 1065899.816274643, 1065899.816274643, 1065899.816274643, 1065899.816274643, 1065899.816274643, 1065899.816274643, 1065899.816274643, 1065899.816274643, 1065899.816274643, 1065899.816274643, 1070538.754169464, 1070538.754169464, 1070538.754169464, 1070538.754169464, 1070538.754169464, 1070538.754169464], "prediction_length": 1168, "reference": "Hallo, mein Name ist Michał Pietruszka und es ist mir eine Freude, Ihnen das Paper mit dem Titel Sparsifying Transformer Models with Trainable Representation Pooling vorzustellen. Die Arbeit wurde bei Applica KI in Zusammenarbeit mit Lukasz Borchmann und Lukasz Garncarek durchgeführt. Lassen Sie mich mit den Problemen beginnen, die in unserer Arbeit abgehandelt werden. Unsere Methode funktioniert gut für die Fälle, in denen lange Eingaben berücksichtigt werden. Grob gesagt ist sie für Aufgaben und Eingaben von über zweitausend Token gedacht, wo die Zieltexte kürzer als die vorgegebenen Eingaben sind. Dies führt zu einigen spezifischen Anwendungen in der NLP. Man kann sich zum Beispiel vorstellen, dass ein langes Dokument zusammengefasst, klassifiziert und eine Frage darüber beantwortet werden muss und Informationen oder einige Schlüsselsätze extrahiert werden müssen. Erinnern wir uns an den Vanilla-Transformer und sein Problem mit der Aufmerksamkeitskomplexität, die vom Quadrat der Eingabezeile abhängt. Im Vanilla-Transformer müssen bei voller Aufmerksamkeitskonnektivität die Relationen jedes Token zu jedem anderen Token berechnet werden. Die rechnerische Komplexität der Aufmerksamkeit hängt von der Reihe der Schichten l, der Sequenzlänge n, einer weiteren Sequenzlänge und der Dimensionalität der Repräsentationen ab. Ähnlich verhält es sich mit der Cross-Attention des Decoders zu diesem Bild auf der rechten Seite, wobei der einzige Unterschied darin besteht, dass die Ziel-Token in diesem Fall auf die Eingabe-Token gerichtet sind. Das sieht man in dieser Formel. Der BLEU-Score stellt Relationen dar, die berechnet werden müssen. Im Falle der vollständigen Aufmerksamkeit müssen wir jede Relation innerhalb der Eingabe-Sequenz berechnen. Jetzt sehen wir, was passiert, wenn wir einen blockweisen Encoder haben, der die Konnektivität der Token so einschränkt, dass sie nur andere Token in der Nähe sehen können. Der Text wird in Blöcken gelesen, was die Reihe der Berechnungen auf der Encoder-Seite drastisch reduzieren kann. Aber die Cross-Attention des Decoders wird so nicht verbessert, da jedes Eingabe-Token ohnehin an den Decoder weitergegeben wird. Diese Methode wird oft als Fusion im Decoder bezeichnet. Die Verbesserung hier kann so interpretiert werden, dass eine der Abhängigkeiten von n durch eine andere Konstante m ersetzt wird, die die Blockgröße darstellt. Unsere wichtigste Beobachtung ist, dass die meisten Token für eine Vielzahl von Aufgaben irrelevant sind und fast vollständig vernachlässigt werden können. Dies ist beispielhaft auf der Folie dargestellt. Nur ein Teil der Eingaben ist für die gewünschte Ausgabe relevant. Zum Beispiel. Man kann einen Artikel einmal lesen, die wichtigsten Teile mit einem Textmarker markieren und dann eine Zusammenfassung erstellen, die nur auf diesem Teil aus der mittleren Phase basiert. Die Kosten für die Hervorhebung und die Entscheidung, ob das aktuelle Token für die Erstellung der Zusammenfassung wesentlich ist, sind somit gering und hängen nur von der Repräsentation des Token ab. Das Pooling der hervorgehobenen Token ist möglich. Das ist unserem Top-k-Operator zu verdanken und die Kosten sind vernachlässigbar. Die Kosten für die Erstellung einer Zusammenfassung aus einer gekürzten Eingabe sind ebenfalls viel niedriger als beim Vanilla-Modell, wenn die gesamte Eingabe berücksichtigt wird. Aber hier stellt sich eine Frage. Wie kann man wichtige Token auswählen und Gradienten zu dieser Auswahl zurückverfolgen? Das zugrundeliegende wesentliche Problem, das wir lösen, besteht darin, einen trainierbaren Auswahlmechanismus vorzuschlagen. Dieser ermöglicht es, dass der Gradient während des Trainings rückverfolgt werden kann, sodass das Netzwerk lernen kann, die wichtigsten Token auszuwählen. Präziser ausgedrückt: Angesichts einiger Unterwert-Einbettungen, die aus einer einfachen linearen Schicht stammen, besteht die Aufgabe darin, die Einbettungen mit dem höchsten Score zu ermitteln. Zunächst wird die Sequenz permutiert, und es werden Paare gebildet, sodass der höher bewertete Vektor mit dem niedriger bewerteten zusammengebracht wird. Anschließend werden die Gewichtungen mithilfe von einer verstärkten Softmax über die Scores berechnet. Nach jeder Turnierrunde werden neue Vektoren und Scores als lineare Kombination dieser Paare mit den erhaltenen Gewichtungen zusammengestellt. Kurz gesagt kombinieren wir sie linear, indem wir eine Softmax über ihre Scores durchführen. Während man zwei Token kombiniert, kann auch schlechte Qualität erzeugt werden. Aber auch die Übertragung der Gradienten auf alle eingegebenen Einbettungen wird ermöglicht. Kurz gesagt wollen wir ein trainierbares Top-k vorschlagen, das eine turnierähnliche Soft-Selection bei jedem Schritt ausführt. Aus einem anderen Blickwinkel betrachtet, folgt das Repräsentationspooling auf die Encoder-Schicht. Zunächst wird jede Repräsentation bewertet. Dann werden nur jene mit den höchsten Scores an die nächste Ebene weitergegeben. Die Kodierung kann wie in der Standard-Transformer-Architektur auf die volle Länge der Eingabe durchgeführt werden. Es ist jedoch möglich, Text in Blöcken mit fester Länge zu verarbeiten und global die beste Repräsentation zu wählen. Hier ist ein Beispiel für das nach dem Encoder eingeführte Repräsentationspooling. Dies hatte einen direkten Einfluss auf die Ursache der Cross-Attention. Diese hängt nicht von der Länge der Eingabe N ab, sondern von der Konstante K, welche die gepoolte Länge darstellt. Diese Konstante gibt an, wie viele Repräsentationen ausgewählt und an den Decoder übergeben werden. Die Erstellung einer Zusammenfassung aus einem kürzeren Text ist wesentlich billiger als die frühere Lösung. Die Sequenzlänge kann um einen großen Faktor verkürzt werden. Wir haben beispielsweise in unseren Experimenten k erfolgreich sechzehnmal oder sogar vierundsechzigmal kleiner als den Wert von n verwendet. Bitte beachten Sie, dass die positive Wirkung von blockweiser Kodierung und selbständiger Aufmerksamkeit anhaltend ist. Vergessen Sie nicht, dass die Rechenkosten der Aufmerksamkeit vom Quadrat der eingegebenen Länge abhängen. Die Reduzierung der Eingabe zu einem früheren Zeitpunkt während des Kodierungsprozesses kann die Kosten erheblich senken. Für das Pyramidion-Modell haben wir die Größe der Repräsentation bei der Ausgabe jeder ausgewählten Schicht eingegrenzt, was zu einer exponentiellen Verringerung der Rechenkosten führt, wenn die Kodierung fortschreitet. Wie Sie sehen können, sind die gesamten Rechenkosten eines vollständigen Encoders hier weniger als doppelt so hoch als die Kosten der ersten Schicht in voller Größe. Wenn das Pooling früher eingeführt wird, wird die Summe aller lila Quadrate auf eine Konstante begrenzt, die nicht von der Anzahl der Schichten abhängt. Die Konstante c kann durch die Anordnung der Pooling-Schichten innerhalb des Netzwerks beeinflusst werden. Unsere Verbesserungen wurden mit Eingaben in der Länge von achttausend Token verglichen. Die Abbildung zeigt, dass die beste Skalierbarkeit für die Tiefe des Netzwerks erreicht wird, wenn das Pooling aktiviert ist. Hier kann man feststellen, dass bei solchen langen Eingaben das Training des Pyramidions mit 24 Schichten billiger sein kann als das Training eines zweischichtigen Vanilla-Transformers. Ganz zu schweigen davon, wie schnell ein Vanilla-Transformer bei einer so langen Eingabe ungenügend Speicher haben kann. Der qualitative Vergleich unseres Trend-Pyramidions mit anderen Baselines wird anhand der langen Aufgabe mit der Zusammenfassung des Dokuments durchgeführt. Alternativ kann der Hauptteil eines Artikels von arXiv oder PubMed herangezogen werden, wo die Aufgabe darin besteht, eine Zusammenfassung zu erstellen. Man kann also sehen, dass der blockweise Ansatz, der unsere Baseline darstellt, auf modernsten Modellen basiert, während das Pyramidion die Leistung dieser konkurrenzfähigen Baseline beibehält oder verbessert. Gleichzeitig ist unser Modell zu achtzig Prozent schneller zu trainieren und zu über vierhundertfünfzig Prozent schneller bei der Inferenz im Vergleich zur blockweisen Baseline. Beide Modelle haben viel weniger Parameter und wurden von Grund auf für die ausgewählten Aufgaben trainiert. Frühere Ansätze zur Erzielung einer ähnlichen Leistung mussten mehr Parameter verwenden sowie vortrainierte grundlegende Modelle und zusätzliche Vortrainingsziele bei der Sprache nutzen. Wir laden Sie ein, unser vollständiges Paper zu lesen und unseren GitHub-Code zu verwenden. Vielen Dank fürs Zuschauen.", "source": ["2/acl_6060/dev/full_wavs/2022.acl-long.590.wav", "samplerate: 16000 Hz", "channels: 1", "duration: 09:37.237 min", "format: WAV (Microsoft) [WAV]", "subtype: Signed 16 bit PCM [PCM_16]"], "source_length": 577312.0}
{"index": 3, "prediction": "Hallo, das ist Yoweri Joe von der Harvard University. Ich bin sehr froh, ihre Arbeit zur Online-Semantik-Parsing für Latenzreduktion in taskorientiertem Dialog vorzustellen. Das ist ein Joint Work mit Jason, Michael, Anthony und Sam von Microsoft Cementing Machines. in task-oriented dialog Ein Benutzer interagiert mit einem System, das Anfragen von Benutzervertretern, normalerweise im Sprechen, bearbeitet. von der Endung der Benutzeransage bis zur Systemantwort Es gibt oft unmerkliche Verzögerungen. Unter der Hood wird das Benutzer-Audience in ein ausführbares Programm übersetzt. und dann ausgeführt , damit das System richtig reagieren kann. Hier ist das Programm als semant ischer Graph dargestellt, der die Berechnung skizziert. wo eine Note eine Funktion inruft und seine Kinder die Argumente sind Die großen N odes markieren augenblickliche Operationen , aber die anderen sind langsam auszuführen. bemerken, dass, unlike the simple example here we show, Diese Programme können oft kompliziertere Graphen sein. Jenseits der Baumstrukturen. in diesem talk wir stellten die frage können wir generieren das Programm und die Ausführung, bevor der Benutzer die Änderung fertigstellt, damit das System eine schnellere Reaktion erzielen kann. Das ist eine Online- Vorhersage und Entscheidung Problem. Es gibt viele andere in diesem Raum. Beispiele hierfür sind die gleichzeitige Übersetzung Wo ein Live-Interpreter eine Sprache in Echtzeit in eine andere übersetzt. Smart Text -Autokompilierung, um die Benutzerabsicht zu ermitteln. und über den Pool, wo die Fahrer geschickt werden, wo sie gebraucht werden könnten, basierend auf der vorhergesagten Nachfrage. Alle diese Szen arien haben eine Gemeinsamkeit: Es ist vorteilhaft, Entscheidungen zu treffen, bevor man andere Einträge sieht. In unserem Fall werden wir mit Online-Semantik parsen. was erwartet werden könnte, dass es schwierig ist, da wir wissen, was der Benutzer sagen könnte, und es ist auch untersucht , ohne formelle Bewertungsmetrik. Zuerst schauen wir uns an, wie ein normales System funktioniert. Es ist offline betrieben, indem es nur am Ende der Benutzeranweisung zum Programm parst. Hier wird der Kriptograph vorhergesagt, nachdem er alle Informationen gesehen hat. Im Gegensatz dazu schlagen wir ein Online-System vor, das bei jedem Alternativ-Präfix parsert. Zum Beispiel: Jedes Mal, wenn wir einen neuen Token sehen, prognostizieren wir einen neuen Graph. nicht gesagt da könnte er irres an der position von an der pool party mit barack obama Wir haben einen Grafik mit den rechten Noten. auf die Person und das Ereignis-Subjekt, aber das ist die falsche Zeitinformation. Dieser Prozess geht weiter. bis wir die vollen Benutzeranweisungen erhalten haben. Wie würde sich das auswirken? Die Exekution ist in der Offline-Systeme Wir haben am Ende den Programmgrafen. So dass das System an diesem Punkt mit der Ausführung beginnen kann. Denken Sie daran, dass die großen Knoten schnell funktionieren , also betrachten wir nur die Ausführungszeitlinie der farbigen langsamen Funktionen. Er stens können diese zwei Personenfunktionen parallel ausgeführt werden. und sie haben keine Abhängigkeit von anderen Funktionen. Als nächstes kann das No-C rit-Event dann ausgeführt werden, nachdem Ergebnisse von niedrigeren Noten erhalten wurden, und dann die Topfunktion yellt, so dass das ganze Programm fertig ist. Der Ausführungsprozess ist auf die Programmabhängigkeitsstruktur beschränkt. wo manche Operationen nicht parallelisiert werden können , was eine bemerkenswerte Verzögerung verursacht. in unserem Online-System, wo wir vorhersagen, wie wir gehen. Die Ausführung des Programms kann früher beginnen. Hier ist das Präfix nach Obama. Wir können mit Sicherheit vorhersagen, dass die F inder-Person-Funktion in einem Programm sein sollte , aber der Rest kann Fehler enthalten, da sie ausgegraben sind. Die Ausführung des Knoten punktes kann sofort in diesem Schritt gestartet werden. Dann , mit mehr Tok en, prognostizieren wir einen völlig neuen Graph , aber ein Teil davon wird bereits ausgeführt , also müssen wir nur den Rest der Nodes, von denen wir uns auch sicher sind, berücksichtigen. Hier kann eine andere gute Person parallel hingerichtet werden. Wiederum, wir können falsche Vorhersagen haben. mit mehr Text. Wir haben mehr Fähigkeit, es richtig zu machen , wie z.B. die Ereigniszeit hier, wo am auch richtig erwartet wird. Dann können wir den Rest ausführen , nach der Programmabhängigkeitsstruktur. Durch die Überlappung der Ausführungszeitlinie mit der Zeitlinie der Änderungen sparen wir eine große Zeit. Wir haben also die Aufgabe vorgeschlagen, Online-Sementizparsing zu machen. Eine zugrunde liegende Annahme ist, dass die Ausführungszeit die Modell vorhersagezeit dominiert, so dass wir nur Zeit gewinnen konnten, indem wir früher vorhersagen. Eine andere Annahme ist, dass die Vorhersage und die Ausführung den Hintergrund haben, der nicht sichtbar ist für Benutzer es ist nicht notwendig, eine Konsistenz zu halten Wir analysieren die Geschichte, also analysieren wir nach jedem Token von Anfang bis Ende. In besonderem Fall schlagen wir einen Zwei-Stufen-Ansatz vor. ein vorgeschlagener Schritt, der einen Graphen mit vollständiger Struktur vorhersagt. Und ein Select- Schritt, der die Noten auswählt, die es wert sind, in dieser Zeit ausgeführt zu werden. Wir haben zwei Varianten der vorgeschlagenen Methode. Der erste Ansatz kombiniert eine Sprachmodellvollendung mit vollständiger Ausdrucksfähigkeit zur Graph-Parsing. In der Regel ist das Präfix abt Obama erst durch ein Feintun-Bart-Sprachmodell abgeschlossen und dann in ein Programm mit vollem Offline-Parser übersetzt. Der zweite Ansatz sagt das Programm direkt von YouTube aus voraus. Benutzer -Other-Prefix. Das wird erreicht, indem ein einzelner Online-Parser angepasst wird, um den Gold graph von jedem Präfix zu übersetzen. Dies erleichtert dem Modell, die richtige Ansicht zu lernen. Ein bisschen detaillierter. Wie generieren wir diese Grafiken? Wir formulieren das Problem, indem wir eine serielle Version des Graphen generieren. Jede Note oder Kante wird durch eine Aktion dargestellt. Hier beginnen wir mit dem ersten Knoten. Die Nummer unten zeichnet die absolute Indexierung der Aktionsgeschichte auf. Dann haben wir die zweite Note. Als nächstes ist die Kante zwischen ihnen. Sie enthält den Zeiger zum Index der vorherigen Knoten. Und das Randlabel : Zero hier bedeutet, die neueste Knotenstelle zu verbinden. mit einem Nullpunkt, der durch die Nullaktion erzeugt wird. und Next Note, Next Edge. Dieser Prozess geht weiter , bis wir den vollen Graph generieren. Das zugrunde liegende Modell basiert auf einem Transformator mit einem selbstgesteuerten Mechanismus, ähnlich wie ein früherer übergangsbasierter Parser. Nach der Erstellung eines vollständigen Graphen Wir haben die Wahrscheinlichkeiten der Aktionsstufe, die verschiedenen Teilen des Graphen entsprechen. mit leichten, zuversichtlichen Subgraphen basierend auf der Schwellenheuristik, die ausgeführt werden soll. Später werden wir den Schwellenwert variieren, um unterschiedliche Kompromisse zwischen der Latenzreduktion und den Ausführungskosten zu erzielen. Eine formelle Bewertung der Online-Methoden Wir schlagen eine endgültige Latenzreduktion vor. Oh, FLR-Mänschchen. Hier ist ein Zusammenfassung , wie ein Offline-System die Ausführungszeitlinie beendet. in Online-Systemen Die Ausführung überschneidet sich mit der Zeitlinie der Abwechslung, also endet sie früher. FLR ist definiert als die Reduzierungszeit im Vergleich zum Offline-System, die am Ende der Ausführung markiert wird. Wir führen Experimente an zwei großen, konservierten, zementierten Parsing-Datensätzen durch. S. M. Kaflo und Ch. D. S. T. graph-based parser. Wenn man offline arbeitet, kann man die neuesten Leistungen bei der Parsing erzielen. Auf beiden Datensätzen erreicht das Outline Complete Modell auch Nontrivial. bluegane vergleicht mit der einfachen bislinie der note completion Jetzt schauen wir uns die Vorhersage und Genauigkeit unseres Grafikparser-Präfixes an. Wir testen die Übereinstimmung von Grafen zwei Pools zwischen der Generation und der Gergraph-Invalidationsdaten. in Y-Achsen , für jede Präfixlänge in X-Achsen , repräsentiert durch Prozentsätze. Jede dieser Kurven repräsentiert ein anderes Modell. mit dem Unterschied in den Trainingsdaten. Die Bottom Curve ist der Offline-Parser. und wir mischen in den Präfixdaten unterschiedliche Linien. um das Modell zu einem Online-Parser zu transformieren. Zum Beispiel das Legend-Präfix 80 % plus. Das bedeutet, dass das Modell mit den Präfixdaten gekennzeichnet ist. mit einer Länge von Perfekten, die größer ist als 80 % der Länge der vollständigen Ausdrucksform. Die obere linke Ecke ist ein gewünschter Bereich. wie wir sehen können , der Offline-Parser in Black Curve ist nicht gut auf den Präfixdaten, als wir mehr Präfixe in Training mischen, die Kurve ist liftend oben und links , besser auf alle die Präfixlänge. Allerdings ist die voll ordnungsgemäße Parsingleistung in der oberen rechten Punkt nicht beeinflusst. basierend auf diesen starken Ergebnissen Wie viel Latenz reduzieren wir? Wir messen die Zeit an der Anzahl der Quelltokens und simulieren verschiedene Funktionsausführungszeiten. Die Kur ven zeigen den Kompromiss zwischen der FLR-Metrik und den Ausführungskosten, gemessen an der Anzahl der übermäßigen Funktionskosten, die nicht korrekt sind. Das wird erreicht, indem man die Subgraph-Selektionsschwelle variiert. Eine höhere Schwelle wählt weniger Funktionen und Fehler aus , aber erhält eine kleinere FLR. Während die untere Schwelle aggressiver Programme auswählt und ausführt. Wir vergleichen die beiden Ansätze, die wir vorschlagen, in der Basislinie. Das tut nichts, als direkt den Offline-Parser anzuwenden. für den Online-Gebrauch. Regen ist das beste FLR und kostet Trade-off. Wir sehen , dass beide Methoden die Basislinie mit großer Marge schlagen und dass sie auf GDST ähnlicher funktionieren. Wenn die einzelne Funktion schneller ausgeführt wird, gibt es tendenziell mehr Run-Ausführungen und weniger Latenzreduktionsraum. wenn die Ausführung der einzelnen Funktionen langsamer ist Es gibt mehr Raum für FLR-Bevorderung. Unsere beiden Ansätze erzielen bessere Leistungen in verschiedenen Kostregionen. Insgesamt haben wir 30 bis 63 % relative Latenzreduktion erreicht. abhängig von der Ausführungszeit. und erlaubt Kosten. Schließlich haben wir einen Abbruch der durchschnittlichen Latenz reduktion in Tokens für jede Art der Funktionsknoten. Die erlaubte Ursache sind drei falsche Hinrichtungen. wie wir sehen können, sind sie gegen alle der borde Es gibt auch einige Funktionen, auf denen wir gewinnen. Impress ive Latenzreduktion, wo die rote Stange viel länger ist , wie z.B. bei Manager und Empfänger. Das sind Low-Level-Funktionen , die nicht viel Abhängigkeit haben. und andere. In der Schlussfolgerung Wir schlagen Online- Sem ester-Parsing als neue Aufgabe vor, die mit einer strengen Latenzreduktionsmetrik erforscht werden muss. mit einem starken grafischen Zementparser Wir haben eine relativ gute Latenzreduktion erreicht. entweder durch eine Pipeline -Ansatz mit L-Line-Erfüllung und einem vollen Parser oder direkt durch einen gelernten Parser auf den Präfixen. Unser Ansatz kann ein allgemeiner Rahmen sein und auf andere ausführbare semantische Repräsentationen in verschiedenen Bereichen angewendet werden. Zukunftswerke könnten eine schlauer Vorhersage- und Ausführungsintegrationsmethode erforschen. Danke für das Hören.", "delays": [3000.0, 3000.0, 3000.0, 7500.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 9000.0, 10250.0, 10250.0, 10250.0, 10250.0, 10250.0, 10250.0, 10250.0, 10250.0, 10250.0, 10250.0, 13000.0, 13000.0, 13000.0, 14500.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 20000.0, 20000.0, 20000.0, 22750.0, 22750.0, 22750.0, 24000.0, 24000.0, 24000.0, 24000.0, 25500.0, 25500.0, 26250.0, 26250.0, 26250.0, 26250.0, 26250.0, 29000.0, 29000.0, 29000.0, 29000.0, 30000.0, 30000.0, 30000.0, 30000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 36000.0, 36000.0, 37500.0, 38000.0, 38000.0, 38000.0, 38000.0, 38000.0, 38000.0, 38000.0, 38000.0, 40750.0, 40750.0, 40750.0, 42000.0, 42000.0, 42000.0, 42000.0, 42000.0, 42000.0, 42000.0, 44750.0, 44750.0, 44750.0, 44750.0, 46250.0, 46250.0, 47500.0, 47500.0, 47500.0, 47500.0, 47500.0, 47500.0, 47500.0, 50250.0, 50250.0, 51750.0, 51750.0, 51750.0, 51750.0, 52250.0, 52250.0, 52250.0, 52250.0, 52250.0, 52250.0, 55000.0, 55000.0, 55000.0, 56500.0, 56500.0, 56500.0, 56500.0, 57250.0, 57250.0, 57250.0, 57250.0, 57250.0, 57250.0, 57250.0, 60750.0, 60750.0, 60750.0, 60750.0, 60750.0, 60750.0, 60750.0, 60750.0, 60750.0, 63500.0, 63500.0, 64250.0, 64250.0, 64250.0, 64250.0, 64250.0, 66250.0, 66250.0, 66250.0, 69000.0, 69000.0, 69000.0, 69000.0, 69000.0, 69000.0, 69000.0, 71250.0, 71250.0, 71250.0, 71250.0, 71250.0, 71250.0, 75500.0, 77000.0, 77000.0, 77000.0, 77000.0, 77000.0, 78000.0, 78000.0, 78000.0, 78000.0, 78000.0, 78000.0, 78000.0, 78000.0, 78000.0, 78000.0, 81000.0, 81000.0, 81000.0, 81000.0, 81750.0, 81750.0, 81750.0, 81750.0, 83750.0, 83750.0, 83750.0, 83750.0, 83750.0, 83750.0, 83750.0, 86500.0, 87000.0, 87000.0, 87000.0, 87000.0, 87000.0, 91250.0, 91250.0, 91250.0, 91250.0, 91250.0, 91250.0, 91250.0, 91250.0, 91250.0, 91250.0, 91250.0, 94000.0, 94000.0, 95000.0, 95000.0, 95000.0, 95000.0, 95000.0, 95000.0, 99250.0, 99250.0, 99250.0, 99250.0, 99250.0, 99250.0, 99250.0, 99250.0, 99250.0, 100750.0, 100750.0, 100750.0, 100750.0, 100750.0, 100750.0, 100750.0, 100750.0, 100750.0, 100750.0, 103500.0, 103500.0, 103500.0, 105000.0, 105000.0, 108000.0, 108750.0, 108750.0, 108750.0, 108750.0, 108750.0, 108750.0, 108750.0, 108750.0, 108750.0, 108750.0, 108750.0, 108750.0, 111500.0, 111500.0, 111500.0, 113000.0, 113000.0, 113500.0, 113500.0, 113500.0, 120500.0, 120500.0, 120500.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 122000.0, 123000.0, 123000.0, 123000.0, 123000.0, 128500.0, 128500.0, 128500.0, 128500.0, 128500.0, 128500.0, 128500.0, 128500.0, 128500.0, 128500.0, 131250.0, 131250.0, 131250.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 136750.0, 138000.0, 138000.0, 138000.0, 138000.0, 138000.0, 138000.0, 138000.0, 138000.0, 138000.0, 138000.0, 142250.0, 142250.0, 142250.0, 142250.0, 142250.0, 142250.0, 143750.0, 143750.0, 144250.0, 144250.0, 144250.0, 144250.0, 144250.0, 147000.0, 147000.0, 148500.0, 148500.0, 148500.0, 148500.0, 148500.0, 148500.0, 148500.0, 148500.0, 149000.0, 149000.0, 149000.0, 149000.0, 149000.0, 151000.0, 151000.0, 151000.0, 151000.0, 151000.0, 151000.0, 154750.0, 154750.0, 154750.0, 154750.0, 154750.0, 154750.0, 154750.0, 154750.0, 154750.0, 154750.0, 154750.0, 157000.0, 157000.0, 157000.0, 157000.0, 157000.0, 157000.0, 157000.0, 157000.0, 160000.0, 161500.0, 161500.0, 161500.0, 161500.0, 161500.0, 161500.0, 161500.0, 161500.0, 161500.0, 161500.0, 161500.0, 163500.0, 163500.0, 163500.0, 163500.0, 166000.0, 166000.0, 166000.0, 166000.0, 166000.0, 166000.0, 166000.0, 168750.0, 168750.0, 168750.0, 168750.0, 168750.0, 171500.0, 171750.0, 171750.0, 171750.0, 171750.0, 171750.0, 174000.0, 174000.0, 174000.0, 174000.0, 174000.0, 174000.0, 176750.0, 176750.0, 176750.0, 176750.0, 176750.0, 176750.0, 176750.0, 176750.0, 176750.0, 176750.0, 176750.0, 176750.0, 179500.0, 179500.0, 179500.0, 179500.0, 181000.0, 181000.0, 181000.0, 181000.0, 181000.0, 182500.0, 182500.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 186750.0, 188000.0, 189250.0, 189250.0, 189250.0, 189250.0, 189250.0, 189250.0, 189250.0, 192000.0, 195000.0, 195250.0, 195250.0, 195250.0, 195250.0, 195250.0, 195250.0, 201000.0, 201000.0, 201000.0, 201000.0, 201000.0, 202500.0, 202500.0, 202500.0, 202500.0, 202500.0, 202500.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 206000.0, 210250.0, 210250.0, 210250.0, 210750.0, 210750.0, 210750.0, 210750.0, 213500.0, 213500.0, 213500.0, 215000.0, 215000.0, 215000.0, 215000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 220750.0, 221250.0, 221250.0, 221250.0, 221250.0, 221250.0, 221250.0, 221250.0, 221250.0, 223750.0, 223750.0, 223750.0, 223750.0, 223750.0, 223750.0, 223750.0, 226500.0, 226500.0, 227250.0, 227250.0, 227250.0, 227250.0, 230000.0, 230000.0, 231500.0, 231500.0, 231500.0, 231500.0, 231500.0, 231500.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 233000.0, 234250.0, 234250.0, 234250.0, 234250.0, 234250.0, 234250.0, 234250.0, 234250.0, 234250.0, 234250.0, 234250.0, 238500.0, 238500.0, 238500.0, 238500.0, 239000.0, 239000.0, 239000.0, 239000.0, 239000.0, 239000.0, 239000.0, 239000.0, 241750.0, 243250.0, 243250.0, 243250.0, 243250.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 244750.0, 246250.0, 246250.0, 246250.0, 246250.0, 246250.0, 247750.0, 247750.0, 247750.0, 249250.0, 249250.0, 249250.0, 249250.0, 249250.0, 249250.0, 249250.0, 250500.0, 250500.0, 250500.0, 250500.0, 250500.0, 250500.0, 250500.0, 250500.0, 250500.0, 250500.0, 253250.0, 254250.0, 254250.0, 254250.0, 254250.0, 254250.0, 254250.0, 254250.0, 254250.0, 257250.0, 257250.0, 257250.0, 257250.0, 257250.0, 257250.0, 259250.0, 259250.0, 259250.0, 262000.0, 262000.0, 262000.0, 262000.0, 265000.0, 265000.0, 265000.0, 265000.0, 266500.0, 266500.0, 266500.0, 266500.0, 266500.0, 266500.0, 266500.0, 266500.0, 266500.0, 266500.0, 266500.0, 266500.0, 269250.0, 269250.0, 269250.0, 270750.0, 270750.0, 270750.0, 271750.0, 271750.0, 271750.0, 271750.0, 277500.0, 278500.0, 278500.0, 278500.0, 278500.0, 278500.0, 278500.0, 278500.0, 278500.0, 278500.0, 278500.0, 278500.0, 278500.0, 278500.0, 278500.0, 283250.0, 283250.0, 284250.0, 284250.0, 284250.0, 284250.0, 284250.0, 284250.0, 284250.0, 288750.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 291750.0, 291750.0, 293250.0, 293250.0, 293250.0, 293250.0, 293250.0, 293250.0, 293250.0, 293250.0, 293250.0, 293250.0, 293250.0, 293250.0, 293250.0, 296000.0, 296000.0, 296000.0, 296000.0, 297500.0, 299000.0, 299000.0, 299000.0, 299000.0, 299000.0, 302000.0, 302000.0, 302000.0, 302000.0, 302000.0, 302500.0, 302500.0, 302500.0, 302500.0, 302500.0, 302500.0, 302500.0, 302500.0, 302500.0, 302500.0, 302500.0, 302500.0, 306250.0, 306250.0, 306250.0, 306250.0, 306250.0, 306250.0, 306250.0, 306250.0, 306250.0, 306250.0, 306250.0, 306250.0, 306250.0, 306250.0, 310000.0, 310000.0, 310000.0, 310000.0, 310000.0, 310000.0, 310000.0, 310000.0, 314250.0, 314250.0, 314250.0, 314250.0, 314250.0, 314250.0, 314250.0, 314250.0, 314250.0, 314250.0, 318500.0, 318500.0, 318500.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 319250.0, 324000.0, 324000.0, 324000.0, 324000.0, 324250.0, 324250.0, 324250.0, 328500.0, 328500.0, 328500.0, 328500.0, 328500.0, 328500.0, 329250.0, 329250.0, 329250.0, 329250.0, 329250.0, 332000.0, 333500.0, 333500.0, 333500.0, 335000.0, 335000.0, 336500.0, 336500.0, 336500.0, 336500.0, 338000.0, 338000.0, 340250.0, 340250.0, 340250.0, 340250.0, 340250.0, 340250.0, 340250.0, 340250.0, 340250.0, 340250.0, 343000.0, 343000.0, 344250.0, 344250.0, 344250.0, 344250.0, 344250.0, 344250.0, 344250.0, 344250.0, 344250.0, 347000.0, 353000.0, 353000.0, 353000.0, 353000.0, 353000.0, 354500.0, 354500.0, 354500.0, 354500.0, 354500.0, 354500.0, 354500.0, 354500.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 355750.0, 359250.0, 359250.0, 359250.0, 361250.0, 361250.0, 361250.0, 361250.0, 361250.0, 364000.0, 365000.0, 365000.0, 365000.0, 365000.0, 365000.0, 365000.0, 365000.0, 365000.0, 365000.0, 365000.0, 365000.0, 368750.0, 368750.0, 368750.0, 368750.0, 368750.0, 368750.0, 368750.0, 368750.0, 368750.0, 371500.0, 371500.0, 371500.0, 371500.0, 371500.0, 371500.0, 371500.0, 374250.0, 374250.0, 374250.0, 375500.0, 375500.0, 375500.0, 375500.0, 375500.0, 375500.0, 375500.0, 378000.0, 378000.0, 378000.0, 378000.0, 378000.0, 378000.0, 382250.0, 382250.0, 382250.0, 382250.0, 382250.0, 382250.0, 382250.0, 383750.0, 383750.0, 383750.0, 383750.0, 383750.0, 383750.0, 383750.0, 383750.0, 383750.0, 386500.0, 388000.0, 388000.0, 388250.0, 388250.0, 388250.0, 388250.0, 388250.0, 388250.0, 388250.0, 388250.0, 388250.0, 391000.0, 391000.0, 391000.0, 391000.0, 391000.0, 391000.0, 391000.0, 391000.0, 391000.0, 393500.0, 393500.0, 393500.0, 393500.0, 393500.0, 396000.0, 396000.0, 396000.0, 396000.0, 397000.0, 397000.0, 397000.0, 397000.0, 397000.0, 397000.0, 397000.0, 401500.0, 401500.0, 401500.0, 401500.0, 401500.0, 401500.0, 401500.0, 401500.0, 403000.0, 404500.0, 404500.0, 404500.0, 404500.0, 404500.0, 404500.0, 404500.0, 404500.0, 404500.0, 408750.0, 408750.0, 408750.0, 408750.0, 408750.0, 408750.0, 411750.0, 411750.0, 413250.0, 413250.0, 413750.0, 413750.0, 413750.0, 413750.0, 413750.0, 413750.0, 413750.0, 413750.0, 416500.0, 416500.0, 416500.0, 416500.0, 419000.0, 419000.0, 419000.0, 419000.0, 419000.0, 419000.0, 419000.0, 419000.0, 423250.0, 423250.0, 423250.0, 424750.0, 424750.0, 424750.0, 424750.0, 426000.0, 426000.0, 426000.0, 426000.0, 426000.0, 426000.0, 426000.0, 426000.0, 426000.0, 426000.0, 430750.0, 430750.0, 430750.0, 430750.0, 430750.0, 433500.0, 433500.0, 433500.0, 433500.0, 433500.0, 433500.0, 435500.0, 435500.0, 438250.0, 438250.0, 438250.0, 438250.0, 439750.0, 439750.0, 439750.0, 439750.0, 439750.0, 439750.0, 439750.0, 441750.0, 441750.0, 444500.0, 444500.0, 444500.0, 444500.0, 446000.0, 446000.0, 446000.0, 446000.0, 446000.0, 446000.0, 446000.0, 446000.0, 446000.0, 448750.0, 448750.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 453000.0, 457750.0, 457750.0, 457750.0, 459750.0, 459750.0, 459750.0, 459750.0, 459750.0, 459750.0, 459750.0, 462000.0, 462000.0, 462000.0, 462000.0, 462000.0, 462000.0, 462000.0, 462000.0, 464000.0, 464000.0, 468500.0, 468500.0, 468500.0, 468500.0, 468500.0, 468500.0, 468500.0, 468500.0, 468500.0, 468500.0, 468500.0, 468500.0, 468500.0, 473500.0, 473500.0, 473500.0, 473500.0, 473500.0, 473500.0, 473500.0, 473500.0, 473500.0, 473500.0, 477500.0, 477500.0, 477500.0, 477500.0, 477500.0, 477500.0, 477500.0, 477500.0, 477500.0, 482250.0, 482250.0, 482250.0, 482250.0, 483750.0, 484500.0, 484500.0, 484500.0, 484500.0, 484500.0, 484500.0, 487250.0, 488750.0, 490250.0, 491500.0, 491500.0, 491500.0, 491500.0, 491500.0, 491500.0, 491500.0, 491500.0, 491500.0, 491500.0, 491500.0, 494250.0, 495750.0, 497250.0, 497250.0, 497250.0, 497250.0, 497250.0, 497250.0, 497500.0, 497500.0, 497500.0, 497500.0, 500000.0, 500000.0, 500000.0, 500500.0, 500500.0, 500500.0, 500500.0, 502750.0, 502750.0, 502750.0, 502750.0, 502750.0, 502750.0, 505500.0, 505500.0, 505500.0, 505500.0, 505500.0, 505500.0, 508500.0, 508500.0, 508500.0, 508500.0, 508500.0, 508500.0, 508500.0, 508500.0, 511250.0, 511250.0, 511250.0, 511250.0, 511250.0, 511250.0, 511250.0, 511250.0, 514000.0, 514000.0, 515000.0, 515000.0, 515000.0, 515000.0, 515000.0, 517750.0, 518000.0, 518000.0, 518000.0, 518000.0, 518000.0, 518000.0, 518000.0, 518000.0, 518000.0, 520750.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 521500.0, 524500.0, 524500.0, 524500.0, 524500.0, 524750.0, 524750.0, 524750.0, 524750.0, 527500.0, 527500.0, 527500.0, 527500.0, 529000.0, 529000.0, 529000.0, 530500.0, 530500.0, 530500.0, 530500.0, 530500.0, 532000.0, 532000.0, 533500.0, 533500.0, 533500.0, 533500.0, 535000.0, 535000.0, 535000.0, 536500.0, 536500.0, 536500.0, 538000.0, 538000.0, 538000.0, 538000.0, 538000.0, 538000.0, 539500.0, 539500.0, 539500.0, 540000.0, 540000.0, 540000.0, 544000.0, 544000.0, 544000.0, 545750.0, 545750.0, 545750.0, 545750.0, 545750.0, 545750.0, 545750.0, 545750.0, 545750.0, 545750.0, 549250.0, 549250.0, 549250.0, 549250.0, 549250.0, 551250.0, 551250.0, 551250.0, 551250.0, 551250.0, 555500.0, 555500.0, 555500.0, 555500.0, 555500.0, 555500.0, 555500.0, 555500.0, 555500.0, 557000.0, 557000.0, 557000.0, 557000.0, 559750.0, 559750.0, 561250.0, 561250.0, 561250.0, 561250.0, 561250.0, 562750.0, 562750.0, 562750.0, 564000.0, 566000.0, 566000.0, 566000.0, 566000.0, 566000.0, 566000.0, 566000.0, 566000.0, 566000.0, 566000.0, 566000.0, 566000.0, 568750.0, 569750.0, 569750.0, 569750.0, 569750.0, 569750.0, 569750.0, 569750.0, 574000.0, 574000.0, 574000.0, 574000.0, 574000.0, 574000.0, 574000.0, 574000.0, 574000.0, 575500.0, 575500.0, 575500.0, 575500.0, 575500.0, 575500.0, 578250.0, 579750.0, 579750.0, 579750.0, 579750.0, 579750.0, 579750.0, 579750.0, 579750.0, 582500.0, 583500.0, 583500.0, 583500.0, 583500.0, 583500.0, 583500.0, 583500.0, 583500.0, 583500.0, 583500.0, 586250.0, 586250.0, 586250.0, 586750.0, 586750.0, 586750.0, 586750.0, 586750.0, 589250.0, 589250.0, 589250.0, 592000.0, 593250.0, 593250.0, 593250.0, 593250.0, 593250.0, 593250.0, 593250.0, 596000.0, 596000.0, 597500.0, 597500.0, 597500.0, 597500.0, 597500.0, 599000.0, 599000.0, 599000.0, 599000.0, 599000.0, 600500.0, 601000.0, 601000.0, 601000.0, 601000.0, 601000.0, 601000.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 610500.0, 613250.0, 613250.0, 613250.0, 613250.0, 613250.0, 613250.0, 613250.0, 613250.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616750.0, 619500.0, 619500.0, 619500.0, 621000.0, 621000.0, 621000.0, 622000.0, 622000.0, 622000.0, 626250.0, 626250.0, 626250.0, 626250.0, 626250.0, 627750.0, 627750.0, 628000.0, 628000.0, 628000.0, 630250.0, 630250.0, 630250.0, 630250.0, 632250.0, 632250.0, 632250.0, 638500.0, 638500.0, 638500.0, 638500.0, 638500.0, 638500.0, 638500.0, 638500.0, 640000.0, 640000.0, 640000.0, 640750.0, 640750.0, 640750.0, 640750.0, 640750.0, 644250.0, 644250.0, 644250.0, 644250.0, 644250.0, 644250.0, 644250.0, 647000.0, 647000.0, 647000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 650750.0, 650750.0, 650750.0, 650750.0, 650750.0, 650750.0, 650750.0, 650750.0, 650750.0, 653500.0, 655000.0, 655000.0, 655000.0, 655000.0, 655000.0, 655000.0, 656500.0, 656500.0, 656500.0, 657750.0, 657750.0, 657750.0, 657750.0, 657750.0, 657750.0, 657750.0, 660500.0, 660500.0, 660500.0, 661750.0, 661750.0, 661750.0, 661750.0, 661750.0, 661750.0, 663750.0, 663750.0, 666250.0, 666250.0, 666250.0, 669000.0, 669000.0, 670500.0, 672000.0, 672500.0, 672500.0, 672500.0, 672500.0, 672500.0, 672500.0, 672500.0, 672500.0, 672500.0, 672500.0, 672500.0, 672500.0, 672500.0, 675250.0, 675250.0, 675250.0, 675250.0, 675250.0, 678000.0, 678000.0, 678000.0, 678000.0, 678000.0, 678000.0, 678000.0, 681000.0, 681000.0, 681000.0, 681000.0, 682500.0, 682500.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 689500.0, 689500.0, 689500.0, 691000.0, 691000.0, 691000.0, 691000.0, 692500.0, 692500.0, 692500.0, 694000.0, 694000.0, 694000.0, 694250.0, 694250.0, 694250.0, 694250.0, 694250.0, 698500.0, 698500.0, 699250.0, 699250.0, 699250.0, 699250.0, 699250.0, 699250.0, 701250.0, 701250.0, 701250.0, 701250.0], "elapsed": [6856.602668762207, 6856.602668762207, 6856.602668762207, 16529.43253517151, 21528.91707420349, 21528.91707420349, 21528.91707420349, 21528.91707420349, 21528.91707420349, 21528.91707420349, 21528.91707420349, 21528.91707420349, 21528.91707420349, 24864.421606063843, 24864.421606063843, 24864.421606063843, 24864.421606063843, 24864.421606063843, 24864.421606063843, 24864.421606063843, 24864.421606063843, 24864.421606063843, 24864.421606063843, 29572.550058364868, 29572.550058364868, 29572.550058364868, 32285.34507751465, 35205.01184463501, 35205.01184463501, 35205.01184463501, 35205.01184463501, 35205.01184463501, 35205.01184463501, 35205.01184463501, 35205.01184463501, 35205.01184463501, 35205.01184463501, 35205.01184463501, 40967.376708984375, 40967.376708984375, 40967.376708984375, 45908.51449966431, 45908.51449966431, 45908.51449966431, 48450.72913169861, 48450.72913169861, 48450.72913169861, 48450.72913169861, 51013.11945915222, 51013.11945915222, 52999.52220916748, 52999.52220916748, 52999.52220916748, 52999.52220916748, 52999.52220916748, 57789.51072692871, 57789.51072692871, 57789.51072692871, 57789.51072692871, 59709.71965789795, 59709.71965789795, 59709.71965789795, 59709.71965789795, 63668.604373931885, 63668.604373931885, 63668.604373931885, 63668.604373931885, 63668.604373931885, 70775.93231201172, 70775.93231201172, 73739.87174034119, 75644.44279670715, 75644.44279670715, 75644.44279670715, 75644.44279670715, 75644.44279670715, 75644.44279670715, 75644.44279670715, 75644.44279670715, 80166.57710075378, 80166.57710075378, 80166.57710075378, 82442.50559806824, 82442.50559806824, 82442.50559806824, 82442.50559806824, 82442.50559806824, 82442.50559806824, 82442.50559806824, 86969.65837478638, 86969.65837478638, 86969.65837478638, 86969.65837478638, 89605.98635673523, 89605.98635673523, 92177.12569236755, 92177.12569236755, 92177.12569236755, 92177.12569236755, 92177.12569236755, 92177.12569236755, 92177.12569236755, 96707.29041099548, 96707.29041099548, 99473.881483078, 99473.881483078, 99473.881483078, 99473.881483078, 100903.23805809021, 100903.23805809021, 100903.23805809021, 100903.23805809021, 100903.23805809021, 100903.23805809021, 105694.80633735657, 105694.80633735657, 105694.80633735657, 108782.18007087708, 108782.18007087708, 108782.18007087708, 108782.18007087708, 110622.31588363647, 110622.31588363647, 110622.31588363647, 110622.31588363647, 110622.31588363647, 110622.31588363647, 110622.31588363647, 117438.11464309692, 117438.11464309692, 117438.11464309692, 117438.11464309692, 117438.11464309692, 117438.11464309692, 117438.11464309692, 117438.11464309692, 117438.11464309692, 122107.59258270264, 122107.59258270264, 123902.78553962708, 123902.78553962708, 123902.78553962708, 123902.78553962708, 123902.78553962708, 127774.89256858826, 127774.89256858826, 127774.89256858826, 132257.25889205933, 132257.25889205933, 132257.25889205933, 132257.25889205933, 132257.25889205933, 132257.25889205933, 132257.25889205933, 136614.88962173462, 136614.88962173462, 136614.88962173462, 136614.88962173462, 136614.88962173462, 136614.88962173462, 144093.24598312378, 147197.85571098328, 147197.85571098328, 147197.85571098328, 147197.85571098328, 147197.85571098328, 149664.83330726624, 149664.83330726624, 149664.83330726624, 149664.83330726624, 149664.83330726624, 149664.83330726624, 149664.83330726624, 149664.83330726624, 149664.83330726624, 149664.83330726624, 154772.6502418518, 154772.6502418518, 154772.6502418518, 154772.6502418518, 156483.60800743103, 156483.60800743103, 156483.60800743103, 156483.60800743103, 160362.80846595764, 160362.80846595764, 160362.80846595764, 160362.80846595764, 160362.80846595764, 160362.80846595764, 160362.80846595764, 164976.03130340576, 166461.49444580078, 166461.49444580078, 166461.49444580078, 166461.49444580078, 166461.49444580078, 174422.48153686523, 174422.48153686523, 174422.48153686523, 174422.48153686523, 174422.48153686523, 174422.48153686523, 174422.48153686523, 174422.48153686523, 174422.48153686523, 174422.48153686523, 174422.48153686523, 179309.6227645874, 179309.6227645874, 181639.00184631348, 181639.00184631348, 181639.00184631348, 181639.00184631348, 181639.00184631348, 181639.00184631348, 189474.11847114563, 189474.11847114563, 189474.11847114563, 189474.11847114563, 189474.11847114563, 189474.11847114563, 189474.11847114563, 189474.11847114563, 189474.11847114563, 192585.4034423828, 192585.4034423828, 192585.4034423828, 192585.4034423828, 192585.4034423828, 192585.4034423828, 192585.4034423828, 192585.4034423828, 192585.4034423828, 192585.4034423828, 197195.1723098755, 197195.1723098755, 197195.1723098755, 200099.21550750732, 200099.21550750732, 206144.4215774536, 208555.74488639832, 208555.74488639832, 208555.74488639832, 208555.74488639832, 208555.74488639832, 208555.74488639832, 208555.74488639832, 208555.74488639832, 208555.74488639832, 208555.74488639832, 208555.74488639832, 208555.74488639832, 213088.4666442871, 213088.4666442871, 213088.4666442871, 215895.1437473297, 215895.1437473297, 217426.3436794281, 217426.3436794281, 217426.3436794281, 231211.70163154602, 231211.70163154602, 231211.70163154602, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 234824.0442276001, 237029.5262336731, 237029.5262336731, 237029.5262336731, 237029.5262336731, 246077.55827903748, 246077.55827903748, 246077.55827903748, 246077.55827903748, 246077.55827903748, 246077.55827903748, 246077.55827903748, 246077.55827903748, 246077.55827903748, 246077.55827903748, 250816.3685798645, 250816.3685798645, 250816.3685798645, 256330.03902435303, 256330.03902435303, 256330.03902435303, 256330.03902435303, 256330.03902435303, 256330.03902435303, 256330.03902435303, 256330.03902435303, 256330.03902435303, 256330.03902435303, 256330.03902435303, 261347.403049469, 264029.28471565247, 264029.28471565247, 264029.28471565247, 264029.28471565247, 264029.28471565247, 264029.28471565247, 264029.28471565247, 264029.28471565247, 264029.28471565247, 264029.28471565247, 271504.1470527649, 271504.1470527649, 271504.1470527649, 271504.1470527649, 271504.1470527649, 271504.1470527649, 274256.4866542816, 274256.4866542816, 275992.98882484436, 275992.98882484436, 275992.98882484436, 275992.98882484436, 275992.98882484436, 280743.1378364563, 280743.1378364563, 283826.2891769409, 283826.2891769409, 283826.2891769409, 283826.2891769409, 283826.2891769409, 283826.2891769409, 283826.2891769409, 283826.2891769409, 285347.00083732605, 285347.00083732605, 285347.00083732605, 285347.00083732605, 285347.00083732605, 289358.74915122986, 289358.74915122986, 289358.74915122986, 289358.74915122986, 289358.74915122986, 289358.74915122986, 296298.86269569397, 296298.86269569397, 296298.86269569397, 296298.86269569397, 296298.86269569397, 296298.86269569397, 296298.86269569397, 296298.86269569397, 296298.86269569397, 296298.86269569397, 296298.86269569397, 300612.97059059143, 300612.97059059143, 300612.97059059143, 300612.97059059143, 300612.97059059143, 300612.97059059143, 300612.97059059143, 300612.97059059143, 305658.1437587738, 308686.2256526947, 308686.2256526947, 308686.2256526947, 308686.2256526947, 308686.2256526947, 308686.2256526947, 308686.2256526947, 308686.2256526947, 308686.2256526947, 308686.2256526947, 308686.2256526947, 312238.7318611145, 312238.7318611145, 312238.7318611145, 312238.7318611145, 316632.1294307709, 316632.1294307709, 316632.1294307709, 316632.1294307709, 316632.1294307709, 316632.1294307709, 316632.1294307709, 321154.8800468445, 321154.8800468445, 321154.8800468445, 321154.8800468445, 321154.8800468445, 326039.8578643799, 327363.9237880707, 327363.9237880707, 327363.9237880707, 327363.9237880707, 327363.9237880707, 331590.14105796814, 331590.14105796814, 331590.14105796814, 331590.14105796814, 331590.14105796814, 331590.14105796814, 336461.86780929565, 336461.86780929565, 336461.86780929565, 336461.86780929565, 336461.86780929565, 336461.86780929565, 336461.86780929565, 336461.86780929565, 336461.86780929565, 336461.86780929565, 336461.86780929565, 336461.86780929565, 341246.94538116455, 341246.94538116455, 341246.94538116455, 341246.94538116455, 344002.50601768494, 344002.50601768494, 344002.50601768494, 344002.50601768494, 344002.50601768494, 347041.597366333, 347041.597366333, 350079.83326911926, 350079.83326911926, 350079.83326911926, 350079.83326911926, 350079.83326911926, 350079.83326911926, 350079.83326911926, 350079.83326911926, 350079.83326911926, 354601.35293006897, 356834.6631526947, 359271.74043655396, 359271.74043655396, 359271.74043655396, 359271.74043655396, 359271.74043655396, 359271.74043655396, 359271.74043655396, 363963.53459358215, 369519.84119415283, 370811.6970062256, 370811.6970062256, 370811.6970062256, 370811.6970062256, 370811.6970062256, 370811.6970062256, 381620.890378952, 381620.890378952, 381620.890378952, 381620.890378952, 381620.890378952, 384696.94447517395, 384696.94447517395, 384696.94447517395, 384696.94447517395, 384696.94447517395, 384696.94447517395, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 393853.8236618042, 401268.9309120178, 401268.9309120178, 401268.9309120178, 402831.5086364746, 402831.5086364746, 402831.5086364746, 402831.5086364746, 407493.08013916016, 407493.08013916016, 407493.08013916016, 409986.0887527466, 409986.0887527466, 409986.0887527466, 409986.0887527466, 412213.7248516083, 412213.7248516083, 412213.7248516083, 412213.7248516083, 412213.7248516083, 412213.7248516083, 419052.77276039124, 420811.3284111023, 420811.3284111023, 420811.3284111023, 420811.3284111023, 420811.3284111023, 420811.3284111023, 420811.3284111023, 420811.3284111023, 425209.9049091339, 425209.9049091339, 425209.9049091339, 425209.9049091339, 425209.9049091339, 425209.9049091339, 425209.9049091339, 429695.5020427704, 429695.5020427704, 431314.12625312805, 431314.12625312805, 431314.12625312805, 431314.12625312805, 436522.0227241516, 436522.0227241516, 439685.0209236145, 439685.0209236145, 439685.0209236145, 439685.0209236145, 439685.0209236145, 439685.0209236145, 442797.18804359436, 442797.18804359436, 442797.18804359436, 442797.18804359436, 442797.18804359436, 442797.18804359436, 445487.0228767395, 445487.0228767395, 445487.0228767395, 445487.0228767395, 445487.0228767395, 445487.0228767395, 445487.0228767395, 445487.0228767395, 445487.0228767395, 445487.0228767395, 445487.0228767395, 452811.5699291229, 452811.5699291229, 452811.5699291229, 452811.5699291229, 454423.39277267456, 454423.39277267456, 454423.39277267456, 454423.39277267456, 454423.39277267456, 454423.39277267456, 454423.39277267456, 454423.39277267456, 458775.0952243805, 461629.8899650574, 461629.8899650574, 461629.8899650574, 461629.8899650574, 464567.26717948914, 464567.26717948914, 464567.26717948914, 464567.26717948914, 464567.26717948914, 464567.26717948914, 464567.26717948914, 467254.91428375244, 467254.91428375244, 467254.91428375244, 467254.91428375244, 467254.91428375244, 470026.9513130188, 470026.9513130188, 470026.9513130188, 473209.6230983734, 473209.6230983734, 473209.6230983734, 473209.6230983734, 473209.6230983734, 473209.6230983734, 473209.6230983734, 476000.82540512085, 476000.82540512085, 476000.82540512085, 476000.82540512085, 476000.82540512085, 476000.82540512085, 476000.82540512085, 476000.82540512085, 476000.82540512085, 476000.82540512085, 480835.9696865082, 482893.7349319458, 482893.7349319458, 482893.7349319458, 482893.7349319458, 482893.7349319458, 482893.7349319458, 482893.7349319458, 482893.7349319458, 487897.27210998535, 487897.27210998535, 487897.27210998535, 487897.27210998535, 487897.27210998535, 487897.27210998535, 491405.85350990295, 491405.85350990295, 491405.85350990295, 495966.1719799042, 495966.1719799042, 495966.1719799042, 495966.1719799042, 501696.3369846344, 501696.3369846344, 501696.3369846344, 501696.3369846344, 504761.75260543823, 504761.75260543823, 504761.75260543823, 504761.75260543823, 504761.75260543823, 504761.75260543823, 504761.75260543823, 504761.75260543823, 504761.75260543823, 504761.75260543823, 504761.75260543823, 504761.75260543823, 509278.413772583, 509278.413772583, 509278.413772583, 511645.884513855, 511645.884513855, 511645.884513855, 513686.7582798004, 513686.7582798004, 513686.7582798004, 513686.7582798004, 524546.0126399994, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 527307.6937198639, 540190.5934810638, 540190.5934810638, 542564.3892288208, 542564.3892288208, 542564.3892288208, 542564.3892288208, 542564.3892288208, 542564.3892288208, 542564.3892288208, 550633.4626674652, 553874.1040229797, 553874.1040229797, 553874.1040229797, 553874.1040229797, 553874.1040229797, 553874.1040229797, 553874.1040229797, 556866.0168647766, 556866.0168647766, 560111.4859580994, 560111.4859580994, 560111.4859580994, 560111.4859580994, 560111.4859580994, 560111.4859580994, 560111.4859580994, 560111.4859580994, 560111.4859580994, 560111.4859580994, 560111.4859580994, 560111.4859580994, 560111.4859580994, 564803.4722805023, 564803.4722805023, 564803.4722805023, 564803.4722805023, 567467.4994945526, 570692.6023960114, 570692.6023960114, 570692.6023960114, 570692.6023960114, 570692.6023960114, 578376.7380714417, 578376.7380714417, 578376.7380714417, 578376.7380714417, 578376.7380714417, 580410.2754592896, 580410.2754592896, 580410.2754592896, 580410.2754592896, 580410.2754592896, 580410.2754592896, 580410.2754592896, 580410.2754592896, 580410.2754592896, 580410.2754592896, 580410.2754592896, 580410.2754592896, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 587461.580991745, 594637.3863220215, 594637.3863220215, 594637.3863220215, 594637.3863220215, 594637.3863220215, 594637.3863220215, 594637.3863220215, 594637.3863220215, 602219.3460464478, 602219.3460464478, 602219.3460464478, 602219.3460464478, 602219.3460464478, 602219.3460464478, 602219.3460464478, 602219.3460464478, 602219.3460464478, 602219.3460464478, 610204.4649124146, 610204.4649124146, 610204.4649124146, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 612654.9637317657, 619400.7127285004, 619400.7127285004, 619400.7127285004, 619400.7127285004, 620484.9450588226, 620484.9450588226, 620484.9450588226, 628186.4302158356, 628186.4302158356, 628186.4302158356, 628186.4302158356, 628186.4302158356, 628186.4302158356, 630238.3074760437, 630238.3074760437, 630238.3074760437, 630238.3074760437, 630238.3074760437, 634926.6953468323, 637776.1626243591, 637776.1626243591, 637776.1626243591, 640925.4281520844, 640925.4281520844, 644047.643661499, 644047.643661499, 644047.643661499, 644047.643661499, 647209.3296051025, 647209.3296051025, 652728.7302017212, 652728.7302017212, 652728.7302017212, 652728.7302017212, 652728.7302017212, 652728.7302017212, 652728.7302017212, 652728.7302017212, 652728.7302017212, 652728.7302017212, 657839.3049240112, 657839.3049240112, 660202.5716304779, 660202.5716304779, 660202.5716304779, 660202.5716304779, 660202.5716304779, 660202.5716304779, 660202.5716304779, 660202.5716304779, 660202.5716304779, 665257.6882839203, 679000.1835823059, 679000.1835823059, 679000.1835823059, 679000.1835823059, 679000.1835823059, 682793.5426235199, 682793.5426235199, 682793.5426235199, 682793.5426235199, 682793.5426235199, 682793.5426235199, 682793.5426235199, 682793.5426235199, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 685970.5789089203, 691364.1624450684, 691364.1624450684, 691364.1624450684, 695144.1876888275, 695144.1876888275, 695144.1876888275, 695144.1876888275, 695144.1876888275, 700107.3753833771, 702472.08070755, 702472.08070755, 702472.08070755, 702472.08070755, 702472.08070755, 702472.08070755, 702472.08070755, 702472.08070755, 702472.08070755, 702472.08070755, 702472.08070755, 709348.0432033539, 709348.0432033539, 709348.0432033539, 709348.0432033539, 709348.0432033539, 709348.0432033539, 709348.0432033539, 709348.0432033539, 709348.0432033539, 713773.0057239532, 713773.0057239532, 713773.0057239532, 713773.0057239532, 713773.0057239532, 713773.0057239532, 713773.0057239532, 718468.2037830353, 718468.2037830353, 718468.2037830353, 720916.2404537201, 720916.2404537201, 720916.2404537201, 720916.2404537201, 720916.2404537201, 720916.2404537201, 720916.2404537201, 725045.0201034546, 725045.0201034546, 725045.0201034546, 725045.0201034546, 725045.0201034546, 725045.0201034546, 732506.0431957245, 732506.0431957245, 732506.0431957245, 732506.0431957245, 732506.0431957245, 732506.0431957245, 732506.0431957245, 735253.5223960876, 735253.5223960876, 735253.5223960876, 735253.5223960876, 735253.5223960876, 735253.5223960876, 735253.5223960876, 735253.5223960876, 735253.5223960876, 740043.027639389, 742935.6822967529, 742935.6822967529, 744597.1822738647, 744597.1822738647, 744597.1822738647, 744597.1822738647, 744597.1822738647, 744597.1822738647, 744597.1822738647, 744597.1822738647, 744597.1822738647, 749612.0946407318, 749612.0946407318, 749612.0946407318, 749612.0946407318, 749612.0946407318, 749612.0946407318, 749612.0946407318, 749612.0946407318, 749612.0946407318, 753777.3048877716, 753777.3048877716, 753777.3048877716, 753777.3048877716, 753777.3048877716, 757989.2263412476, 757989.2263412476, 757989.2263412476, 757989.2263412476, 760079.4794559479, 760079.4794559479, 760079.4794559479, 760079.4794559479, 760079.4794559479, 760079.4794559479, 760079.4794559479, 768321.4268684387, 768321.4268684387, 768321.4268684387, 768321.4268684387, 768321.4268684387, 768321.4268684387, 768321.4268684387, 768321.4268684387, 771251.4073848724, 774511.6519927979, 774511.6519927979, 774511.6519927979, 774511.6519927979, 774511.6519927979, 774511.6519927979, 774511.6519927979, 774511.6519927979, 774511.6519927979, 780781.3370227814, 780781.3370227814, 780781.3370227814, 780781.3370227814, 780781.3370227814, 780781.3370227814, 785736.7916107178, 785736.7916107178, 788903.9044380188, 788903.9044380188, 790784.9025726318, 790784.9025726318, 790784.9025726318, 790784.9025726318, 790784.9025726318, 790784.9025726318, 790784.9025726318, 790784.9025726318, 795385.8814239502, 795385.8814239502, 795385.8814239502, 795385.8814239502, 800273.0650901794, 800273.0650901794, 800273.0650901794, 800273.0650901794, 800273.0650901794, 800273.0650901794, 800273.0650901794, 800273.0650901794, 808212.9619121552, 808212.9619121552, 808212.9619121552, 811311.3300800323, 811311.3300800323, 811311.3300800323, 811311.3300800323, 814344.9211120605, 814344.9211120605, 814344.9211120605, 814344.9211120605, 814344.9211120605, 814344.9211120605, 814344.9211120605, 814344.9211120605, 814344.9211120605, 814344.9211120605, 822920.6335544586, 822920.6335544586, 822920.6335544586, 822920.6335544586, 822920.6335544586, 827791.3599014282, 827791.3599014282, 827791.3599014282, 827791.3599014282, 827791.3599014282, 827791.3599014282, 831742.4914836884, 831742.4914836884, 836619.2345619202, 836619.2345619202, 836619.2345619202, 836619.2345619202, 839469.405412674, 839469.405412674, 839469.405412674, 839469.405412674, 839469.405412674, 839469.405412674, 839469.405412674, 843118.5500621796, 843118.5500621796, 848070.2307224274, 848070.2307224274, 848070.2307224274, 848070.2307224274, 850922.4824905396, 850922.4824905396, 850922.4824905396, 850922.4824905396, 850922.4824905396, 850922.4824905396, 850922.4824905396, 850922.4824905396, 850922.4824905396, 855528.2025337219, 855528.2025337219, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 864786.4172458649, 871663.1700992584, 871663.1700992584, 871663.1700992584, 876585.7033729553, 876585.7033729553, 876585.7033729553, 876585.7033729553, 876585.7033729553, 876585.7033729553, 876585.7033729553, 880932.9316616058, 880932.9316616058, 880932.9316616058, 880932.9316616058, 880932.9316616058, 880932.9316616058, 880932.9316616058, 880932.9316616058, 884843.9910411835, 884843.9910411835, 894204.4916152954, 894204.4916152954, 894204.4916152954, 894204.4916152954, 894204.4916152954, 894204.4916152954, 894204.4916152954, 894204.4916152954, 894204.4916152954, 894204.4916152954, 894204.4916152954, 894204.4916152954, 894204.4916152954, 903847.827911377, 903847.827911377, 903847.827911377, 903847.827911377, 903847.827911377, 903847.827911377, 903847.827911377, 903847.827911377, 903847.827911377, 903847.827911377, 911350.1162528992, 911350.1162528992, 911350.1162528992, 911350.1162528992, 911350.1162528992, 911350.1162528992, 911350.1162528992, 911350.1162528992, 911350.1162528992, 918280.3058624268, 918280.3058624268, 918280.3058624268, 918280.3058624268, 921041.4991378784, 923270.2729701996, 923270.2729701996, 923270.2729701996, 923270.2729701996, 923270.2729701996, 923270.2729701996, 928191.0343170166, 931170.7532405853, 934047.9588508606, 937085.8089923859, 937085.8089923859, 937085.8089923859, 937085.8089923859, 937085.8089923859, 937085.8089923859, 937085.8089923859, 937085.8089923859, 937085.8089923859, 937085.8089923859, 937085.8089923859, 941877.8381347656, 944863.5303974152, 947972.7025032043, 947972.7025032043, 947972.7025032043, 947972.7025032043, 947972.7025032043, 947972.7025032043, 949269.326210022, 949269.326210022, 949269.326210022, 949269.326210022, 954112.398147583, 954112.398147583, 954112.398147583, 955511.1153125763, 955511.1153125763, 955511.1153125763, 955511.1153125763, 959688.4245872498, 959688.4245872498, 959688.4245872498, 959688.4245872498, 959688.4245872498, 959688.4245872498, 964503.7217140198, 964503.7217140198, 964503.7217140198, 964503.7217140198, 964503.7217140198, 964503.7217140198, 970786.2570285797, 970786.2570285797, 970786.2570285797, 970786.2570285797, 970786.2570285797, 970786.2570285797, 970786.2570285797, 970786.2570285797, 975735.867023468, 975735.867023468, 975735.867023468, 975735.867023468, 975735.867023468, 975735.867023468, 975735.867023468, 975735.867023468, 980248.9292621613, 980248.9292621613, 982309.4863891602, 982309.4863891602, 982309.4863891602, 982309.4863891602, 982309.4863891602, 987000.6856918335, 988486.7649078369, 988486.7649078369, 988486.7649078369, 988486.7649078369, 988486.7649078369, 988486.7649078369, 988486.7649078369, 988486.7649078369, 988486.7649078369, 993480.6501865387, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 995948.6982822418, 1001081.3453197479, 1001081.3453197479, 1001081.3453197479, 1001081.3453197479, 1002222.4473953247, 1002222.4473953247, 1002222.4473953247, 1002222.4473953247, 1006919.0232753754, 1006919.0232753754, 1006919.0232753754, 1006919.0232753754, 1009679.7709465027, 1009679.7709465027, 1009679.7709465027, 1012332.1032524109, 1012332.1032524109, 1012332.1032524109, 1012332.1032524109, 1012332.1032524109, 1015061.3160133362, 1015061.3160133362, 1017867.1679496765, 1017867.1679496765, 1017867.1679496765, 1017867.1679496765, 1020778.00822258, 1020778.00822258, 1020778.00822258, 1023844.0616130829, 1023844.0616130829, 1023844.0616130829, 1026846.9598293304, 1026846.9598293304, 1026846.9598293304, 1026846.9598293304, 1026846.9598293304, 1026846.9598293304, 1029836.1599445343, 1029836.1599445343, 1029836.1599445343, 1031674.9889850616, 1031674.9889850616, 1031674.9889850616, 1038829.7274112701, 1038829.7274112701, 1038829.7274112701, 1043440.5438899994, 1043440.5438899994, 1043440.5438899994, 1043440.5438899994, 1043440.5438899994, 1043440.5438899994, 1043440.5438899994, 1043440.5438899994, 1043440.5438899994, 1043440.5438899994, 1048750.295162201, 1048750.295162201, 1048750.295162201, 1048750.295162201, 1048750.295162201, 1052579.7364711761, 1052579.7364711761, 1052579.7364711761, 1052579.7364711761, 1052579.7364711761, 1060430.8609962463, 1060430.8609962463, 1060430.8609962463, 1060430.8609962463, 1060430.8609962463, 1060430.8609962463, 1060430.8609962463, 1060430.8609962463, 1060430.8609962463, 1063082.4773311615, 1063082.4773311615, 1063082.4773311615, 1063082.4773311615, 1067780.880689621, 1067780.880689621, 1070815.571308136, 1070815.571308136, 1070815.571308136, 1070815.571308136, 1070815.571308136, 1073969.6357250214, 1073969.6357250214, 1073969.6357250214, 1076665.866136551, 1082258.951663971, 1082258.951663971, 1082258.951663971, 1082258.951663971, 1082258.951663971, 1082258.951663971, 1082258.951663971, 1082258.951663971, 1082258.951663971, 1082258.951663971, 1082258.951663971, 1082258.951663971, 1087004.5833587646, 1089495.768547058, 1089495.768547058, 1089495.768547058, 1089495.768547058, 1089495.768547058, 1089495.768547058, 1089495.768547058, 1097335.7973098755, 1097335.7973098755, 1097335.7973098755, 1097335.7973098755, 1097335.7973098755, 1097335.7973098755, 1097335.7973098755, 1097335.7973098755, 1097335.7973098755, 1099902.099609375, 1099902.099609375, 1099902.099609375, 1099902.099609375, 1099902.099609375, 1099902.099609375, 1104513.890504837, 1107321.6061592102, 1107321.6061592102, 1107321.6061592102, 1107321.6061592102, 1107321.6061592102, 1107321.6061592102, 1107321.6061592102, 1107321.6061592102, 1112238.7223243713, 1114646.0964679718, 1114646.0964679718, 1114646.0964679718, 1114646.0964679718, 1114646.0964679718, 1114646.0964679718, 1114646.0964679718, 1114646.0964679718, 1114646.0964679718, 1114646.0964679718, 1119615.257024765, 1119615.257024765, 1119615.257024765, 1121245.7356452942, 1121245.7356452942, 1121245.7356452942, 1121245.7356452942, 1121245.7356452942, 1125546.4823246002, 1125546.4823246002, 1125546.4823246002, 1129988.6546134949, 1132412.422657013, 1132412.422657013, 1132412.422657013, 1132412.422657013, 1132412.422657013, 1132412.422657013, 1132412.422657013, 1137087.1121883392, 1137087.1121883392, 1139907.1106910706, 1139907.1106910706, 1139907.1106910706, 1139907.1106910706, 1139907.1106910706, 1142782.8731536865, 1142782.8731536865, 1142782.8731536865, 1142782.8731536865, 1142782.8731536865, 1145554.535627365, 1147255.7990550995, 1147255.7990550995, 1147255.7990550995, 1147255.7990550995, 1147255.7990550995, 1147255.7990550995, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1161377.0928382874, 1165148.1239795685, 1169809.8571300507, 1169809.8571300507, 1169809.8571300507, 1169809.8571300507, 1169809.8571300507, 1169809.8571300507, 1169809.8571300507, 1169809.8571300507, 1174497.9770183563, 1174497.9770183563, 1174497.9770183563, 1174497.9770183563, 1174497.9770183563, 1176190.3626918793, 1180762.4833583832, 1180762.4833583832, 1180762.4833583832, 1183433.9671134949, 1183433.9671134949, 1183433.9671134949, 1185351.868391037, 1185351.868391037, 1185351.868391037, 1192398.47946167, 1192398.47946167, 1192398.47946167, 1192398.47946167, 1192398.47946167, 1195018.568277359, 1195018.568277359, 1196257.601737976, 1196257.601737976, 1196257.601737976, 1200248.5661506653, 1200248.5661506653, 1200248.5661506653, 1200248.5661506653, 1203772.675037384, 1203772.675037384, 1203772.675037384, 1213958.8866233826, 1213958.8866233826, 1213958.8866233826, 1213958.8866233826, 1213958.8866233826, 1213958.8866233826, 1213958.8866233826, 1213958.8866233826, 1216664.490222931, 1216664.490222931, 1216664.490222931, 1218497.7657794952, 1218497.7657794952, 1218497.7657794952, 1218497.7657794952, 1218497.7657794952, 1225000.066280365, 1225000.066280365, 1225000.066280365, 1225000.066280365, 1225000.066280365, 1225000.066280365, 1225000.066280365, 1229568.6814785004, 1229568.6814785004, 1229568.6814785004, 1231580.339193344, 1231580.339193344, 1231580.339193344, 1231580.339193344, 1231580.339193344, 1231580.339193344, 1231580.339193344, 1236289.8721694946, 1236289.8721694946, 1236289.8721694946, 1236289.8721694946, 1236289.8721694946, 1236289.8721694946, 1236289.8721694946, 1236289.8721694946, 1236289.8721694946, 1241252.278327942, 1244109.6451282501, 1244109.6451282501, 1244109.6451282501, 1244109.6451282501, 1244109.6451282501, 1244109.6451282501, 1246812.8371238708, 1246812.8371238708, 1246812.8371238708, 1249370.5971240997, 1249370.5971240997, 1249370.5971240997, 1249370.5971240997, 1249370.5971240997, 1249370.5971240997, 1249370.5971240997, 1254480.1955223083, 1254480.1955223083, 1254480.1955223083, 1256762.0544433594, 1256762.0544433594, 1256762.0544433594, 1256762.0544433594, 1256762.0544433594, 1256762.0544433594, 1260198.618888855, 1260198.618888855, 1264372.6749420166, 1264372.6749420166, 1264372.6749420166, 1269520.99275589, 1269520.99275589, 1272282.3824882507, 1275828.4831047058, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1278223.8354682922, 1282918.2374477386, 1282918.2374477386, 1282918.2374477386, 1282918.2374477386, 1282918.2374477386, 1287657.595872879, 1287657.595872879, 1287657.595872879, 1287657.595872879, 1287657.595872879, 1287657.595872879, 1287657.595872879, 1292929.7497272491, 1292929.7497272491, 1292929.7497272491, 1292929.7497272491, 1295957.2274684906, 1295957.2274684906, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1302393.307209015, 1309442.1708583832, 1309442.1708583832, 1309442.1708583832, 1312225.9175777435, 1312225.9175777435, 1312225.9175777435, 1312225.9175777435, 1315207.573890686, 1315207.573890686, 1315207.573890686, 1318321.4604854584, 1318321.4604854584, 1318321.4604854584, 1319618.0391311646, 1319618.0391311646, 1319618.0391311646, 1319618.0391311646, 1319618.0391311646, 1327593.8367843628, 1327593.8367843628, 1329868.6974048615, 1329868.6974048615, 1329868.6974048615, 1329868.6974048615, 1329868.6974048615, 1329868.6974048615, 1333772.4437713623, 1333772.4437713623, 1333772.4437713623, 1333772.4437713623], "prediction_length": 1633, "reference": "Hallo, ich bin Jiawei Zhou von der Harvard University. Ich freue mich sehr, unsere Arbeit zum semantischenOnline-Parsing für die Latenzreduktion bei einem aufgabenorientierten Dialog vorstellen zu können. Dies ist eine gemeinsame Arbeit mit Jason, Michael, Anthony und Sam von Microsoft Semantic Machines. Beim aufgabenorientierten Dialog interagiert ein Benutzer mit dem System, das Anfragen von Benutzeräußerungen, in der Regel in gesprochener Form, bearbeitet. Vom Ende der Benutzeräußerung bis zur Antwort des Systems gibt es oft eine spürbare Verzögerung. Im Detail wird die Benutzeräußerung in ein ausführbares Programm übersetzt. Dieses wird dann ausgeführt, damit das System richtig reagieren kann. Denn das Programm wird als semantischer Graph dargestellt, der die Berechnung skizziert, wobei ein Knoten einen Funktionsaufruf darstellt und seine Kindknoten die Argumente sind. Die großen Knoten markieren sofortige Operationen, aber die anderen sind langsam in der Ausführung. Das einfache Beispiel hier zeigt, dass diese Programme oft kompliziertere Graphen sein können als die Baumstrukturen. In diesem Vortrag stellen wir die Frage, ob wir mit der Generierung des Programms und seiner Ausführung beginnen können, bevor der Benutzer überhaupt die Äußerung beendet hat, sodass das System schneller reagieren kann. Dies ist das Problem der Online-Vorhersage und Entscheidung. Es gibt viele andere in diesem REALM. Beispiele sind Simultanübersetzungen, bei denen ein Dolmetscher live eine Sprache in eine andere in Echtzeit übersetzt; die intelligente automatische Vervollständigung von Text, um die Absicht des Benutzers zu erraten; und der Uber Pool, wo Fahrer dorthin geschickt werden, wo sie basierend auf der prognostizierten Nachfrage möglicherweise benötigt werden. All diese Szenarien haben eines gemeinsam. Es ist vorteilhaft, Entscheidungen zu treffen, bevor man alle Eingaben sieht. In unserem Fall werden wir uns mit dem semantischen Online-Parsing befassen, was eine Herausforderung sein könnte, da wir erraten müssen, was der Benutzer sagen könnte. Dieses Gebiet ist auch wenig erforscht und hat keine formale Evaluationsmetrik. Schauen wir uns zunächst an, wie ein gewöhnliches System funktioniert. Dieses funktioniert offline durch Parsing zum Programm erst am Ende der Benutzeräußerung. Hier wird das Zeichen Graph vorhergesagt, nachdem alle Information gesehen wurden. Im Gegensatz dazu schlagen wir ein Online-System vor, das bei jedem Äußerung das Präfix vergleicht. Jedes Mal, wenn wir beispielsweise ein neues Token sehen, prognostizieren wir einen neuen Graphen. Beachten Sie, dass Fehler auftreten können. Bei der Position von der Poolparty mit Barack Obama haben wir einen Graphen mit den richtigen Knoten über die Person und das Thema des Ereignisses, aber wahrscheinlich die falschen Informationen zu den Zeiten. Dieser Prozess geht weiter, bis wir die vollständige Benutzeräußerung erhalten. Wie würde sich dies auf die Ausführungszeiten im Offline-System auswirken? Am Ende erhalten wir den Programm-Graphen, damit das System an dieser Stelle mit der Ausführung beginnen kann. Vergessen Sie nicht, dass die großen Knoten schnelle Operationen sind. Daher betrachten wir nur die Ausführungszeiten der farbigen langsamen Funktionen. Erstens können diese beiden Personensuchfunktionen parallel ausgeführt werden, da sie keine Abhängigkeit von anderen Funktionen haben. Sie sind weiß hinterlegt im rosa Kästchen. Als Nächstes kann der Knoten „Ereignis erstellen“ ausgeführt werden, nachdem er Ergebnisse von Knoten bekommen hat. Mit der Top-Ertragsfunktion wird das gesamte Programm beendet. Der Ausführungsprozess ist streng und beschränkt sich auf die Abhängigkeitsstruktur des Programms, bei der einige Operationen nicht parallelisiert werden können. Das führt zu einer spürbaren Verzögerung. In unserem Online-System, wo wir im Laufe der Zeit vorhersagen, kann die Programmausführung früher beginnen. Hier, beim Präfix nach Obama, sagen wir zuversichtlich voraus, dass die Funktion „Person finden“ im Programm sein muss, aber dass der Rest Fehler enthalten kann, da sie ausgegraut sind. Die Ausführung des Knotens kann sofort als Schritt gestartet werden. Dann, mit mehr Token, prognostizieren wir einen völlig neuen Graphen, aber ein Teil davon wird bereits ausgeführt. Wir müssen also nur den Rest der Knoten betrachten, bei denen wir uns auch sicher sind. Hier kann wieder „Finde Person“ parallel ausgeführt werden. Auch hier könnten wir falsche Vorhersagen haben. Mit mehr Text steigt die Chance, dass wir richtig liegen. Zum Beispiel bei der Zeit des Ereignisses, bei der AM auch richtig vorhergesehen wird. Dann können wir mit der Ausführung des Rests beginnen, indem wir der Abhängigkeitsstruktur des Programms folgen. Indem wir die Ausführungszeiten mit den Zeiten der Äußerungen überlappen, sparen wir viel Zeit ein. Also haben wir die Aufgabe mit dem semantischen Online-Parsing vorgeschlagen. Eine zugrunde liegende Annahme ist, dass die Ausführungszeit die Vorhersagezeit des Modells dominiert. Also konnten wir nur Zeit gewinnen, indem wir früher voraussagten. Eine weitere Annahme ist, dass, wenn die Vorhersage und die Ausführung im Hintergrund stattfinden, sie für Benutzer nicht sichtbar sind. Es ist nicht notwendig, eine konsistente Parsing-Historie aufzubewahren. Also parsen wir nach jedem Token von Grund auf neu. Insbesondere wollen wir einen zweistufigen Ansatz vorschlagen. Wir schlagen einen Schritt vor, bei dem ein Graph mit vollständiger Struktur vorhergesagt wird und einen Schritt, bei dem die Knoten ausgewählt werden, die es zu diesem Zeitpunkt wert sind, ausgeführt zu werden. Wir hatten zwei Varianten der vorgeschlagenen Methode. Der erste Ansatz kombiniert eine Sprachmodell-Vervollständigung mit einer vollständigen Äußerung zum Graph-Parsing. Insbesondere wird das Präfix nach Obama zunächst durch ein fein abgestimmtes BART-Sprachmodell vervollständigt und dann in ein Programm mit vollständigem Offline-Parser übersetzt. Der zweite Ansatz sagt das Programm direkt aus den Präfixen der Benutzeräußerung voraus. Dies wird durch Training von einem einzigen Online-Parser erreicht, der aus jedem Präfix in den Zielgraphen übersetzen soll. Dies erleichtert dem Modell, die richtige Erwartung zu erlernen. Detaillierter gesagt: Wie können wir diese Graphen generieren? Wir formulieren das Problem, indem wir eine serielle Version des Graphen generieren. Jeder Knoten oder jede Kante wird durch eine Aktion dargestellt. Hier beginnen wir mit dem ersten Knoten. Die Reihe unten zeichnet den absoluten Index im Aktionsverlauf auf. Dann haben wir den zweiten Knoten. Als Nächstes kommt die Kante zwischen ihnen. Dort ist der Zeiger auf den Index des früheren Knotens und das Kantenlabel enthalten. Null bedeutet hier, dass der neueste Knoten mit dem Knoten verbunden wird, der durch die Null-Aktion und die Kante des nächsten Knotens generiert wurde. Dieser Prozess geht weiter, bis wir den vollständigen Graph generieren. Das zugrunde liegende Modell basiert auf dem Transformator mit Selbstausrichtungsmechanismus, ähnlich einem früheren übergangsbasierten Parser. Nach Generierung eines vollständigen Graphen haben wir die Wahrscheinlichkeiten der Aktionsebene erhalten, die verschiedenen Teilen des Graphen entsprechen. Wir wählen Konfidenzteilgraphen auf der Grundlage der auszuführenden Schwellwerte heuristisch aus. Später werden wir den Schwellenwert variieren, um unterschiedliche Kompromisse zwischen der Latenzreduzierung und den Ausführungskosten zu erzielen. Für die formale Evaluation der Online-Methoden wollen wir eine endgültige Latenzreduzierung oder FLR-Metrik vorschlagen. Hier ist eine Zusammenfassung, wie ein Offline-System die Ausführungszeiten beendet. In Online-Systemen überschneidet sich die Ausführung mit den Zeiten der Äußerung. Sie endet also früher. FLR ist als die Reduktionszeit im Vergleich zum Offline-System definiert und durch das Ende der Ausführung markiert. Wir führen Experimente an zwei großen Datensätzen von Konversationen mit semantischem Parsing durch: SMCalFlow und TreeDST. Unser auf dem Graphen basierte Parser erreicht, wenn er offline betrieben wird, beste Leistungen beim Parsing für beide Datensätze. Das LM-Complete-Modell erzielt auch eine nicht triviale BLEU -Verstärkung im Vergleich zur einfachen Basislinie der Knotenvervollständigung. Schauen wir uns nun die Vorhersagegenauigkeit unseres Präfixes für den Graph-Parser an. Wir testen den F1-Score der Graph-Tupel zwischen der Generierung und dem Go-Graph in den Validierungsdaten auf der y-Achse für jede Präfixlänge in der x-Achse, dargestellt durch Prozentsätze. Jede dieser Kurven stellt ein anderes Modell mit dem einzigen Unterschied in den Trainingsdaten dar. Die untere Kurve ist der Offline-Parser. Wir mischen Präfix- Daten in verschiedenen Längen hinein, um das Modell in einen Online-Parser zu überführen. Zum Beispiel bedeutet das Legendenpräfix „80 Prozent plus“, dass das Modell mit Präfix-Daten trainiert wird, wobei die Präfixlänge größer als 80 Prozent der vollen Äußerungslänge ist. Die obere linke Ecke ist der gewünschte Bereich. Wie wir sehen können, funktioniert der Offline-Parser in der schwarzen Kurve der Präfix-Daten nicht gut. Da wir im Training mehr Präfixe mischen, hebt sich die Kurve nach oben und links und schneidet bei allen Präfixlängen besser ab. Die volle Leistung des Äußerung-Parsings wird jedoch im oberen rechten Punkt nicht beeinflusst. Basierend auf diesen starken Ergebnissen, stellt sich die Frage, wie viel Latenz reduziert wird. Wir messen die Zeit anhand der Reihe von Quelltoken und simulieren verschiedene Funktionsausführungszeiten. Die Kurven zeigen den Kompromiss zwischen der FLR-Metrik und den Ausführungskosten, gemessen an der Reihe übermäßiger Funktionskosten, die nicht korrekt sind. Dies wird durch Variation der Teilgraphenauswahlschwelle erreicht. Eine höhere Schwelle wählt weniger Fehlfunktionen aus, erhält aber eine kleinere FLR, während die niedrigere Schwelle aggressiver Programme auswählt und ausführt. Wir vergleichen die beiden Ansätze, die wir vorschlagen, mit einer Baseline, die nichts anderes tut, als den Offline-Parser für den Online-Einsatz anzuwenden. Der obere linke Bereich hat den besten FLR und Kostenvorteil. Wir sehen, dass beide unserer Methoden die Baseline um eine große Differenz übertreffen und sie bei TreeDST ähnlicher abschneiden. Während die Ausführung einzelner Funktionen schneller ist, gibt es tendenziell mehr Ausführungsvorgänge und weniger Raum für die Latenzreduzierung. Wenn die Ausführung einzelner Funktionen langsamer ist, gibt es mehr Möglichkeiten für FLR-Verbesserungen. Unsere beiden Ansätze erreichen eine bessere Leistung in verschiedenen Kostenbereichen. Insgesamt erreichen wir je nach Ausführungszeit und zulässigen Kosten eine Reduzierung der relativen Latenz um 63 bis 60 Prozent. Schließlich haben wir eine Aufschlüsselung der durchschnittlichen Latenzreduktion in Token für jeden Typ des Funktionsknotens, wenn die zulässigen Kosten drei Ausführungsvorgänge betragen. Wie wir sehen können, gibt es in jedem Bereich positive Ergebnisse. Es gibt auch einige Funktionen, bei denen wir eine beeindruckende Latenzreduzierung erzielen und der rote Balken viel länger ist, wie z. B. Find Manager und Empfänger. Dies sind Low-Level-Funktionen, die keine große Abhängigkeit von anderen haben. Abschließend haben wir das semantische Online-Parsing als neue Aufgabe vorgeschlagen, das wir mit der strengen Latenzreduktionsmetrik untersuchen. Mit einem starken graph-basierten, semantischen Parser erreichen wir eine relativ gute Latenzreduktion, entweder durch unseren Pipeline-Ansatz mit LM-Abschluss und einem vollständigen Parser, oder direkt durch einen gelernten Parser mit Fokus auf die Präfixe. Darüber hinaus kann unser Ansatz ein allgemeiner Rahmen sein und auf andere ausführbare semantische Darstellungen in verschiedenen Domänen angewendet werden. Zukünftige Arbeiten könnten eine intelligentere Vorhersage und die Methode der Ausführungsintegration erforschen. Danke fürs Zuhören.", "source": ["2/acl_6060/dev/full_wavs/2022.acl-long.110.wav", "samplerate: 16000 Hz", "channels: 1", "duration: 1e+01:43.007 min", "format: WAV (Microsoft) [WAV]", "subtype: Signed 16 bit PCM [PCM_16]"], "source_length": 700717.0}
{"index": 4, "prediction": "Hallo, ich werde unsere Arbeit über die Erzeugung von Retrieval-Augmented- Kontrar-Factuals für Fragen-Antwort-Aufgaben diskutieren. Das ist eine Arbeit, die ich während meines Praktikums bei Google Research gemacht habe, wo ich von Matthew Lam und Ian Tenney betreut wurde. Um die Aufgabe zu motivieren, las se mich mit der Definition eines Vertrags beginnen. In diesem Werk definieren wir ein Counterfactual als eine Pertribution des Inputs. Text, der sich in irgendeiner bedeutungsvollen, kontrollierten Weise von dem Originaltext unterscheidet und uns erlaubt, über die Veränderungen im Ausgang oder das Tasklabel zu reden. Zum Beispiel, wenn man die Worte faszinierend zu faszinierend ändert. Und das expected to mind ändert das Gefühl für diese Filmrevision. Ähnlich fügte er den Qualifikator Womens zu der Frage hinzu. Changes the answer to the question in the example below. Ändert die Antwort auf die Frage im Beispiel unten. Menschen sind im Vergleich zu NLP-Modellen, die auf der Aufgabe ausgebildet sind, typischerweise robust gegen solche Störungen. Warum ist das ? Der Datensatz kann mit Systemax samplt werden. Das ist eine schlichtere Entscheidung, die von der Gegenwirkung durch die Verletzung der Grenzen durchführt wird. wie in diesem Studiendeklassifikationsproblem gezeigt. Priorwerk hat festgestellt, dass das Hinzufügen von Konterfaktusbeispielen zu den Tradingdaten kann das Modell robust zu solchen Perdurationen machen. Also, wenn Fälschungsregeln wertvoll sind. Wie können wir sie generieren? Diese Aufgabe ist besonders schwer für NLP. Weil hier sind drei Beispiele aus drei verschiedenen NLP-Aufgaben. Wie Sie sehen können, gibt es Beispiele, die die Entscheidungsschwelle verletzen. Zwischen den Ergebnissen muss man sehr sorgfältig gearbeitet werden, indem man einige Attribute des Textes, die hier unterstrichen sind, perterpiniert. Das könnte man mit menschlicher Anmerkung machen, aber das ist teuer und voreingenommen. Einige frühere Arbeiten konzentrierten sich auf die Verwendung von Syntax bäumen oder der semantischen Rollenlabelung. Aber die Menge der durch diese Technik erzeugten Störungen ist durch den semantischen Rahmen begrenzt. In jüngeren Arbeiten wurden Massensprachmodelle verwendet, um Füllen Sie Masken-Partsionen des Textes aus. Aber es kann schwierig sein, zu finden, welche Teile des Textes zu stören sind. Es gibt mehr Challenges zu Generating Contracts für Fragen beantworten, speziell. Diese Aufgabe erfordert Hintergrundwissen. Zum Beispiel, um die ursprüngliche Frage zu stellen : Ist Indiana Jones Temple of Doom ein Prequel? Wir müssen uns der anderen Filme in der Franchise bewusst sein. um eine Frage zu bekommen , wie ist Indiana Jones Raiders of the Lost Ark? Darüber hinaus können zufällige Störungen zu Fragen führen, die mit den verfügbaren Beweisen nicht beantwortet werden können. oder falsche Prämissen haben. Darüber hinaus können einige Fragen perturbationen zu einer signifikanten semantischen Drift vom ursprünglichen Input führen. Zum Beispiel ist diese Frage indiana jones praktizierender kindesklaver in temple of doom Wir schlagen eine sehr einfache und dennoch effektive Technik vor , die Retrieve-Generate-Filter oder RGF genannt wird. um gegen gegen wirkende Perturbationen von Fragen zu bekämpfen und auch alle anderen erwähnten Herausforderungen zu bekämpfen. Die Kernintuition hinter RTF ist , dass die notwendige Hintergrundinformation, die benötigt wird, um Störungen zu erzeugen, in den nahen Missen des Fragestellmodells vorhanden sein kann. Zum Beispiel produziert das State-of-the-Art-Modell Realm die folgenden Top-K-Antworten auf die Frage, wer der Kapitän des Richmond Football Clubs ist. Nun, es hat den ursprünglichen Referenzpassage -Anwalt Trent Kotkin als Topmost-Choice zurückgewonnen, es hat auch zusätzliche Passagen und Antworten zurückgewonnen, die verwendet werden können, um For instance, es enthält zwei weitere Antworten, die den Kapitänen der Reserve- und der Frauenmannschaft des gleichen Clubs entsprechen, und das kann zu interessanten Edits führen. Zusammenfassend: RGF erstmals holt Top-K-relevanteste Antworten und Kontexte ab, die nicht mit der Referenzantwort und dem Kontext übereinstimmen. Nach diesem Schritt , dem Frage-Generation-Modell, werden die Bedingungen für diese alternativen Antworten, eine Frage zu generieren, die ihnen entspricht, festgelegt. Und schließlich können wir die generierten Fragen filtern, die auf Minimalität basieren oder auf der Art der semantischen Pertribution basieren, die wir einführen möchten. Über jeden Schritt geht man im Detail. Für das Retrieval verwenden wir ein Retrieve- und Read-Modell wie Realm, das die Originalfrage als Input nimmt und ein großes Korpus wie Wikipedia. Es besteht aus zwei Modulen. Das Retriever-Modul führt eine Ähnlichkeitsüberprüfung über einen dichten Index von Passagen durch, um die topk-relevantesten Passagen der Frage zu finden, und ein Reader-Modul, das Extrakt aus jedem Passage. als eine potenzielle Antwort. Realm retrieves the gold. Passage and Answer in most cases. In diesem Werk sind wir jedoch mehr interessiert in die Antworten und Kontexte, die es weiter hinunter die Linie retrieves. Im nächsten Schritt Wir verwenden diese alternativen Antworten und Kontexte, um neue Fragen zu erzeugen , die diesen Alternativen entsprechen. Das ist das Modell der Generation Question. Pre-Trained Text-to-Text-Transformer, das ist auf die NQ-Daten ausgelegt. um eine Frage für eine Antwort zu generieren, die im Kontext markiert ist. Während der Inferenz liefern wir das Fragestellungsmodell, die alternative Antwort und Kontexte, die wir in der vorherigen Folge zurückgewonnen haben. Zum Beispiel für das Query. Wer ist der Kapitän des Richmond Football Clubs? Das Frauenteam des Clubs, kapitän von Jess Kennedy, Und das Generation-Modell der Frage: Der Question, der Kapitän des Richmond Football Clubs, der erste weibliche Team des Jahres. die eine spezifische somatische Perturbation hat. In ähnlicher Weise bekommen wir auch Qu eries wie: Wer ist Kapitän Richmond s VFL-Reserv eteam oder wer hat Graham negiert im Grand Final letztes Jahr? Schließlich filtern wir eine Teilmenge der generierten Anfragen auf der Grundlage einiger gewünschter Merkmale aus. Wie bereits erwähnt, möchten wir sicherstellen, dass die neue Frage dem Original semantisch noch nahe steht. Für eine Filtertechnik, die keine zusätzliche Aufsicht erfordert, behalten wir einfach neue Fragen dass sie eine kleine, auf Token-Ebene angelegte Distanz von der ursprünglichen Frage haben. Zum Beispiel: Wir entfernen die Frage , wer Graham in der Grand Final letztes Jahr negierte, weil es eine lange Zeit dauert. Längere Distanz von der ursprünglichen Frage. In unseren Experimenten demonstrieren wir, dass diese einfache Heuristik kann zu Augment and Q-Training-Daten verwendet werden. Wir experimentieren auch mit einer Filterstrategie, die auf der Art der semantischen Perturbation basiert. Zu diesem Zweck verwenden wir ein allgemeines Queriedekompositionen-Framework, das QED genannt wird. QED identifiziert zwei Teile der Frage , ein Predikat und eine Referenz. Referenzen sind nun Phrasen in der Frage, die Entitäten im Kontext entsprechen. Ein Predikat ist im Grunde der verbleibende Teil der Frage. Zum Beispiel sind wir in der Lage, die Query zu dekomposieren. Das war die erste Frauenmannschaft von Captain Richmond. In zwei Referenzen : Richmond Football Club, Frauenmannschaft Und das Prädikat: \"Wer hat Kapitän X?\" Ein Modell, das auf Referenzpredikaten-Anmerkungen für Und Q gibt uns diese Frage der Dekomposition. Das dekomposieren der ursprünglichen und der generierten Fragen basierend auf Q&amp;E. Er erlaubt uns, unsere Generatoren zu kategorisieren. Wir haben zwei Gruppen von Fragen erhalten. Das ist der Referenzwechsel, während wir die Prädikate behalten. Und die, die einen Prädikatwechsel durchlaufen, und optionale Referenzen für For instance. Wer Captain Richmonds VFL-Reserve-Team ist eine Referenzänderung. Während wer trägt Nummer neun für Der Club ist ein Prädikatwechsel. Wir bewerten jetzt die Wirksamkeit von RGF-Perturbationen , wenn sie auf Trainingsdaten ergänzt werden. um die Wirksamkeit der gegenwahrscheinlichen Erweiterung besonders effektiv zu bewerten. Wir experimentieren mit zwei starken Daten-Augmentations-Basislinien. Die erste Baseline , die als Random Answer and Question Generation bezeichnet wird, Das hat keine Beziehung zu der ursprünglichen Frage. Das heißt, Passagen und Antworten sind einfach zufällig aus Wikipedia samplt. Diese Baseline fügt im Grunde mehr Daten hinzu, die wie NQ aussehen. mit der zweiten Wäsche, Gold, Antwort und Frage, Generation. Wir werden speziell den Retrieval-Teil unserer Methode ablösen. Hier werden nur alternative Antworten aus demselben Abschnitt ausgewählt, der die goldene Antwort enthielt. Wie gehen die Basislinien und RJF? # Augmentation Auf Read-Comprehension, wo das Modell Zugang zu Frage und Kontext hat. Wir experimentieren mit sechs Out-of-Domain-Datensätzen und präsentieren hier die Ergebnisse. Wo die Training-Daten in Augmentation verdoppelt werden. Wir finden das beide. Daten-Augmentation-Basislinien sind nicht in der Lage, die Domain-Generalisierung zu verbessern. Ein Ensemble von sechs Modellen, trainiert auf den Originaldaten. Es scheint die konkurrenzfähigste Basis zu sein. Verglichen mit der Basislinie finden wir, dass RGF-Counterfactuals die in der Lage sind, die Performance außerhalb der Domain zu verbessern, während sie die Performance in der Domain beibehalten. Das suggeriert, dass die Reasoning Gaps des Modells Die Quanti fakt-Augmentation ist effektiver als das Hinzufügen von Daten aus der Training-Distribution. Darüber hinaus sind wir auch sehr zufrieden mit der neuen Technologie. Wir finden , dass wir mit Retrieval zu samplenden alternativen Ausgängen oder Antworten ist wichtig für eine effektive CDA. Wir experimentieren auch mit Open-Domain-Q A-Einstellungen, bei denen das Modell nur die Frage sieht. Und noch einmal, wir bewerten vier Out-of-Domain-Datensätze. Wir finden , dass Baseline-Modelle nicht so effektiv sind für die Aus-der-Domain-Vergänzung. Die Datenvergrößerung mit R GF zeigt mehr signifikante Verbesserungen. Wir haben sogar in der Indomäne-NQ-Datensatz verbessert. Wir haben die Hypothese aufgestellt, dass die kontrafaktischen Daten Augmentation hilft dem Modell. In Learning Better Query Encoding für sehr ähnliche Queries. Schließlich bewerten wir auch die Fähigkeit des Modells, die Konsistenz in der lokalen Nachbarschaft der ursprünglichen Frage zu verbessern. Die Konsistenz misst den Anteil der von dem Modell korrekt beantworteten Fragen, bei denen sowohl die ursprüngliche als auch die kontrafaktuelle Frage richtig beantwortet sind. Das hilft uns, die Robustheit des Modells zu messen. zu kleinen Perturbationen in der Nachbarschaft der Original-Input Wir experimentieren mit fünf Datensätzen , die Paare von Fragen enthalten, die sich semantisch nahe stehen. Abgesehen von den drei Datensätzen EQA, Ambiguous und CoreF kontrastieren sie, die bereits verfügbar sind. Wir bewerten auch auf RGF -Counterfactuals, die mit Original- und Q-Fragen gepaart sind, basierend auf dem, ob sie eine Prädikatsänderung oder einen Referenzwechsel durchlaufen haben. Diese Untersätze wurden im Haus annottiert, um Lärm zu eliminieren. und werden als Ressource zur Verfügung gestellt. Alle Bas islinien sind nicht in der Lage, die Konsistenz mit dem Ensemble-Modell&nbsp;&nbsp; Improving Consistency via Small Margin Allerdings hat RDF-Konterfaktualvergrößerung beeindruckende Gewinne und Konsistenz. Sowohl auf vorherigen Datensätzen als auch auf den beiden Subsätzen werden wir kuratiert. für Referenz - und Predikate-Motivationen. Beachten Sie, dass die erweiterte Argie der Daten nicht durch Motivationstypen verzerrt ist, nur die Evaluierungssätze sind. In der Tat wurde eine qualitative Inspektion der Arten von Counterfeits erstellt. Zeigen Sie, dass die generierten Fragen mehrere verschiedene Störungen enthalten. Zum Beispiel diese ursprüngliche Frage über die Bevölkerung von Walnut Grove, Minnesota, ist auf unterschiedliche Dimensionen wie Stadt, Staat, Land und Land verwirrt. und verschiedene Prädikate wie Standort, Poverty, Anzahl der Schulen. R GF-Perturbationen sind kontextspezifisch. Zum Beispiel für diese andere Frage über den Wimmenden. Das Einzel-Turnier ist eine lange, Typ of Game, Typ of Tournament oder das Game-Outcome. Wir lösen die Aufgabe, die Counterfactual-Daten zu berücksichtigen. #Ah Augmentation and Perturbations for Informationen suchen, Queries suchen und Wir haben uns mit den einzigartigen Herausforderungen der Reversal of the Generation-Ansatz befasst. Übergen erieren mit Nearsight-Misses des Modells und filtern nach Störungsart oder Minimalität. Wir finden , dass diese Technik keine zusätzliche Aufsicht erfordert und die Beispiele sind für Augmentation gekennzeichnet. Augmentation verbessert die Ausdehnung der Domäne und die Nachbarschaftskonsistenz. Und wir finden , dass RGF-Kontrast-Fakturiere semantisch divers sind, ohne zu introduzieren. Buyers during Augmentation. (Bei Augmentation) Danke fürs Gespräch.", "delays": [4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 4500.0, 6000.0, 6000.0, 6000.0, 6000.0, 6250.0, 6250.0, 6250.0, 6250.0, 9000.0, 9000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 16750.0, 16750.0, 16750.0, 16750.0, 16750.0, 16750.0, 17250.0, 17250.0, 17250.0, 17250.0, 17250.0, 17250.0, 17250.0, 17250.0, 20000.0, 21250.0, 21250.0, 21250.0, 21250.0, 21250.0, 21250.0, 21250.0, 21250.0, 21250.0, 21250.0, 21250.0, 25500.0, 25500.0, 25500.0, 25500.0, 27000.0, 27000.0, 27000.0, 27000.0, 27000.0, 27000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 29000.0, 32750.0, 32750.0, 32750.0, 32750.0, 32750.0, 32750.0, 32750.0, 32750.0, 32750.0, 32750.0, 35500.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 37000.0, 40000.0, 40750.0, 40750.0, 40750.0, 40750.0, 40750.0, 40750.0, 40750.0, 40750.0, 40750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 43750.0, 48000.0, 48000.0, 49500.0, 49500.0, 49500.0, 49750.0, 49750.0, 49750.0, 49750.0, 49750.0, 49750.0, 49750.0, 49750.0, 49750.0, 49750.0, 49750.0, 49750.0, 52500.0, 52500.0, 52500.0, 53250.0, 53250.0, 53250.0, 53250.0, 53250.0, 53250.0, 53250.0, 53250.0, 56000.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 58250.0, 61250.0, 61250.0, 61250.0, 61250.0, 61250.0, 66250.0, 66250.0, 66250.0, 66250.0, 66250.0, 66250.0, 66250.0, 66250.0, 66250.0, 66250.0, 66250.0, 69000.0, 69000.0, 69000.0, 69000.0, 69000.0, 69000.0, 69000.0, 69000.0, 71500.0, 71500.0, 71500.0, 71500.0, 71500.0, 73500.0, 73500.0, 73500.0, 73500.0, 73500.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80250.0, 80250.0, 80250.0, 80250.0, 84250.0, 84250.0, 84250.0, 84250.0, 84250.0, 84250.0, 84250.0, 84250.0, 84250.0, 84250.0, 84250.0, 87000.0, 87000.0, 88500.0, 88500.0, 88500.0, 88500.0, 88500.0, 91000.0, 91000.0, 91000.0, 91000.0, 91000.0, 91000.0, 91000.0, 91000.0, 91000.0, 91000.0, 91000.0, 91000.0, 91000.0, 95750.0, 97250.0, 98750.0, 98750.0, 98750.0, 98750.0, 98750.0, 98750.0, 98750.0, 98750.0, 98750.0, 99000.0, 99000.0, 103250.0, 103250.0, 103250.0, 103250.0, 103250.0, 103250.0, 103250.0, 103250.0, 103250.0, 103250.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 106750.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 109000.0, 109000.0, 109000.0, 109000.0, 109000.0, 109000.0, 113250.0, 113250.0, 113250.0, 113250.0, 113250.0, 113250.0, 113250.0, 115500.0, 115500.0, 115500.0, 115500.0, 115500.0, 115500.0, 119750.0, 120250.0, 120250.0, 120250.0, 120250.0, 120250.0, 120250.0, 120250.0, 120250.0, 120250.0, 120250.0, 120250.0, 120250.0, 120250.0, 125250.0, 125250.0, 125250.0, 125250.0, 125250.0, 125250.0, 125250.0, 125250.0, 127250.0, 127250.0, 127250.0, 129750.0, 129750.0, 129750.0, 129750.0, 132500.0, 132500.0, 132500.0, 134000.0, 134000.0, 134000.0, 134000.0, 134000.0, 135500.0, 135500.0, 135500.0, 135500.0, 135500.0, 135500.0, 135500.0, 135500.0, 135500.0, 137000.0, 137000.0, 137000.0, 137000.0, 137750.0, 137750.0, 137750.0, 137750.0, 137750.0, 137750.0, 137750.0, 140500.0, 140500.0, 140500.0, 140500.0, 140500.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 141750.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 147500.0, 149500.0, 149500.0, 149500.0, 149500.0, 155000.0, 155000.0, 155000.0, 155000.0, 155000.0, 155250.0, 155250.0, 155250.0, 155250.0, 155250.0, 155250.0, 155250.0, 155250.0, 155250.0, 155250.0, 158000.0, 158000.0, 159500.0, 159500.0, 159500.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 164750.0, 164750.0, 164750.0, 166250.0, 166250.0, 166250.0, 166250.0, 166250.0, 166250.0, 166250.0, 167750.0, 167750.0, 167750.0, 167750.0, 167750.0, 167750.0, 167750.0, 172000.0, 172000.0, 172000.0, 173500.0, 173500.0, 173500.0, 173500.0, 173500.0, 173500.0, 173500.0, 173500.0, 174500.0, 174500.0, 174500.0, 174500.0, 174500.0, 174500.0, 179500.0, 179500.0, 179500.0, 179500.0, 179500.0, 181000.0, 181000.0, 182500.0, 182500.0, 182500.0, 182500.0, 182500.0, 182500.0, 185500.0, 185500.0, 185500.0, 185500.0, 185750.0, 185750.0, 185750.0, 185750.0, 185750.0, 185750.0, 185750.0, 185750.0, 185750.0, 188500.0, 188500.0, 191500.0, 191500.0, 191500.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 193000.0, 198750.0, 198750.0, 200000.0, 200000.0, 200000.0, 200000.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 204250.0, 208500.0, 211500.0, 211500.0, 211500.0, 211500.0, 211500.0, 211500.0, 211500.0, 211500.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 213750.0, 221000.0, 221000.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 222750.0, 225500.0, 225500.0, 225500.0, 228500.0, 228500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 229500.0, 232000.0, 232000.0, 233500.0, 233500.0, 233500.0, 233500.0, 233500.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 238000.0, 241000.0, 241000.0, 241000.0, 241000.0, 241000.0, 241000.0, 241000.0, 243750.0, 246750.0, 246750.0, 246750.0, 246750.0, 246750.0, 246750.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248750.0, 248750.0, 248750.0, 248750.0, 248750.0, 248750.0, 248750.0, 248750.0, 248750.0, 248750.0, 250750.0, 250750.0, 250750.0, 250750.0, 250750.0, 253500.0, 253500.0, 255000.0, 256500.0, 256500.0, 256500.0, 256500.0, 256500.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 262250.0, 262250.0, 262250.0, 262250.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 265500.0, 268000.0, 268000.0, 268000.0, 268000.0, 271000.0, 271000.0, 271000.0, 271000.0, 271000.0, 271000.0, 271000.0, 271000.0, 271000.0, 271000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 274250.0, 274250.0, 274250.0, 278500.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 281250.0, 281250.0, 281250.0, 281250.0, 281250.0, 283500.0, 283500.0, 283500.0, 283500.0, 283500.0, 283500.0, 283500.0, 287250.0, 287250.0, 287250.0, 287250.0, 287250.0, 287250.0, 287250.0, 287250.0, 290000.0, 290000.0, 290000.0, 290000.0, 290000.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 290250.0, 294500.0, 294500.0, 294500.0, 294500.0, 294500.0, 295250.0, 295250.0, 295250.0, 295250.0, 295250.0, 295250.0, 297500.0, 297500.0, 297500.0, 297500.0, 297500.0, 297500.0, 297500.0, 297500.0, 297500.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 302750.0, 302750.0, 302750.0, 302750.0, 304000.0, 304000.0, 304000.0, 304000.0, 307250.0, 307500.0, 307500.0, 307500.0, 307500.0, 307500.0, 307500.0, 307500.0, 310250.0, 310250.0, 311750.0, 311750.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 313250.0, 315750.0, 315750.0, 315750.0, 315750.0, 315750.0, 315750.0, 318500.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 321500.0, 321500.0, 321500.0, 321500.0, 321500.0, 321500.0, 323000.0, 323000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 329500.0, 329500.0, 329500.0, 329500.0, 329500.0, 330750.0, 330750.0, 330750.0, 330750.0, 330750.0, 330750.0, 330750.0, 330750.0, 330750.0, 330750.0, 335000.0, 335000.0, 336500.0, 336500.0, 336500.0, 336500.0, 336500.0, 336500.0, 336500.0, 336500.0, 337000.0, 337000.0, 337000.0, 337000.0, 337000.0, 337000.0, 342750.0, 342750.0, 342750.0, 342750.0, 342750.0, 342750.0, 342750.0, 342750.0, 342750.0, 342750.0, 342750.0, 342750.0, 342750.0, 345500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 346500.0, 350750.0, 350750.0, 350750.0, 350750.0, 350750.0, 350750.0, 352000.0, 352000.0, 352750.0, 352750.0, 352750.0, 352750.0, 352750.0, 352750.0, 352750.0, 352750.0, 352750.0, 352750.0, 352750.0, 352750.0, 352750.0, 352750.0, 355000.0, 355000.0, 355000.0, 355000.0, 355000.0, 355000.0, 357750.0, 359250.0, 359250.0, 359500.0, 359500.0, 359500.0, 359500.0, 359500.0, 359500.0, 362250.0, 362250.0, 362250.0, 362250.0, 362250.0, 362250.0, 362250.0, 367000.0, 367000.0, 367000.0, 368500.0, 368500.0, 368500.0, 369250.0, 369250.0, 369250.0, 369250.0, 369250.0, 369250.0, 369250.0, 369250.0, 375000.0, 375000.0, 375000.0, 375000.0, 375000.0, 375000.0, 375000.0, 375000.0, 375000.0, 375000.0, 375000.0, 375000.0, 377750.0, 379250.0, 379250.0, 379250.0, 379250.0, 379250.0, 379500.0, 379500.0, 379500.0, 379500.0, 379500.0, 379500.0, 382250.0, 382250.0, 384500.0, 384500.0, 384500.0, 384500.0, 384500.0, 384500.0, 384500.0, 384500.0, 384500.0, 384500.0, 387500.0, 387500.0, 387500.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 390500.0, 390500.0, 390500.0, 390500.0, 390500.0, 390500.0, 390500.0, 390500.0, 390500.0, 390500.0, 390500.0, 392750.0, 392750.0, 392750.0, 392750.0, 392750.0, 392750.0, 392750.0, 392750.0, 395500.0, 395500.0, 395500.0, 396750.0, 396750.0, 396750.0, 396750.0, 396750.0, 399000.0, 399000.0, 399000.0, 399000.0, 399000.0, 399000.0, 399000.0, 403000.0, 403000.0, 403000.0, 403000.0, 403000.0, 403000.0, 406000.0, 406000.0, 406000.0, 406000.0, 406000.0, 406000.0, 406000.0, 406000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 414500.0, 414500.0, 414500.0, 414500.0, 414500.0, 414500.0, 414500.0, 419750.0, 419750.0, 419750.0, 419750.0, 419750.0, 419750.0, 419750.0, 422500.0, 422500.0, 422500.0, 423000.0, 423000.0, 423000.0, 423000.0, 423000.0, 423000.0, 425250.0, 425250.0, 425250.0, 425250.0, 425250.0, 425250.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 430500.0, 430500.0, 430500.0, 430500.0, 433250.0, 433250.0, 433250.0, 434000.0, 434000.0, 434000.0, 434000.0, 434000.0, 434000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 441500.0, 442250.0, 442250.0, 442250.0, 442250.0, 442250.0, 442250.0, 442250.0, 447250.0, 447250.0, 448250.0, 448250.0, 448250.0, 448250.0, 448250.0, 448250.0, 448250.0, 448250.0, 451000.0, 451000.0, 451000.0, 451500.0, 451500.0, 451500.0, 454250.0, 454250.0, 454250.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 455000.0, 457750.0, 458000.0, 458000.0, 458000.0, 458000.0, 458000.0, 458000.0, 458000.0, 460750.0, 460750.0, 462250.0, 462250.0, 462250.0, 462250.0, 462250.0, 462250.0, 462250.0, 462250.0, 462250.0, 466000.0, 466000.0, 466000.0, 466000.0, 466000.0, 466000.0, 466000.0, 466000.0, 466000.0, 466000.0, 466000.0, 466000.0, 470000.0, 470000.0, 470000.0, 470000.0, 470000.0, 470000.0, 470000.0, 470000.0, 470000.0, 473250.0, 473250.0, 473250.0, 473250.0, 473250.0, 473250.0, 473250.0, 473250.0, 476000.0, 477500.0, 477500.0, 477500.0, 477500.0, 477500.0, 478500.0, 478500.0, 478500.0, 478500.0, 478500.0, 478500.0, 478500.0, 478500.0, 482250.0, 482250.0, 482250.0, 482250.0, 482250.0, 482250.0, 484500.0, 484500.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 488750.0, 491500.0, 491500.0, 491500.0, 493000.0, 493000.0, 493000.0, 493000.0, 493000.0, 493000.0, 493000.0, 497000.0, 497000.0, 497000.0, 497000.0, 497000.0, 497000.0, 497000.0, 500000.0, 500000.0, 500000.0, 500000.0, 505000.0, 505000.0, 505000.0, 505000.0, 505000.0, 505000.0, 505000.0, 505000.0, 505000.0, 505000.0, 507750.0, 507750.0, 507750.0, 507750.0, 508500.0, 508500.0, 508500.0, 508500.0, 508500.0, 511000.0, 511000.0, 511000.0, 511000.0, 511000.0, 511000.0, 511000.0, 516500.0, 516500.0, 516500.0, 516500.0, 516500.0, 516500.0, 516500.0, 516500.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 521250.0, 524000.0, 525250.0, 525250.0, 525250.0, 525250.0, 525250.0, 525250.0, 525250.0, 529500.0, 529500.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 530250.0, 532500.0, 532500.0, 532500.0, 532500.0, 532500.0, 532500.0, 532500.0, 532500.0, 532500.0, 532500.0, 532500.0, 535250.0, 535250.0, 536750.0, 536750.0, 536750.0, 536750.0, 537000.0, 537000.0, 537000.0, 537000.0, 537000.0, 537000.0, 537000.0, 539000.0, 539000.0, 539000.0, 539000.0, 539000.0, 539000.0, 543750.0, 545250.0, 545250.0, 545250.0, 545250.0, 546250.0, 546250.0, 546250.0, 546250.0, 546250.0, 546250.0, 546250.0, 546250.0, 546250.0, 549000.0, 549000.0, 549000.0, 549000.0, 549000.0, 549500.0, 549500.0, 552000.0, 552000.0, 553500.0, 553500.0, 553500.0, 553500.0, 553500.0, 553500.0, 553500.0, 554250.0, 554250.0, 554250.0, 557250.0, 557250.0, 557250.0, 560000.0, 560250.0, 560250.0, 560250.0, 560250.0, 560250.0, 563000.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 565750.0, 568500.0, 568500.0, 568500.0, 568500.0, 571250.0, 571250.0, 571250.0, 571250.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 577500.0, 577500.0, 577500.0, 577500.0, 577500.0, 579000.0, 579000.0, 579000.0, 579000.0, 579000.0, 579500.0, 579500.0, 579500.0, 579500.0, 579500.0, 579500.0, 579500.0, 579500.0, 579500.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 587500.0, 590250.0, 591750.0, 591750.0, 591750.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 595000.0, 595000.0, 595000.0, 595000.0, 595000.0, 595000.0, 595000.0, 595000.0, 599250.0, 599250.0, 599250.0, 599250.0, 599250.0, 600750.0, 600750.0, 601750.0, 601750.0, 601750.0, 601750.0, 601750.0, 601750.0, 601750.0, 601750.0, 601750.0, 604500.0, 604500.0, 604500.0, 604500.0, 606000.0, 606000.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 608500.0, 611250.0, 612750.0, 612750.0, 612750.0, 612750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 616750.0, 620250.0, 620250.0, 620250.0, 620250.0, 620250.0, 620250.0, 620250.0, 620250.0, 620250.0, 620250.0, 622250.0, 622250.0, 622250.0, 622250.0, 622250.0, 622250.0, 622250.0, 627000.0, 627000.0, 628500.0, 628500.0, 629250.0, 629250.0, 629250.0, 629250.0, 629250.0, 629250.0, 629250.0, 629250.0, 629250.0, 631500.0, 631500.0, 631500.0, 631500.0, 631500.0, 636000.0, 637500.0, 637500.0, 637500.0, 637500.0, 637500.0, 637500.0, 641500.0, 641500.0, 641500.0, 641500.0, 641500.0, 641500.0, 641500.0, 641500.0, 641500.0, 641500.0, 641500.0, 641500.0, 641500.0, 644000.0, 644000.0, 644250.0, 644250.0, 644250.0, 648500.0, 648500.0, 648500.0, 650000.0, 650250.0, 650250.0, 650250.0, 650250.0, 650250.0, 650250.0, 650250.0, 650250.0, 650250.0, 650250.0, 650250.0, 650250.0, 650250.0, 655750.0, 655750.0, 655750.0, 655750.0, 655750.0, 655750.0, 655750.0, 655750.0, 655750.0, 655750.0, 655750.0, 655750.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 660500.0, 661500.0, 661500.0, 661500.0, 661500.0, 665500.0, 665500.0, 665500.0, 665500.0, 665500.0, 667000.0, 667000.0, 668500.0, 668500.0, 668500.0, 668500.0, 668500.0, 668500.0, 670500.0, 670500.0, 670500.0, 670500.0, 670500.0, 670500.0, 670500.0, 670500.0, 670500.0, 670500.0, 673250.0, 673250.0, 673250.0, 673250.0, 675500.0, 675500.0, 675500.0, 675500.0, 675500.0, 679750.0, 682000.0, 682000.0, 682000.0, 682000.0, 682000.0, 682000.0, 682000.0, 682000.0, 682000.0, 682000.0, 682000.0, 682000.0, 685250.0, 685250.0, 685250.0, 685250.0, 685250.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 694000.0, 694000.0, 694000.0, 694000.0, 694000.0, 694000.0, 694000.0, 694000.0, 697000.0, 697000.0, 697000.0, 697000.0, 697000.0, 699500.0, 699500.0, 699500.0, 699500.0, 699500.0, 703500.0, 703500.0, 703500.0, 703500.0, 703500.0, 703500.0, 703500.0, 703500.0, 703500.0, 703500.0, 703500.0, 703500.0, 703500.0, 706250.0, 707750.0, 709000.0, 709000.0, 709000.0, 709000.0, 709000.0, 709000.0, 709000.0, 709000.0, 709000.0, 709000.0, 711750.0, 711750.0, 713250.0, 713250.0, 713250.0, 713250.0, 713250.0, 714750.0, 714750.0, 714750.0, 714750.0, 714750.0, 714750.0, 717500.0, 717500.0, 717500.0, 719000.0, 719000.0, 719000.0, 719000.0, 719000.0, 719000.0, 719000.0, 719000.0, 719000.0, 719000.0, 721750.0, 721750.0, 721750.0, 723000.0, 723000.0, 723000.0, 723000.0, 723000.0, 723000.0, 723000.0, 723000.0, 723000.0, 725000.0, 725000.0, 725000.0, 725000.0, 725000.0, 729000.0, 729000.0, 729000.0], "elapsed": [8433.358430862427, 8433.358430862427, 8433.358430862427, 8433.358430862427, 8433.358430862427, 8433.358430862427, 12110.558271408081, 12110.558271408081, 12110.558271408081, 12110.558271408081, 13896.836996078491, 13896.836996078491, 13896.836996078491, 13896.836996078491, 18864.376544952393, 18864.376544952393, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 25411.433935165405, 34289.27278518677, 34289.27278518677, 34289.27278518677, 34289.27278518677, 34289.27278518677, 34289.27278518677, 35856.53877258301, 35856.53877258301, 35856.53877258301, 35856.53877258301, 35856.53877258301, 35856.53877258301, 35856.53877258301, 35856.53877258301, 40687.52932548523, 43408.22744369507, 43408.22744369507, 43408.22744369507, 43408.22744369507, 43408.22744369507, 43408.22744369507, 43408.22744369507, 43408.22744369507, 43408.22744369507, 43408.22744369507, 43408.22744369507, 51714.648723602295, 51714.648723602295, 51714.648723602295, 51714.648723602295, 55178.73406410217, 55178.73406410217, 55178.73406410217, 55178.73406410217, 55178.73406410217, 55178.73406410217, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 60597.45979309082, 67922.39499092102, 67922.39499092102, 67922.39499092102, 67922.39499092102, 67922.39499092102, 67922.39499092102, 67922.39499092102, 67922.39499092102, 67922.39499092102, 67922.39499092102, 72576.8883228302, 75531.64219856262, 75531.64219856262, 75531.64219856262, 75531.64219856262, 75531.64219856262, 75531.64219856262, 75531.64219856262, 75531.64219856262, 75531.64219856262, 75531.64219856262, 80757.48801231384, 82951.71570777893, 82951.71570777893, 82951.71570777893, 82951.71570777893, 82951.71570777893, 82951.71570777893, 82951.71570777893, 82951.71570777893, 82951.71570777893, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 90741.13178253174, 98834.38611030579, 98834.38611030579, 102386.94190979004, 102386.94190979004, 102386.94190979004, 104521.65627479553, 104521.65627479553, 104521.65627479553, 104521.65627479553, 104521.65627479553, 104521.65627479553, 104521.65627479553, 104521.65627479553, 104521.65627479553, 104521.65627479553, 104521.65627479553, 104521.65627479553, 109264.02854919434, 109264.02854919434, 109264.02854919434, 111242.36941337585, 111242.36941337585, 111242.36941337585, 111242.36941337585, 111242.36941337585, 111242.36941337585, 111242.36941337585, 111242.36941337585, 115914.32905197144, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 121451.45845413208, 127469.39492225647, 127469.39492225647, 127469.39492225647, 127469.39492225647, 127469.39492225647, 138229.46333885193, 138229.46333885193, 138229.46333885193, 138229.46333885193, 138229.46333885193, 138229.46333885193, 138229.46333885193, 138229.46333885193, 138229.46333885193, 138229.46333885193, 138229.46333885193, 143068.1381225586, 143068.1381225586, 143068.1381225586, 143068.1381225586, 143068.1381225586, 143068.1381225586, 143068.1381225586, 143068.1381225586, 147586.67540550232, 147586.67540550232, 147586.67540550232, 147586.67540550232, 147586.67540550232, 151369.12608146667, 151369.12608146667, 151369.12608146667, 151369.12608146667, 151369.12608146667, 155714.13135528564, 155714.13135528564, 155714.13135528564, 155714.13135528564, 155714.13135528564, 155714.13135528564, 155714.13135528564, 162610.63861846924, 162610.63861846924, 162610.63861846924, 162610.63861846924, 162610.63861846924, 163908.19597244263, 163908.19597244263, 163908.19597244263, 163908.19597244263, 171669.74925994873, 171669.74925994873, 171669.74925994873, 171669.74925994873, 171669.74925994873, 171669.74925994873, 171669.74925994873, 171669.74925994873, 171669.74925994873, 171669.74925994873, 171669.74925994873, 176402.7178287506, 176402.7178287506, 178985.90064048767, 178985.90064048767, 178985.90064048767, 178985.90064048767, 178985.90064048767, 184764.40405845642, 184764.40405845642, 184764.40405845642, 184764.40405845642, 184764.40405845642, 184764.40405845642, 184764.40405845642, 184764.40405845642, 184764.40405845642, 184764.40405845642, 184764.40405845642, 184764.40405845642, 184764.40405845642, 191515.78044891357, 194363.28411102295, 197371.7007637024, 197371.7007637024, 197371.7007637024, 197371.7007637024, 197371.7007637024, 197371.7007637024, 197371.7007637024, 197371.7007637024, 197371.7007637024, 198484.5027923584, 198484.5027923584, 206998.02827835083, 206998.02827835083, 206998.02827835083, 206998.02827835083, 206998.02827835083, 206998.02827835083, 206998.02827835083, 206998.02827835083, 206998.02827835083, 206998.02827835083, 208996.30570411682, 208996.30570411682, 208996.30570411682, 208996.30570411682, 208996.30570411682, 213775.2866744995, 216318.0227279663, 216318.0227279663, 216318.0227279663, 216318.0227279663, 216318.0227279663, 216318.0227279663, 216318.0227279663, 216318.0227279663, 218402.64749526978, 218402.64749526978, 218402.64749526978, 218402.64749526978, 218402.64749526978, 218402.64749526978, 225814.87846374512, 225814.87846374512, 225814.87846374512, 225814.87846374512, 225814.87846374512, 225814.87846374512, 225814.87846374512, 230649.43289756775, 230649.43289756775, 230649.43289756775, 230649.43289756775, 230649.43289756775, 230649.43289756775, 238015.5532360077, 239934.14998054504, 239934.14998054504, 239934.14998054504, 239934.14998054504, 239934.14998054504, 239934.14998054504, 239934.14998054504, 239934.14998054504, 239934.14998054504, 239934.14998054504, 239934.14998054504, 239934.14998054504, 239934.14998054504, 248269.7207927704, 248269.7207927704, 248269.7207927704, 248269.7207927704, 248269.7207927704, 248269.7207927704, 248269.7207927704, 248269.7207927704, 252128.31592559814, 252128.31592559814, 252128.31592559814, 256500.00619888306, 256500.00619888306, 256500.00619888306, 256500.00619888306, 261541.43166542053, 261541.43166542053, 261541.43166542053, 264436.79761886597, 264436.79761886597, 264436.79761886597, 264436.79761886597, 264436.79761886597, 267273.85354042053, 267273.85354042053, 267273.85354042053, 267273.85354042053, 267273.85354042053, 267273.85354042053, 267273.85354042053, 267273.85354042053, 267273.85354042053, 270081.8347930908, 270081.8347930908, 270081.8347930908, 270081.8347930908, 271967.87190437317, 271967.87190437317, 271967.87190437317, 271967.87190437317, 271967.87190437317, 271967.87190437317, 271967.87190437317, 276884.17959213257, 276884.17959213257, 276884.17959213257, 276884.17959213257, 276884.17959213257, 279245.95522880554, 279245.95522880554, 279245.95522880554, 279245.95522880554, 279245.95522880554, 279245.95522880554, 279245.95522880554, 279245.95522880554, 279245.95522880554, 279245.95522880554, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 290212.50557899475, 294081.57324790955, 294081.57324790955, 294081.57324790955, 294081.57324790955, 304349.223613739, 304349.223613739, 304349.223613739, 304349.223613739, 304349.223613739, 306058.2778453827, 306058.2778453827, 306058.2778453827, 306058.2778453827, 306058.2778453827, 306058.2778453827, 306058.2778453827, 306058.2778453827, 306058.2778453827, 306058.2778453827, 310614.95995521545, 310614.95995521545, 313377.5849342346, 313377.5849342346, 313377.5849342346, 315163.47312927246, 315163.47312927246, 315163.47312927246, 315163.47312927246, 315163.47312927246, 315163.47312927246, 315163.47312927246, 315163.47312927246, 322032.4251651764, 322032.4251651764, 322032.4251651764, 325234.2219352722, 325234.2219352722, 325234.2219352722, 325234.2219352722, 325234.2219352722, 325234.2219352722, 325234.2219352722, 328194.72074508667, 328194.72074508667, 328194.72074508667, 328194.72074508667, 328194.72074508667, 328194.72074508667, 328194.72074508667, 336251.28269195557, 336251.28269195557, 336251.28269195557, 339391.28589630127, 339391.28589630127, 339391.28589630127, 339391.28589630127, 339391.28589630127, 339391.28589630127, 339391.28589630127, 339391.28589630127, 341582.93747901917, 341582.93747901917, 341582.93747901917, 341582.93747901917, 341582.93747901917, 341582.93747901917, 349821.1908340454, 349821.1908340454, 349821.1908340454, 349821.1908340454, 349821.1908340454, 352604.1417121887, 352604.1417121887, 355342.5512313843, 355342.5512313843, 355342.5512313843, 355342.5512313843, 355342.5512313843, 355342.5512313843, 361462.5735282898, 361462.5735282898, 361462.5735282898, 361462.5735282898, 363292.1781539917, 363292.1781539917, 363292.1781539917, 363292.1781539917, 363292.1781539917, 363292.1781539917, 363292.1781539917, 363292.1781539917, 363292.1781539917, 368076.03096961975, 368076.03096961975, 375016.0789489746, 375016.0789489746, 375016.0789489746, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 378397.72605895996, 388783.79940986633, 388783.79940986633, 391955.0199508667, 391955.0199508667, 391955.0199508667, 391955.0199508667, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 402683.002948761, 409925.57096481323, 416668.6599254608, 416668.6599254608, 416668.6599254608, 416668.6599254608, 416668.6599254608, 416668.6599254608, 416668.6599254608, 416668.6599254608, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 422693.8548088074, 438267.21692085266, 438267.21692085266, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 444741.1823272705, 449437.9916191101, 449437.9916191101, 449437.9916191101, 455564.1667842865, 455564.1667842865, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 458683.7422847748, 462969.3329334259, 462969.3329334259, 465544.3947315216, 465544.3947315216, 465544.3947315216, 465544.3947315216, 465544.3947315216, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 474935.6966018677, 480718.1580066681, 480718.1580066681, 480718.1580066681, 480718.1580066681, 480718.1580066681, 480718.1580066681, 480718.1580066681, 485710.6001377106, 491918.40147972107, 491918.40147972107, 491918.40147972107, 491918.40147972107, 491918.40147972107, 491918.40147972107, 495126.1525154114, 495126.1525154114, 495126.1525154114, 495126.1525154114, 495126.1525154114, 495126.1525154114, 497260.8244419098, 497260.8244419098, 497260.8244419098, 497260.8244419098, 497260.8244419098, 497260.8244419098, 497260.8244419098, 497260.8244419098, 497260.8244419098, 497260.8244419098, 501039.2334461212, 501039.2334461212, 501039.2334461212, 501039.2334461212, 501039.2334461212, 506082.0024013519, 506082.0024013519, 508977.8723716736, 512392.915725708, 512392.915725708, 512392.915725708, 512392.915725708, 512392.915725708, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 521583.1551551819, 525717.9534435272, 525717.9534435272, 525717.9534435272, 525717.9534435272, 532040.1477813721, 532040.1477813721, 532040.1477813721, 532040.1477813721, 532040.1477813721, 532040.1477813721, 532040.1477813721, 532040.1477813721, 536565.7689571381, 536565.7689571381, 536565.7689571381, 536565.7689571381, 542546.6601848602, 542546.6601848602, 542546.6601848602, 542546.6601848602, 542546.6601848602, 542546.6601848602, 542546.6601848602, 542546.6601848602, 542546.6601848602, 542546.6601848602, 545139.3089294434, 545139.3089294434, 545139.3089294434, 545139.3089294434, 545139.3089294434, 545139.3089294434, 545139.3089294434, 545139.3089294434, 545139.3089294434, 545139.3089294434, 545139.3089294434, 545139.3089294434, 549405.5128097534, 549405.5128097534, 549405.5128097534, 556926.6777038574, 560222.8939533234, 560222.8939533234, 560222.8939533234, 560222.8939533234, 560222.8939533234, 560222.8939533234, 560222.8939533234, 560222.8939533234, 560222.8939533234, 560222.8939533234, 560222.8939533234, 562602.694272995, 562602.694272995, 562602.694272995, 562602.694272995, 562602.694272995, 567008.4943771362, 567008.4943771362, 567008.4943771362, 567008.4943771362, 567008.4943771362, 567008.4943771362, 567008.4943771362, 575249.4378089905, 575249.4378089905, 575249.4378089905, 575249.4378089905, 575249.4378089905, 575249.4378089905, 575249.4378089905, 575249.4378089905, 580488.6360168457, 580488.6360168457, 580488.6360168457, 580488.6360168457, 580488.6360168457, 581894.2368030548, 581894.2368030548, 581894.2368030548, 581894.2368030548, 581894.2368030548, 581894.2368030548, 581894.2368030548, 581894.2368030548, 589619.8537349701, 589619.8537349701, 589619.8537349701, 589619.8537349701, 589619.8537349701, 591486.8092536926, 591486.8092536926, 591486.8092536926, 591486.8092536926, 591486.8092536926, 591486.8092536926, 596190.9759044647, 596190.9759044647, 596190.9759044647, 596190.9759044647, 596190.9759044647, 596190.9759044647, 596190.9759044647, 596190.9759044647, 596190.9759044647, 600363.2078170776, 600363.2078170776, 600363.2078170776, 600363.2078170776, 600363.2078170776, 605060.4336261749, 605060.4336261749, 605060.4336261749, 605060.4336261749, 607207.0970535278, 607207.0970535278, 607207.0970535278, 607207.0970535278, 613327.2550106049, 614685.0538253784, 614685.0538253784, 614685.0538253784, 614685.0538253784, 614685.0538253784, 614685.0538253784, 614685.0538253784, 619699.1007328033, 619699.1007328033, 622732.2416305542, 622732.2416305542, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 626098.6928939819, 630627.2358894348, 630627.2358894348, 630627.2358894348, 630627.2358894348, 630627.2358894348, 630627.2358894348, 635412.9581451416, 638266.8082714081, 638266.8082714081, 638266.8082714081, 638266.8082714081, 638266.8082714081, 638266.8082714081, 641192.2879219055, 641192.2879219055, 641192.2879219055, 641192.2879219055, 641192.2879219055, 641192.2879219055, 644288.9614105225, 644288.9614105225, 646747.9696273804, 646747.9696273804, 646747.9696273804, 646747.9696273804, 646747.9696273804, 646747.9696273804, 646747.9696273804, 646747.9696273804, 646747.9696273804, 646747.9696273804, 646747.9696273804, 657080.260515213, 657080.260515213, 657080.260515213, 657080.260515213, 657080.260515213, 659844.113111496, 659844.113111496, 659844.113111496, 659844.113111496, 659844.113111496, 659844.113111496, 659844.113111496, 659844.113111496, 659844.113111496, 659844.113111496, 667493.7143325806, 667493.7143325806, 670645.10846138, 670645.10846138, 670645.10846138, 670645.10846138, 670645.10846138, 670645.10846138, 670645.10846138, 670645.10846138, 672188.4407997131, 672188.4407997131, 672188.4407997131, 672188.4407997131, 672188.4407997131, 672188.4407997131, 683236.8967533112, 683236.8967533112, 683236.8967533112, 683236.8967533112, 683236.8967533112, 683236.8967533112, 683236.8967533112, 683236.8967533112, 683236.8967533112, 683236.8967533112, 683236.8967533112, 683236.8967533112, 683236.8967533112, 688382.0440769196, 691011.855840683, 691011.855840683, 691011.855840683, 691011.855840683, 691011.855840683, 691011.855840683, 691011.855840683, 691011.855840683, 691011.855840683, 691011.855840683, 691011.855840683, 691011.855840683, 698436.4821910858, 698436.4821910858, 698436.4821910858, 698436.4821910858, 698436.4821910858, 698436.4821910858, 701190.2997493744, 701190.2997493744, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 703451.0469436646, 707754.4610500336, 707754.4610500336, 707754.4610500336, 707754.4610500336, 707754.4610500336, 707754.4610500336, 712191.3495063782, 714912.2550487518, 714912.2550487518, 716225.2097129822, 716225.2097129822, 716225.2097129822, 716225.2097129822, 716225.2097129822, 716225.2097129822, 721156.0456752777, 721156.0456752777, 721156.0456752777, 721156.0456752777, 721156.0456752777, 721156.0456752777, 721156.0456752777, 727915.7984256744, 727915.7984256744, 727915.7984256744, 730674.7839450836, 730674.7839450836, 730674.7839450836, 732688.0445480347, 732688.0445480347, 732688.0445480347, 732688.0445480347, 732688.0445480347, 732688.0445480347, 732688.0445480347, 732688.0445480347, 743603.3449172974, 743603.3449172974, 743603.3449172974, 743603.3449172974, 743603.3449172974, 743603.3449172974, 743603.3449172974, 743603.3449172974, 743603.3449172974, 743603.3449172974, 743603.3449172974, 743603.3449172974, 748260.523557663, 751060.2073669434, 751060.2073669434, 751060.2073669434, 751060.2073669434, 751060.2073669434, 752315.0362968445, 752315.0362968445, 752315.0362968445, 752315.0362968445, 752315.0362968445, 752315.0362968445, 757088.7835025787, 757088.7835025787, 761931.6782951355, 761931.6782951355, 761931.6782951355, 761931.6782951355, 761931.6782951355, 761931.6782951355, 761931.6782951355, 761931.6782951355, 761931.6782951355, 761931.6782951355, 767142.1649456024, 767142.1649456024, 767142.1649456024, 768758.9643001556, 768758.9643001556, 768758.9643001556, 768758.9643001556, 768758.9643001556, 768758.9643001556, 768758.9643001556, 773366.3928508759, 773366.3928508759, 773366.3928508759, 773366.3928508759, 773366.3928508759, 773366.3928508759, 773366.3928508759, 773366.3928508759, 773366.3928508759, 773366.3928508759, 773366.3928508759, 777624.755859375, 777624.755859375, 777624.755859375, 777624.755859375, 777624.755859375, 777624.755859375, 777624.755859375, 777624.755859375, 782229.3510437012, 782229.3510437012, 782229.3510437012, 784455.0495147705, 784455.0495147705, 784455.0495147705, 784455.0495147705, 784455.0495147705, 788748.7285137177, 788748.7285137177, 788748.7285137177, 788748.7285137177, 788748.7285137177, 788748.7285137177, 788748.7285137177, 796212.1000289917, 796212.1000289917, 796212.1000289917, 796212.1000289917, 796212.1000289917, 796212.1000289917, 802126.1913776398, 802126.1913776398, 802126.1913776398, 802126.1913776398, 802126.1913776398, 802126.1913776398, 802126.1913776398, 802126.1913776398, 812165.6839847565, 812165.6839847565, 812165.6839847565, 812165.6839847565, 812165.6839847565, 812165.6839847565, 812165.6839847565, 812165.6839847565, 812165.6839847565, 812165.6839847565, 812165.6839847565, 816720.2093601227, 816720.2093601227, 816720.2093601227, 816720.2093601227, 816720.2093601227, 816720.2093601227, 816720.2093601227, 825845.2327251434, 825845.2327251434, 825845.2327251434, 825845.2327251434, 825845.2327251434, 825845.2327251434, 825845.2327251434, 831607.1064472198, 831607.1064472198, 831607.1064472198, 833307.6989650726, 833307.6989650726, 833307.6989650726, 833307.6989650726, 833307.6989650726, 833307.6989650726, 837663.2540225983, 837663.2540225983, 837663.2540225983, 837663.2540225983, 837663.2540225983, 837663.2540225983, 842317.6472187042, 842317.6472187042, 842317.6472187042, 842317.6472187042, 842317.6472187042, 842317.6472187042, 846739.6359443665, 846739.6359443665, 846739.6359443665, 846739.6359443665, 851306.482553482, 851306.482553482, 851306.482553482, 852965.1598930359, 852965.1598930359, 852965.1598930359, 852965.1598930359, 852965.1598930359, 852965.1598930359, 856882.435798645, 856882.435798645, 856882.435798645, 856882.435798645, 856882.435798645, 864001.3353824615, 864001.3353824615, 864001.3353824615, 864001.3353824615, 864001.3353824615, 864001.3353824615, 866785.9170436859, 868736.6766929626, 868736.6766929626, 868736.6766929626, 868736.6766929626, 868736.6766929626, 868736.6766929626, 868736.6766929626, 877230.126619339, 877230.126619339, 879652.2452831268, 879652.2452831268, 879652.2452831268, 879652.2452831268, 879652.2452831268, 879652.2452831268, 879652.2452831268, 879652.2452831268, 884773.2419967651, 884773.2419967651, 884773.2419967651, 886480.9458255768, 886480.9458255768, 886480.9458255768, 891407.5927734375, 891407.5927734375, 891407.5927734375, 893283.5042476654, 893283.5042476654, 893283.5042476654, 893283.5042476654, 893283.5042476654, 893283.5042476654, 893283.5042476654, 893283.5042476654, 893283.5042476654, 893283.5042476654, 897980.1349639893, 899203.497171402, 899203.497171402, 899203.497171402, 899203.497171402, 899203.497171402, 899203.497171402, 899203.497171402, 903993.3731555939, 903993.3731555939, 906843.0836200714, 906843.0836200714, 906843.0836200714, 906843.0836200714, 906843.0836200714, 906843.0836200714, 906843.0836200714, 906843.0836200714, 906843.0836200714, 913897.0921039581, 913897.0921039581, 913897.0921039581, 913897.0921039581, 913897.0921039581, 913897.0921039581, 913897.0921039581, 913897.0921039581, 913897.0921039581, 913897.0921039581, 913897.0921039581, 913897.0921039581, 921112.9419803619, 921112.9419803619, 921112.9419803619, 921112.9419803619, 921112.9419803619, 921112.9419803619, 921112.9419803619, 921112.9419803619, 921112.9419803619, 927797.248840332, 927797.248840332, 927797.248840332, 927797.248840332, 927797.248840332, 927797.248840332, 927797.248840332, 927797.248840332, 932587.8767967224, 935354.0079593658, 935354.0079593658, 935354.0079593658, 935354.0079593658, 935354.0079593658, 937759.1226100922, 937759.1226100922, 937759.1226100922, 937759.1226100922, 937759.1226100922, 937759.1226100922, 937759.1226100922, 937759.1226100922, 944488.7800216675, 944488.7800216675, 944488.7800216675, 944488.7800216675, 944488.7800216675, 944488.7800216675, 948257.8692436218, 948257.8692436218, 956209.4342708588, 956209.4342708588, 956209.4342708588, 956209.4342708588, 956209.4342708588, 956209.4342708588, 956209.4342708588, 956209.4342708588, 956209.4342708588, 956209.4342708588, 956209.4342708588, 961165.8754348755, 961165.8754348755, 961165.8754348755, 964146.9812393188, 964146.9812393188, 964146.9812393188, 964146.9812393188, 964146.9812393188, 964146.9812393188, 964146.9812393188, 971294.909954071, 971294.909954071, 971294.909954071, 971294.909954071, 971294.909954071, 971294.909954071, 971294.909954071, 975945.732831955, 975945.732831955, 975945.732831955, 975945.732831955, 987059.1518878937, 987059.1518878937, 987059.1518878937, 987059.1518878937, 987059.1518878937, 987059.1518878937, 987059.1518878937, 987059.1518878937, 987059.1518878937, 987059.1518878937, 991892.2126293182, 991892.2126293182, 991892.2126293182, 991892.2126293182, 993684.0453147888, 993684.0453147888, 993684.0453147888, 993684.0453147888, 993684.0453147888, 998298.5355854034, 998298.5355854034, 998298.5355854034, 998298.5355854034, 998298.5355854034, 998298.5355854034, 998298.5355854034, 1008034.2826843262, 1008034.2826843262, 1008034.2826843262, 1008034.2826843262, 1008034.2826843262, 1008034.2826843262, 1008034.2826843262, 1008034.2826843262, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1018409.7726345062, 1023502.9172897339, 1026001.9125938416, 1026001.9125938416, 1026001.9125938416, 1026001.9125938416, 1026001.9125938416, 1026001.9125938416, 1026001.9125938416, 1034166.980266571, 1034166.980266571, 1036749.8705387115, 1036749.8705387115, 1036749.8705387115, 1036749.8705387115, 1036749.8705387115, 1036749.8705387115, 1036749.8705387115, 1036749.8705387115, 1036749.8705387115, 1036749.8705387115, 1036749.8705387115, 1040875.9987354279, 1040875.9987354279, 1040875.9987354279, 1040875.9987354279, 1040875.9987354279, 1040875.9987354279, 1040875.9987354279, 1040875.9987354279, 1040875.9987354279, 1040875.9987354279, 1040875.9987354279, 1046016.8211460114, 1046016.8211460114, 1048997.9593753815, 1048997.9593753815, 1048997.9593753815, 1048997.9593753815, 1050519.290447235, 1050519.290447235, 1050519.290447235, 1050519.290447235, 1050519.290447235, 1050519.290447235, 1050519.290447235, 1054343.2445526123, 1054343.2445526123, 1054343.2445526123, 1054343.2445526123, 1054343.2445526123, 1054343.2445526123, 1061312.2990131378, 1064430.8998584747, 1064430.8998584747, 1064430.8998584747, 1064430.8998584747, 1066739.676475525, 1066739.676475525, 1066739.676475525, 1066739.676475525, 1066739.676475525, 1066739.676475525, 1066739.676475525, 1066739.676475525, 1066739.676475525, 1071926.9218444824, 1071926.9218444824, 1071926.9218444824, 1071926.9218444824, 1071926.9218444824, 1073632.7378749847, 1073632.7378749847, 1078291.229724884, 1078291.229724884, 1080962.6212120056, 1080962.6212120056, 1080962.6212120056, 1080962.6212120056, 1080962.6212120056, 1080962.6212120056, 1080962.6212120056, 1083011.7530822754, 1083011.7530822754, 1083011.7530822754, 1088619.9181079865, 1088619.9181079865, 1088619.9181079865, 1093322.7198123932, 1094556.3011169434, 1094556.3011169434, 1094556.3011169434, 1094556.3011169434, 1094556.3011169434, 1099466.5532112122, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1105831.5739631653, 1110332.1468830109, 1110332.1468830109, 1110332.1468830109, 1110332.1468830109, 1115174.1077899933, 1115174.1077899933, 1115174.1077899933, 1115174.1077899933, 1116980.9172153473, 1116980.9172153473, 1116980.9172153473, 1116980.9172153473, 1116980.9172153473, 1127278.033733368, 1127278.033733368, 1127278.033733368, 1127278.033733368, 1127278.033733368, 1130524.1255760193, 1130524.1255760193, 1130524.1255760193, 1130524.1255760193, 1130524.1255760193, 1132353.0316352844, 1132353.0316352844, 1132353.0316352844, 1132353.0316352844, 1132353.0316352844, 1132353.0316352844, 1132353.0316352844, 1132353.0316352844, 1132353.0316352844, 1140605.2286624908, 1140605.2286624908, 1140605.2286624908, 1140605.2286624908, 1140605.2286624908, 1140605.2286624908, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1149575.46377182, 1153960.0553512573, 1156720.34740448, 1156720.34740448, 1156720.34740448, 1158018.8808441162, 1158018.8808441162, 1158018.8808441162, 1158018.8808441162, 1158018.8808441162, 1164427.8962612152, 1164427.8962612152, 1164427.8962612152, 1164427.8962612152, 1164427.8962612152, 1164427.8962612152, 1164427.8962612152, 1164427.8962612152, 1172504.5821666718, 1172504.5821666718, 1172504.5821666718, 1172504.5821666718, 1172504.5821666718, 1175335.8211517334, 1175335.8211517334, 1177665.4093265533, 1177665.4093265533, 1177665.4093265533, 1177665.4093265533, 1177665.4093265533, 1177665.4093265533, 1177665.4093265533, 1177665.4093265533, 1177665.4093265533, 1182674.721956253, 1182674.721956253, 1182674.721956253, 1182674.721956253, 1185746.405363083, 1185746.405363083, 1190908.8580608368, 1190908.8580608368, 1190908.8580608368, 1190908.8580608368, 1190908.8580608368, 1190908.8580608368, 1190908.8580608368, 1190908.8580608368, 1190908.8580608368, 1195735.1155281067, 1198983.1030368805, 1198983.1030368805, 1198983.1030368805, 1198983.1030368805, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1210007.3804855347, 1217287.5139713287, 1217287.5139713287, 1217287.5139713287, 1217287.5139713287, 1217287.5139713287, 1217287.5139713287, 1217287.5139713287, 1217287.5139713287, 1217287.5139713287, 1217287.5139713287, 1221280.3180217743, 1221280.3180217743, 1221280.3180217743, 1221280.3180217743, 1221280.3180217743, 1221280.3180217743, 1221280.3180217743, 1229369.6677684784, 1229369.6677684784, 1232430.0200939178, 1232430.0200939178, 1234860.7711791992, 1234860.7711791992, 1234860.7711791992, 1234860.7711791992, 1234860.7711791992, 1234860.7711791992, 1234860.7711791992, 1234860.7711791992, 1234860.7711791992, 1239029.1259288788, 1239029.1259288788, 1239029.1259288788, 1239029.1259288788, 1239029.1259288788, 1247249.0818500519, 1250436.7969036102, 1250436.7969036102, 1250436.7969036102, 1250436.7969036102, 1250436.7969036102, 1250436.7969036102, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1257971.1153507233, 1262401.6995429993, 1262401.6995429993, 1263664.7431850433, 1263664.7431850433, 1263664.7431850433, 1271875.9169578552, 1271875.9169578552, 1271875.9169578552, 1275548.732995987, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1277677.0446300507, 1287762.1171474457, 1287762.1171474457, 1287762.1171474457, 1287762.1171474457, 1287762.1171474457, 1287762.1171474457, 1287762.1171474457, 1287762.1171474457, 1287762.1171474457, 1287762.1171474457, 1287762.1171474457, 1287762.1171474457, 1295720.2787399292, 1295720.2787399292, 1295720.2787399292, 1295720.2787399292, 1295720.2787399292, 1295720.2787399292, 1297677.772283554, 1297677.772283554, 1297677.772283554, 1297677.772283554, 1305393.4364318848, 1305393.4364318848, 1305393.4364318848, 1305393.4364318848, 1305393.4364318848, 1308087.2268676758, 1308087.2268676758, 1311118.143081665, 1311118.143081665, 1311118.143081665, 1311118.143081665, 1311118.143081665, 1311118.143081665, 1316183.99143219, 1316183.99143219, 1316183.99143219, 1316183.99143219, 1316183.99143219, 1316183.99143219, 1316183.99143219, 1316183.99143219, 1316183.99143219, 1316183.99143219, 1320610.7041835785, 1320610.7041835785, 1320610.7041835785, 1320610.7041835785, 1324965.325832367, 1324965.325832367, 1324965.325832367, 1324965.325832367, 1324965.325832367, 1332817.3084259033, 1338751.470565796, 1338751.470565796, 1338751.470565796, 1338751.470565796, 1338751.470565796, 1338751.470565796, 1338751.470565796, 1338751.470565796, 1338751.470565796, 1338751.470565796, 1338751.470565796, 1338751.470565796, 1344763.5416984558, 1344763.5416984558, 1344763.5416984558, 1344763.5416984558, 1344763.5416984558, 1349676.3854026794, 1349676.3854026794, 1349676.3854026794, 1349676.3854026794, 1349676.3854026794, 1349676.3854026794, 1349676.3854026794, 1349676.3854026794, 1349676.3854026794, 1359005.4812431335, 1359005.4812431335, 1359005.4812431335, 1359005.4812431335, 1359005.4812431335, 1359005.4812431335, 1359005.4812431335, 1359005.4812431335, 1363961.4334106445, 1363961.4334106445, 1363961.4334106445, 1363961.4334106445, 1363961.4334106445, 1368210.3691101074, 1368210.3691101074, 1368210.3691101074, 1368210.3691101074, 1368210.3691101074, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1376067.6128864288, 1381173.6834049225, 1384647.489309311, 1387614.8295402527, 1387614.8295402527, 1387614.8295402527, 1387614.8295402527, 1387614.8295402527, 1387614.8295402527, 1387614.8295402527, 1387614.8295402527, 1387614.8295402527, 1387614.8295402527, 1392136.7053985596, 1392136.7053985596, 1394898.4405994415, 1394898.4405994415, 1394898.4405994415, 1394898.4405994415, 1394898.4405994415, 1397863.0573749542, 1397863.0573749542, 1397863.0573749542, 1397863.0573749542, 1397863.0573749542, 1397863.0573749542, 1402867.6884174347, 1402867.6884174347, 1402867.6884174347, 1406379.5759677887, 1406379.5759677887, 1406379.5759677887, 1406379.5759677887, 1406379.5759677887, 1406379.5759677887, 1406379.5759677887, 1406379.5759677887, 1406379.5759677887, 1406379.5759677887, 1411604.253768921, 1411604.253768921, 1411604.253768921, 1414596.27699852, 1414596.27699852, 1414596.27699852, 1414596.27699852, 1414596.27699852, 1414596.27699852, 1414596.27699852, 1414596.27699852, 1414596.27699852, 1418992.3331737518, 1418992.3331737518, 1418992.3331737518, 1418992.3331737518, 1418992.3331737518, 1424649.3072509766, 1424649.3072509766, 1424649.3072509766], "prediction_length": 1830, "reference": "Hi. Ich werde nun unsere Arbeit am generierenden Retrieval und den erweiterten Kontrafakten für Aufgaben der Fragenbeantwortung vorstellen. Dies ist die Arbeit, die ich während meines Praktikums bei Google Research gemacht habe, wo ich von Matthew Lamm und Ian Tenney betreut wurde. Um die Aufgabe vorzustellen, möchte ich damit beginnen, das Wort kontrafaktisch zu definieren. In dieser Arbeit definieren wir kontrafaktisch als eine Störung des eingegebenen Textes, der sich in irgendeiner bedeutungsvollen kontrollierten Weise vom ursprünglichen Text unterscheidet. Damit können wir über die Änderungen des Ergebnisses oder des Labels der Aufgabe schlussfolgern. Wenn man beispielsweise die Wörter „faszinierend“ zu „fesselnd“ oder „erwartet“ zu „todlangweilig“ ändert, ändert das die Stimmung der Filmrezension. Wird die nähere Bestimmung „Damen“ zur Frage hinzugefügt, ändert sich die Antwort auf die Frage wie im Beispiel unten dargestellt. Menschen sind in der Regel robust gegenüber solchen Störungen im Vergleich zu NLP-Modellen, die für die Aufgabe trainiert wurden. Warum? Der Datensatz kann mit systematischen Bias gesampelt werden. Das führt zu einer einfachen Entscheidungsgrenze, die kontrafaktisch übertreten wird. Das zeigt sich in diesem 2D-Klassifizierungsproblem. Mit meiner Arbeit habe ich herausgefunden, dass das Hinzufügen von kontrafaktischen Beispielen zu den Trainingsdaten das Modell robust gegen solche Störungen machen kann. Wenn also Kontrafakten wertvoll sind, wie können wir sie dann generieren? Diese Aufgabe ist besonders schwierig für NLP, denn hier sind drei Beispiele aus drei verschiedenen NLP-Aufgaben. Wie Sie sehen können, müssen Beispiele, die die Entscheidungsgrenze zwischen den Ergebnissen verletzen, sehr sorgfältig erstellt werden, indem einige Attribute des Textes, die hier unterstrichen werden, gestört werden. Dies könnte durch menschliche Annotation geschehen, aber dies ist teuer und voreingenommen. Einige frühere Arbeiten konzentrierten sich auf die Verwendung von Syntax-Bäumen oder einer semantischen Rollenbezeichnung. Aber die Reihe von Störungen, die durch diese Techniken generiert werden, sind durch den semantischen Rahmen begrenzt. Neuere Arbeiten haben maskierte Sprachmodelle verwendet, um maskierte Teile des Textes auszufüllen, um Labels zu ändern. Aber herauszufinden, welche Teile des Textes zu stören sind, kann eine Herausforderung sein. Es gibt mehr Herausforderungen für die Generierung von Kontrafakten als für die spezifische Beantwortung der Frage. Diese Aufgabe erfordert Hintergrundwissen. Um beispielsweise die ursprüngliche Frage zu stören: „Ist Indiana Jones und der Tempel des Todes ein Prequel?“ Wir müssen die anderen Filme im Franchise kennen, um die Frage stellen zu können: „Ist Indiana Jones – Jäger des verlorenen Schatzes ein Prequel?“ Darüber hinaus können zufällige Störungen zu Fragen führen, die mit den verfügbaren Beweisen nicht beantwortet werden können oder falsche Voraussetzungen haben. Darüber hinaus können einige Frage-Störungen zu einer signifikanten semantischen Abweichung von der ursprünglichen Eingabe führen. Zum Beispiel ist diese Frage hier: „Praktiziert Indiana Jones Kindersklaverei im Tempel des Todes?“ Wir wollen eine sehr einfache, aber effektive Technik mit dem Namen „Retrieve Generate Filter“ oder RGF vorschlagen, um kontrafaktische Störungen von Fragen in Angriff zu nehmen. Sie zielt auch darauf ab, alle anderen oben genannten Herausforderungen zu bewältigen. Die Kernintuition hinter RGF ist, dass die notwendigen Hintergrundinformationen, die erforderlich sind, um Störungen zu genieren, in den Near-Misses vorhanden sein können, die von einem Frage-Antwort-Modell erstellt werden. Zum Beispiel liefert das hochmoderne Modell REALM die folgenden Top-k-Antworten auf die Frage, wer der Kapitän des Richmond Football Club ist. Es holt die ursprüngliche Referenzpassage und die Antwort „Trent Cotchin“ als erste Wahl ein. Zusätzlich werden auch zusätzliche Passagen und Antworten abgerufen, die verwendet werden können, um Störungen der Frage zu steuern. Zum Beispiel holt es zwei weitere Antworten ein, passend zu den Kapitänen der Reservemannschaft und der Damenmannschaft des gleichen Vereins. Dies kann zu interessanten Änderungen führen. Zusammenfassend lässt sich sagen, dass RGF zuerst die wichtigsten Top-k-Antworten und Kontexte abruft, die nicht mit der Referenz Antwort in Kontext übereinstimmen. Im Anschluss an diesen Schritt konditioniert dieses Fragengenerierungsmodell diese alternativen Antworten, um eine ihnen entsprechende Frage zu generieren. Schließlich können wir die generierten Fragen nach Minimalität oder nach der Art der semantischen Störung, die wir einführen möchten, filtern. Wenn wir beim Retrieval jeden Schritt genauer durchgehen, dann sehen wir, dass wir einen Abruf verwenden. Dann lesen wir ein Modell wie REALM, das als Eingabe die ursprüngliche Frage und einen großen Korpus wie etwa Wikipedia hernimmt. Es besteht aus zwei Modulen. Das Retrieval-Modul führt eine Ähnlichkeitssuche über einen dichten Index von Passagen durch, um die wichtigsten Top-k-Passagen zur Frage abzurufen. Das Lesemodul extrahiert dann aus jeder Passage einen Bereich als potenzielle Antwort. REALM ruft die Goldpassage und in den meisten Fällen die Antwort ab. In dieser Arbeit sind wir jedoch mehr an den Antworten und am Kontext interessiert, der später abgerufen wird. Im nächsten Schritt der Fragengenerierung verwenden wir diese alternativen Antworten und Kontexte, um neue Fragen zu generieren, die diesen Alternativen entsprechen. Das Modell der Fragengenerierung ist ein vortrainierter Text-to-Text-Transformer, der auf die NQ-Daten abgestimmt ist, um eine Frage für eine Antwort zu generieren, die für den Kontext markiert ist. Während der Interferenz liefern wir das Fragengenerierungsmodell, die alternative Antwort und den Kontext, die wir im früheren Schritt abgerufen haben. Zum Beispiel für die Anfrage: „Wer ist der Kapitän des Richmond Football Clubs?“ REALM ruft Passagen über die Damenmannschaft des Clubs ab, die von Jess Kennedy angeführt wird. Das fragengenerierende Modell generiert die Anfrage: „Wer war Kapitänin der ersten Damenmannschaft des Richmond Football Clubs?“ Hier gibt es eine spezifische semantische Störung. In einer ähnlichen Art und Weise erhalten wir auch Abfragen, wie etwa: „Wer war Kapitän der Richmond's VFL-Reservemannschaft?“ Oder: „Wen hat Graham letztes Jahr im großen Finale geschlagen?“ Schließlich filtern wir eine Teilmenge der generierten Abfragen basierend auf gewünschten Eigenschaften aus. Wie vorhin begründet, möchten wir sicherstellen, dass die neue Frage immer noch semantisch nah am Original ist. Bei den Filtertechniken, die keine zusätzliche Überwachung erfordern, speichern wir einfach neue Fragen, die einen kleinen Token-Label und einen Bearbeitungsabstand von der ursprünglichen Frage haben. Wir entfernen zum Beispiel die Frage: „Wen hat Graham letztes Jahr im großen Finale geschlagen?“ Denn diese hat einen längeren Bearbeitungsabstand zur ursprünglichen Frage. In unseren Experimenten zeigen wir, dass diese einfache Heuristik verwendet werden kann, um Trainingsdaten zu erweitern und in die Warteschlange zu stellen. Wir experimentieren auch mit einer Filterstrategie, die auf der Art der semantischen Störung basiert. Zu diesem Zweck verwenden wir einen allgemeinen Zerlegungsrahmen für die Anfrage mit dem Namen QED. QED identifiziert zwei Teile der Frage: ein Prädikat und eine Referenz. Referenzen sind Substantivgruppen in der Frage, die Entitäten im Kontext entsprechen. Ein Prädikat ist im Grunde der verbleibende Teil der Frage. Zum Beispiel sind wir in der Lage, die Abfrage zu zerlegen: „Wer war Kapitänin der ersten Damenmannschaft des Richmond Football Clubs?“ Wir können die Frage in zwei Referenzen zerlegen: das Damenteam vom Richmond Football Club und das Prädikat X (wer war Kapitänin?). Ein Modell, das auf Referenzen der Prädikatannotationen für NQ trainiert wurde, erlaubt uns diese Zerlegung der Frage. Die Zerlegung sowohl des Originals als auch der generierten Frage basierend auf QED ermöglicht es uns, unsere generierten Kontrafakten für die Bewertung zu kategorisieren. Konkret erhalten wir zwei Gruppen von Fragen. Es gibt Fragen, bei denen sich die Referenz ändert, aber die Prädikate gleichbleiben, und Fragen, bei denen sich die Prädikate ändern und optional Referenzen hinzugefügt werden. Hier ist ein Beispiel für eine Änderung der Referenz: „Wer war Kapitän der Richmond's VFL-Reservemannschaft?“ Das ist eine Veränderung des Prädikats: „Wer trägt die Nummer neun beim Club?“ Wir bewerten nun die Effektivität von RGF-Störungen, wenn diese um die Trainingsdaten ergänzt werden. Um insbesondere die Effektivität des kontrafaktischen Aufbaus effektiv bewerten zu können, experimentieren wir mit zwei starken Baselines des Datenaufbaus. Die erste Baseline, die als zufällige Antwort- und Fragengenerierung bezeichnet wird, fügt Daten hinzu, die keine Relation zur ursprünglichen Frage haben. Das heißt, dass Passagen und Antworten einfach zufällig aus Wikipedia entnommen werden. Diese Baseline fügt im Grunde mehr Daten hinzu, die wie NQ aussehen. Mit der zweiten Baseline, der Goldantwort und der Fragengeneration, aktualisieren wir speziell den Retrieval bei unserer Methode. Hier werden alternative Antworten nur aus der gleichen Passage ausgewählt, welche die Goldantwort enthält. Welche Leistung erbringen die Baselines, RGF und der Aufbau beim Leseverständnis, wo das Modell Zugriff auf Frage und Kontext hat? Wir experimentieren mit sechs von den Datensätzen der Domäne und präsentieren hier die Ergebnisse, wobei es bei den Daten um die Trainingsdaten geht und beim Aufbau verdoppelt werden. Wir stellten fest, dass beide Baselines des Datenaufbaus nicht in der Lage sind, unsere Verallgemeinerung der Domäne zu verbessern. Tatsächlich scheint ein Ensemble von sechs Modellen, die mit den ursprünglichen Daten trainiert wurden, die wettbewerbsfähigste Baseline zu sein. Im Vergleich zu dieser Baseline stellten wir fest, dass RGF-Kontrafakten in der Lage sind, die Leistung außerhalb der Domäne zu verbessern, während die Leistung innerhalb der Domäne beibehalten wird. Dies deutet darauf hin, dass das Füllen der Argumentationslücken beim Modell über einen kontrafaktischen Aufbau effektiver ist als mehr Daten aus der Training-Verteilung hinzuzufügen. Darüber hinaus fanden wir heraus, dass die Verwendung von Retrievals zur Erprobung alternativer Ergebnisse oder Antworten für effektive CDA wichtig ist. Wir experimentieren auch mit einer offenen Domäne-QA -Einstellung, bei der das Modell nur die Frage sieht. Wir bewerten wieder vier von den Datensätzen der Domäne. Wir stellten fest, dass die Baseline-Modelle nicht so effektiv für die Verallgemeinerung der Domäne sind. Allerdings zeigt der Datenaufbau mit RGF signifikantere Verbesserungen. Wir verbessern uns sogar in der Domäne NQ-Datensatz. Wir haben angenommen, dass der kontrafaktische Datenaufbau das Modell beim Lernen von besseren Abfragekodierungen für sehr ähnliche Abfragen unterstützt. Schließlich bewerten wir auch die Fähigkeit des Modells, die Einheitlichkeit in der lokalen Nachbarschaft der ursprünglichen Frage zu verbessern. Die Einheitlichkeit misst den Anteil der vom Modell korrekt beantworteten Fragen, bei denen sowohl das Original als auch die kontrafaktische Abfrage korrekt beantwortet werden. Dies hilft uns explizit, die Robustheit des Modells bei kleinen Störungen in der Nähe der ursprünglichen Eingabe zu messen. Wir experimentieren mit fünf Datensätzen, die Paare von Fragen enthalten, die semantisch nahe beieinander liegen. Abgesehen von den drei Datensätzen AQA, AmbigQA und den QUOREF-Kontrastsätzen, die bereits verfügbar sind, bewerten wir auch RGF-Kontrafakten. Diese sind mit ursprünglichen NQ-Fragen gepaart, basierend darauf, ob sie von einer Prädikat- oder Referenzänderung betroffen waren. Diese Teilmengen wurden intern annotiert, um Qualitätsmängel zu eliminieren. Sie werden als Ressource bereitgestellt. Alle Baselines können die Einheitlichkeit signifikant nicht verbessern. Das Ensemble der Modelle kann die Einheitlichkeit geringfügig verbessern. Der kontrafaktische Aufbau der RGF kann jedoch eine beeindruckende Steigerung der Einheitlichkeit sowohl bei früheren Datensätzen als auch bei den beiden Teilmengen, die wir für Referenz- und Prädikat-Störungen ausgewählt haben, aufweisen. Beachten Sie, dass die erweiterten RGF-Daten nicht durch den Störungstyp verfälscht werden, sondern nur durch die Evaluationssätze. Tatsächlich zeigt eine qualitative Überprüfung der verschiedenen Arten von Kontrafaktoren, dass die generierten Fragen mehrere unterschiedliche Störungen enthalten. Zum Beispiel ist diese ursprüngliche Frage über die Bevölkerung von Walnut Grove in Minnesota gestört. Diese Störung betrifft verschiedene Dimensionen wie Stadt, Bundesland, Land und verschiedene Prädikate wie Lage, Armut, Anzahl von Schulen. Das Audio von Störungen ist kontextspezifisch. Bei dieser anderen Frage über das Einzelturnier in Wimbledon handelt die Störung von der Art des Spiels, der Art des Turniers oder des Spielergebnisses. Abschließende Erkenntnisse: Wir befassen uns mit der Aufgabe des kontrafaktischen Datenaufbaus und Störungen bei der Information. Wir suchen nach Abfragen und bewältigen deren einzigartige Herausforderungen durch eine Umkehrung des Generierungsansatzes. Wir übergenerieren mithilfe von Near-Misses des Modells und filtern basierend auf dem Störungstyp oder der Minimalität. Wir stellten fest, dass diese Technik keiner zusätzlichen Überwachung bedarf und die Beispiele für den Aufbau markiert sind. Der Aufbau verbessert sich dank der Domäneverallgemeinerung und der Konsistenz der Nachbarschaft. Zudem stellten wir fest, dass die RGF-Kontrafakten semantisch divers sind, ohne dass Verzerrungen während des Aufbaus eingeführt wurden. Vielen Dank!", "source": ["2/acl_6060/dev/full_wavs/2022.acl-long.117.wav", "samplerate: 16000 Hz", "channels: 1", "duration: 1e+01:9.014 min", "format: WAV (Microsoft) [WAV]", "subtype: Signed 16 bit PCM [PCM_16]"], "source_length": 727936.0}
